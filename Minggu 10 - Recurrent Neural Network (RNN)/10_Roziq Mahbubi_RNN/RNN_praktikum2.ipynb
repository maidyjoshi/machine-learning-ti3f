{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOzEscqgHR0uJELOVB86+UT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rzqmhb/machine-learning-ti3f/blob/main/Minggu%2010%20-%20Recurrent%20Neural%20Network%20(RNN)/10_Roziq%20Mahbubi_RNN/RNN_praktikum2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Praktikum 2"
      ],
      "metadata": {
        "id": "57Za4W6SE490"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup"
      ],
      "metadata": {
        "id": "SVx9ItOpE6oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Import TensorFlow"
      ],
      "metadata": {
        "id": "SJcAq8VqFAlG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvIeENcQCF4a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # import tensorflow\n",
        "import numpy as np # import numpy\n",
        "import os # import library untuk manipulasi tingkat OS\n",
        "import time # import library waktu"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Download Dataset Shakespeare"
      ],
      "metadata": {
        "id": "HzdOrS-wFEKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengunduh file teks 'shakespeare.txt'\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79ZlButGCSlV",
        "outputId": "2957fed8-ccc8-4d78-dedc-a40dbd574bde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load Data"
      ],
      "metadata": {
        "id": "NNRcIKuGFHNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXWHm9hDCTK9",
        "outputId": "de50c544-a055-4b27-ae9b-747b67febc12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7C8s_D5CX8i",
        "outputId": "fb31d177-d906-4aff-dd01-99b63352605b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Alwsy9wTCY3f",
        "outputId": "e8ba798b-9c11-47d4-8f1b-31b05f3669b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Olah Teks"
      ],
      "metadata": {
        "id": "ohoPg3wrFM4v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Vectorize Teks"
      ],
      "metadata": {
        "id": "FXvvkzNRFPkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat contoh teks dan memisahkan setiap karakter\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRexptqoCa9V",
        "outputId": "bd9bf4c0-031c-44b0-b48c-7a12efeaf41b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat layer StringLookup untuk mengubah karakter menjadi id unik\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "iezCXgu7CbUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merubah id\n",
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-uPUAXmCccN",
        "outputId": "e107580a-cbef-4a0f-d12d-080b0f0cb624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat layer StringLookup lain untuk mengubah id kembali menjadi karakter\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "TYAaIiKACkEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merubah id\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2RGsvZACllc",
        "outputId": "b53d5c2a-55ee-46f1-b0cc-eb0eb09b5957"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggabungkan karakter menjadi string\n",
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPYhdo4fCo_r",
        "outputId": "245772f4-87b2-4ccb-bd29-8022831bb38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk mengubah ID menjadi teks\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "RdyAI3rJCrLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Membuat Training Set dan Target"
      ],
      "metadata": {
        "id": "oC8TmInBLkE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah semua teks menjadi ID\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixrIRGMhCuAj",
        "outputId": "2cce565a-895e-4760-be54-275c2412a189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat dataset dari ID\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "mQsmSdHWCuzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mencetak beberapa ID pertama\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtRtfgFNC0a7",
        "outputId": "5d9c1e4b-ce6b-4830-a564-588df2cf6e15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100 # mendefinisikan sequence"
      ],
      "metadata": {
        "id": "1kRRJtZ_C0Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True) # Membuat sequence dari ID\n",
        "\n",
        "# Mencetak beberapa karakter pertama\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kN5RBtPC0WI",
        "outputId": "9b1032e3-9c3e-48b8-d07f-fc4b5a00c3f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mencetak beberapa text pertama\n",
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8grrvNGFCupJ",
        "outputId": "b29505d9-cf80-4f7d-f2ea-f38100a30d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk membagi input dan target\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "8pbHfHjMCudt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# memecah teks menjadi karakter\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4QgV-ACC-R3",
        "outputId": "aed308b5-3ad2-4627-95a9-c557575a6a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target) # Membuat dataset dari sequence"
      ],
      "metadata": {
        "id": "bQbdp80PC-Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# menampilkan sample data\n",
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lri1qoTC-LT",
        "outputId": "e55f1e7e-4d7c-435f-8078-6a91f3d98d2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Membuat Batch Training"
      ],
      "metadata": {
        "id": "pxkkpahYLsuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Menyiapkan dataset untuk pelatihan\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZ4KYwQsC-Ip",
        "outputId": "4a0c4e48-d797-400b-ee7e-6fcb715e718a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Buat Model"
      ],
      "metadata": {
        "id": "ob4EfsNTLvcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "3UCzv6KaC-GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat model\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "Oe3-NDJ-C-Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat instance dari model\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "4ubsvevqC-BP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Uji Model"
      ],
      "metadata": {
        "id": "R0jFiuBWL062"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZe2JucqC9-8",
        "outputId": "19ab7bdb-761c-4c9b-d239-17e058ac71d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chp2NrMcDMU4",
        "outputId": "af6c2e73-0f23-4515-a1da-25191160578a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "7YN0PkKiDMS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clxmQznbDMQM",
        "outputId": "127e78b3-acca-4ccd-bf70-130f325b4764"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([28, 38, 21,  0, 20, 56, 23, 36,  9, 16, 20, 17, 63, 24, 30, 61, 33,\n",
              "       56, 58, 63, 61,  6, 57, 53, 23, 16, 50, 31,  0, 23, 24,  3, 46, 39,\n",
              "       21, 25, 43, 65, 63, 35, 15, 62, 55, 37, 50, 61, 24, 28, 46, 40, 48,\n",
              "       48, 30, 50, 32, 37, 54,  4,  1, 31, 34, 44, 23, 43, 57,  6, 23, 26,\n",
              "       34, 32, 17, 38, 28, 17, 14, 37, 30, 32, 63, 20, 30, 38, 23, 47, 58,\n",
              "       49, 32, 12, 47,  2, 63,  8, 16, 55, 48, 28, 33, 61, 44, 37])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMyQ5K8mDMNv",
        "outputId": "70b1a22a-a6a8-4ae4-ce3a-533739097fe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b\"s death.\\n\\nQUEEN MARGARET:\\nAnd here's to right our gentle-hearted king.\\n\\nYORK:\\nOpen Thy gate of mercy\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"OYH[UNK]GqJW.CGDxKQvTqsxv'rnJCkR[UNK]JK!gZHLdzxVBwpXkvKOgaiiQkSXo$\\nRUeJdr'JMUSDYODAXQSxGQYJhsjS;h x-CpiOTveX\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train Model"
      ],
      "metadata": {
        "id": "3iGega2oL4p8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tambahan optimizer dan fungsi loss"
      ],
      "metadata": {
        "id": "83n1I0MYL7hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "zrTOei-jDMLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLuusorzDMIj",
        "outputId": "1d589cb8-a0fd-40de-fa9f-34fed74ec01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1866884, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrK_WmcsDMF-",
        "outputId": "6aa5e61e-f99d-4014-a7a3-eaa743dc92fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.80451"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "nvf1wDUzDMDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Konfigurasi Checkpoints"
      ],
      "metadata": {
        "id": "9ZkQPcsoL_jI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "idL9cHgbDMAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Lakukan Proses Training"
      ],
      "metadata": {
        "id": "rjZugbEHMC2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20 # Menentukan jumlah epoch untuk pelatihan"
      ],
      "metadata": {
        "id": "m9eOwQiYDL-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])  # Melakukan pelatihan model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoFljodODL73",
        "outputId": "2ff61b64-cef5-4ad6-d01e-be7dbc48d01a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 15s 53ms/step - loss: 2.6961\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 12s 51ms/step - loss: 1.9703\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 1.6924\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.5347\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 52ms/step - loss: 1.4382\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.3714\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.3201\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.2755\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.2352\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.1947\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.1552\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.1142\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 13s 61ms/step - loss: 1.0689\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 14s 62ms/step - loss: 1.0231\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 14s 62ms/step - loss: 0.9743\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 0.9233\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 0.8714\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 14s 62ms/step - loss: 0.8202\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.7692\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.7217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Generate Teks"
      ],
      "metadata": {
        "id": "NDLTeZSgMG31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat model untuk menghasilkan teks satu langkah pada satu waktu\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "xLcT6w90DL5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars) # Membuat instance dari model OneStep"
      ],
      "metadata": {
        "id": "BF4FUobXDc-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghasilkan teks dengan model\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "# Mencetak hasil dan waktu eksekusi\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah8zozxVDc6q",
        "outputId": "5d547ead-67d8-4e02-d72f-3fd3f1089fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "\n",
            "Ghost of SABESEY:\n",
            "You know the queen's pine; with robbers ready, impress'd\n",
            "To have him more unclineded at many delicers\n",
            "him.\n",
            "\n",
            "NORTHUMBERLAND:\n",
            "In his newge-brethern in the purts of France,\n",
            "And from my business in the Capulets kind\n",
            "Of every wreckned, with nothing fingers\n",
            "To do thee speed to be a pover there.\n",
            "\n",
            "Second Citizen:\n",
            "Come on, sit by the sun,\n",
            "Come on, with a bloody deed to my apparel;\n",
            "But stay the hearts to me, and my life upon her;\n",
            "Madam, your friends are brought my troth, I'll pay them.\n",
            "\n",
            "KING LEWIS XI:\n",
            "To wife, let thim be heard of that person.\n",
            "\n",
            "GRUMIO:\n",
            "Why for Claudio, sir?\n",
            "\n",
            "ABRAHY:\n",
            "No, my good lord Greecen:\n",
            "I will to him in the common.\n",
            "\n",
            "Second Servingman:\n",
            "Here, sir.\n",
            "\n",
            "First Senator:\n",
            "Tell me, good naples, circling now!\n",
            "And all the summers will entreat her good a\n",
            "good favour.\n",
            "\n",
            "COMINIUS:\n",
            "Dost thou done?\n",
            "\n",
            "ISABELLA:\n",
            "It is a mind\n",
            "of noble Geers! my boy shall serve a bawd:--for tears we still haded\n",
            "withdrawing in the field?\n",
            "\n",
            "WARWICK:\n",
            "And I I have heard is gone; it is no blood,\n",
            "This  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.196418285369873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghasilkan teks untuk beberapa instance sekaligus\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "# Mencetak hasil dan waktu eksekusi\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaurcmTTDjNR",
        "outputId": "2cdf87a5-96b6-44fb-e5c4-34361ff891ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nSir, my reasons must not be confixed.\\n\\nKING RICHARD II:\\nSo to offend him so dissembers, there a man\\nFor making him with the racks. My gage\\nNeckssities in him that's tooth'd; boy, in a fearful pow\\ndeservent to beat my body's pabbia. What\\nshould, no less, but there deny to decent\\nOf our places of themselves: sir, were not before\\nI call hom we will to do him right.\\n\\nROMEO:\\nWhate'er it be told them most carelets that,\\nGood patricy, and some of those loves.\\nI, like a brother in the midule should\\nBe subject: 'tis thursday neat, our kingdable dotary\\nAs you have stop'd the suddent in the common bodies\\nOf woltchmans have attendent you out:\\nDo you cut with a man to men's place.\\n\\nGLOUCESTER:\\nGood night to your recompense is ready; you are come\\nTo hear it cannot hence to France to 'wis time\\nwhat I can dream'd a word or thing\\nBy heaven from too hit the heat of worthy:\\nReshow me unthriver, and I knew not\\nThat title can apporn the wreck, which I\\nfear me as she still lives, that took me for the duke.\"\n",
            " b\"ROMEO:\\nGo thy wit down, was I go: and 'tis pour'd is duked wot;\\nWhich never toucheth i' the hearts together,\\nAnd make mercilasts of sweet spritely,\\nAnd some of those that scorn'd to the ugged perford,\\nScarency away; for there comes return to us.\\n\\nHASTINGS:\\nGood morrow to my person; have you done\\nWith that his hand kill'd herself hence and foreafer\\nThat would make mer hearts with a gentleman is\\ncomed here, from him that her hungry pour conjures to thee,\\nThat with a born bending in his life, against with those\\nThat most are green; which is being granted:\\nI must fall said, sir; and if you say: the meat my sons.\\n\\nROMEO:\\nThere is a very good pethip to your power,\\nOur proffer'd in the topully.\\n\\nMessenger:\\nUpon these five years to give him doward.\\n\\nLUCENTIO:\\nAt SOMARIELEY:\\nMy lord, the shepherd's dauntiness; you know not\\nwhat woe doth trial with the measure is at hands.\\n\\nKING EDWARD IV:\\nNo, my good friend, I told you them,\\nThere was a mind determine of my good?\\n\\nCATESBY:\\nHis father's money?\\n\\nTRANIO\"\n",
            " b\"ROMEO:\\nI would not attend you play to me; and, in the\\nmoon, his brides, apparelt thick to taute us insolence,\\nNor choes, when I show'd Paris will be dead.\\n\\nHENRY BOLINGBROKE:\\nHis judgery,\\nConsures Richmond in the field before him:\\nI had a hearned place of pointing torments!\\nMadam, some other have well torned my father,\\nBefore the to dignity in my bird.\\n\\nPETRUCHIO:\\nWhere are you, make good thee and be.\\n\\nDERBY:\\nThe word is shepherds, as his roself and you\\nSupposing to help him a lineal arms at\\nTheir own particular strength!--\\nAnd it not heart will fly:\\nOft with me be in his hand, and own life,\\nMy parks are grace, sir; which this being anchor,\\nWhich once refuse this port in hazing slain,\\nThe wisdom of his heart conceived in hell.\\nTake When for Bery, and I know how you knew them.\\n\\nTRANIO:\\nAy, mistress! from the house of London,\\nSo would he see this good report: or suddle of the hounder-fortune's book,\\nIf with the emptide roared all the subjects' signity\\nWould ad homely slaughter'd England's king\"\n",
            " b\"ROMEO:\\nGood Polixene;\\nSo that high mine eyes upon my bawd;\\nBehold this voice of Marcius to their boardent!\\n\\nCATESBY:\\nHe sole sovereign.\\n\\nESCALUS:\\nCut our nature is broken faith! thou keep my friends,\\nI cannot tell where the deed was dote again,\\nKeep indee Bohemia, which is enough't\\nFor death:' quoth she buil anoth.\\nThe burthend him, wish thou didst see\\nQUEEN MARGARET:\\nWith promised in this life and well-addice\\nTo mercy it in the veining stars\\nOp wiven sons of breasth.\\n\\nLEONTES:\\nGood, Bianca.\\n\\nAUTOLYCUS:\\nO, tell me, madam; go to thee.\\n\\nFRIAR LAURENCE:\\nThese detect Romeo is before.\\n\\nDUCHESS OF YORK:\\nIt cannot be, for I am power?\\n\\nBENVOLIO:\\nAnd yet my holy lords, my swift die all the world\\nIn made, elsewhat anchors most sharp of Edward's child!\\nTell me, good night, is fain and droap\\nWith sixteen years of all the buried majesty\\nEre thou but close his enemies? who if induety\\nWherein it shall not be so bold to do't.\\n\\nNORTHUMBERLAND:\\nRightly for an offly, thou'lt not be so defend;\\nFor my poor heart\"\n",
            " b\"ROMEO:\\nThe senate hath brought by this good shroud?\\n\\nDUKE OF AUMIRLE:\\nRichard of Exeter, for therefore look doth live;\\nI mean, his grace.\\n\\nCORIOLANUS:\\nPrithee, Kate, we'll beat them looks for laying\\nfoot.\\n\\nLUCENTIO:\\nAnd he shall not be here.\\n\\nPOLIXENES:\\nI know not whether to visit them;\\nAnd in disessible way more causes to go\\nwithout a harriest anchor of a mind of son.\\n\\nDUCHESS OF YORK:\\nHe'll see how to a bed of great and virtuous.\\nThy fair presence, rooty to your tarnor will\\nLest on a hook to prayers, to hear her shall be\\nOf butchers, show to beast, desert trymun:\\nFear not, my lord: let my blood with't a great nay:\\nTo him protectors else, obedience; as thou art too;\\nAnd meet me over with that sir!\\nBut Must I love thee again: he will they-bate\\nto them. Now, good Prince against the Tirtue.\\n\\nSecond Citizen:\\nWe pray, where are you?\\n\\nMENENIUS:\\nI poorly look!\\nA heap that never be unhatumpt,\\nIf your find ere I rail on foot\\nHerewitbany of our hearts, and swore as death;\\nWould I, not to unto the liv\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.242555618286133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Ekspor Model Generator"
      ],
      "metadata": {
        "id": "HpEUxgKQMNcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan model\n",
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "# Memuat model yang telah disimpan\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfQN1HLKDjLF",
        "outputId": "ddea1f35-98bd-47b3-8e47-496cda729a0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7c6591ec0730>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghasilkan teks dengan model yang telah dimuat\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_pL2EPtDjIu",
        "outputId": "f338bf31-dc47-4269-d3b2-5f3f10c48c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Who set his foungest toth mine eye seeming shuts\n",
            "To bear the infinite doth character thieves.\n",
            "\n",
            "Serv\n"
          ]
        }
      ]
    }
  ]
}