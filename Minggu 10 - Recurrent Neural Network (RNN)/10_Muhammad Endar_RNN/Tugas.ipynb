{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T22ueImYnFF"
      },
      "source": [
        "## **Jobsheet 10 | Pertemuan 10**\n",
        "## **Recurent Neural Network (RNN)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dighPNItqrOf"
      },
      "source": [
        "### **Tugas**\n",
        "\n",
        "Prosedur pelatihan pada praktikum 2 merupakan prosedur sederhana, yang tidak memberi Anda banyak kendali. Model ini menggunakan \"teacher-forcing\" yang mencegah prediksi buruk diumpankan kembali ke model, sehingga model tidak pernah belajar untuk pulih dari kesalahan. Jadi, setelah Anda melihat cara menjalankan model secara manual, selanjutnya Anda akan mengimplementasikan custom loop pelatihan. Hal ini memberikan titik awal jika, misalnya, Anda ingin menerapkan pembelajaran kurikulum untuk membantu menstabilkan keluaran open-loop model. Bagian terpenting dari loop pelatihan khusus adalah fungsi langkah pelatihan.<p>\n",
        "Gunakan tf.GradientTape untuk men track nilai gradient. Anda dapat mempelajari lebih lanjut tentang pendekatan ini dengan membaca eager execution guide.<p>\n",
        "\n",
        "Prosedurnya adalah \"<p>\n",
        "1. Jalankan Model dan hitung loss dengan tf.GradientTape.\n",
        "2. Hitung update dan terapkan pada model dengan optimizer\n",
        "\n",
        "\n",
        "### **Jawab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m1dVe8FxrDuU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGsqYujLrDdY"
      },
      "source": [
        "melakukan download Dataset Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuuPhTEFrWgL",
        "outputId": "a335637c-19fe-41c0-d608-2af28b34340f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UMseXEHn55d"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alMtjR79rbPZ",
        "outputId": "76fabc6c-7dc3-4a8c-f86d-6968e1e51ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KW3eyB9cre6X",
        "outputId": "64f752af-b9e7-44da-d61b-bf4900c262cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYzdGYDnrouC",
        "outputId": "a5d8c9c0-1a92-4e8b-ba22-6b4ceb0eae0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp8Pf68CpXXJ",
        "outputId": "e6f448d1-eace-4a0b-c315-c4b2f7038ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "   ! $ & ' , - . 3 : ; ? A B C D E F G H I J K L M N O P Q R S T U V W X Y Z a b c d e f g h i j k l m n o p q r s t u v w x y z "
          ]
        }
      ],
      "source": [
        "# Print unique characters\n",
        "for char in vocab:\n",
        "    print(char, end=' ')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sJzZUuCpiu6"
      },
      "source": [
        "olah Teks\n",
        "\n",
        "Vectorize Teks\n",
        "\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TndF_SUbps7q",
        "outputId": "a8ac3825-2e1d-41c9-cc04-ea08c8e8d390"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7PmP0wrpwLx"
      },
      "source": [
        "kemudian buat tf.keras.layers.StringLookup layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nSqr6z7Fp0uD"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bq7vUzqp0rn",
        "outputId": "00f49d78-a3a4-49ad-86f7-72613ad73348"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZY5gn1EEp8CQ"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9u9I2e4qBU9",
        "outputId": "006ccfc7-3613-4853-e701-f0770d47ceb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H77qa8SbqD7r",
        "outputId": "7ca454db-7cff-4d9c-d6d4-e1dcc4af8ca3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "MDXm0r42qGZ9"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WPflQITqJTt"
      },
      "source": [
        "Prediksi\n",
        "\n",
        "Membuat Training Set dan Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73kylzGkqNzs",
        "outputId": "437d317e-296e-42a7-eeb5-0dfa615eb8f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Mj_BsixZqQN2"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18iLIcipqTeS",
        "outputId": "83b05538-be29-4969-85ef-be1ea25d2a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p_MusSReqV7b"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFlcBAs3qYie"
      },
      "source": [
        "Metode batch memungkinkan kita dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5xUrzBCqc27",
        "outputId": "e0b4976b-cdef-4cdf-9148-f0f03a71004c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOQPgK8uqiJk"
      },
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSEJ5sg3qkQ4",
        "outputId": "3a97dbdd-8a9f-4419-fa52-8c6e162fef42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9EocGhsqrKi"
      },
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "F4i8yWAUqttL"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdC60Yf3qw1R",
        "outputId": "1c3c3753-c8e1-475c-e416-098f0278e4e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "KRzoiuyoqzvb"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_RB-i84q2aX",
        "outputId": "c9aebb44-9cc2-47c8-b305-758542cbea8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpyC3Lfdq409"
      },
      "source": [
        "Membuat Batch Training\n",
        "\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh_3rr0Lq9T0",
        "outputId": "6d38ce9a-00ed-422b-f9f1-acb1cafaa6ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vJDZHqOrA-D"
      },
      "source": [
        "Membuat Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "D07ADY4vq_oC"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nFQJrvVvrIZ3"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "C6DmNDvArKjG"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiz4DeAdrMOC"
      },
      "source": [
        "Uji Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzrXbO1OrQZb",
        "outputId": "9843ef1b-b841-4d9b-844d-dfae5fae450e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-v-FtDOYrSzE",
        "outputId": "9f764c2b-347e-454a-fb07-8906def9f7e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "XZGijCaorWYx"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYQiByzarYt2",
        "outputId": "4d3f6095-4249-4130-f07f-018e10c1717a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0, 42, 52, 52, 49, 49, 49, 20, 55, 62, 39,  5, 35, 48, 24, 64, 13,\n",
              "       65, 49,  7,  2, 29, 20, 39, 12,  6,  4, 59, 30, 62, 49, 34, 37, 21,\n",
              "       60, 35, 17,  5,  5, 33, 53,  8, 57,  8, 26, 48, 27, 48, 34,  0, 61,\n",
              "       58, 35, 39, 34, 26, 26, 13, 34, 57,  9, 19, 53, 33,  6, 44, 51,  5,\n",
              "       60, 17, 61, 22, 15, 61,  8, 14, 61, 23, 63, 32, 50, 31, 35, 34, 51,\n",
              "       34, 43, 10,  1,  0, 44, 20, 50, 17, 39, 44, 61, 45, 48, 15])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STcK2eldrbAm"
      },
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cY__Gc4rdqP",
        "outputId": "bb615eba-7bff-419f-b778-79865fb2164a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b' counsel to his unstaid youth?\\n\\nDUKE OF YORK:\\nVex not yourself, nor strive not with your breath;\\nFor'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"[UNK]cmmjjjGpwZ&ViKy?zj, PGZ;'$tQwjUXHuVD&&Tn-r-MiNiU[UNK]vsVZUMM?Ur.FnT'el&uDvIBv-AvJxSkRVUlUd3\\n[UNK]eGkDZevfiB\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIEvEEFprgx5"
      },
      "source": [
        "### **Train Model**\n",
        "\n",
        "Tambahan optimizer dan fungsi loss<p>\n",
        "\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WEhpmrSIrl8x"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vQrRQy2roWv",
        "outputId": "0a90c235-a08d-4505-d40c-6203867e3d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.188585, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtG_mI_lrqsC"
      },
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuSW1aiirsyW",
        "outputId": "aa7ce512-9501-4924-c70b-67752c14a424"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65.92942"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fc4lBWkrvV3"
      },
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jnGYrAQ5rxNU"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RD8-WonFr0EQ"
      },
      "source": [
        "Konfigurasi Checkpoints<p>\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "YpmA-Ncxr3nE"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFTJWDB8r6Di"
      },
      "source": [
        "Lakukan Proses Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAqUQUZCr7lR",
        "outputId": "a7651274-2c04-464c-cdb6-63aea570a339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 15s 55ms/step - loss: 2.7392\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 2.0058\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.7215\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.5549\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.4552\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.3860\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 13s 55ms/step - loss: 1.3329\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.2884\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.2486\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.2092\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8sZbFFxsDM-"
      },
      "source": [
        "Generate Teks<p>\n",
        "\n",
        "Berikut ini membuat prediksi satu langkah:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "6QIyjnK5sGj3"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "hToII-X0sIe8"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OzIiJubhsLF4",
        "outputId": "9eaacb01-586d-475d-addd-048c74e7d3a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Now. God send, the senater:\n",
            "if him the keporty should to kill the figure in the book.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What, is my wift as the hand: what shall shall stand upon my livery?\n",
            "\n",
            "ROMEO:\n",
            "Then he knows, nor will now, saddle sife have\n",
            "perfective; Belaps. Thereof is the centrement of his\n",
            "Against myself I say,\n",
            "With her hence till no other, so, can ster a\n",
            "last! it assurity,\n",
            "I warrant him. Be entreat day's blunch.\n",
            "\n",
            "CAPULET:\n",
            "What is the mast embrace:\n",
            "or, bear it. For I hear, beseech yourselves, and\n",
            "Burks, traitor, to Excoup 's, had no money and death.\n",
            "Poor Margaret, man, a curse is head into my wife.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "what chose the issue of this praise strokes murdersh in our morning\n",
            "Commends' secretive formins, your advice here,\n",
            "As enemies, desperate worth themself,\n",
            "Have no increemity an assuran\n",
            "To set forty on me. the word of pasting\n",
            "By with your ammistacence, in Rome.\n",
            "\n",
            "MENENIUS:\n",
            "That is such brools is so.\n",
            "\n",
            "Clown:\n",
            "Here's a new-better news.\n",
            "\n",
            "DUKE OF AUMERLE:\n",
            "And-done win dicord, I will not say to \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.3598029613494873\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv4u765nsOBQ",
        "outputId": "49be86f4-85f2-496f-cc84-70269e346dcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nO, she had shaked friends. Both, being met's well,\\nWith ungreen wench obstance, Signior Husbany!\\n\\nFiest Catesby:\\nPrey thou, this sudden dows,\\nCannot subsurvey. Loth he go back,\\nTo time hath cares for the poilty:\\nBeing not decey.'\\n\\nKING EDWARD IV:\\nAlack the such a ligh, and cheer to speak with splece a luin;\\ncoadle, by night. I warrant, sir, brister.\\n\\nMENENIUS:\\nO, there's me no more.\\n\\nNurse:\\nAn if I cannot tell him;\\nThat dark'd up ourselves, want thou weep my cheek\\nWhen I prod strength whose dead God, although with hone,\\nwe would not be behelding his heaven's,\\nThat, canourdy in the time,\\nWhich, tender women knows for peers\\nNo remised him from his tongue?\\n\\nFRIAR JAENCA:\\nFor wail in the substace of the worst,\\nWho shows perpected his approfected men.\\n\\nANTONIO:\\nThe widow his heeds.\\n\\nFirst Citizen:\\nAy, let the prince shall not\\nHow can I not, sit now?\\n\\nCORIOLANUS:\\nNo, number\\nhere all make him mad so blows. But when,\\nWith Richard Castor here deliver'd her!\\n\\nGREGORY:\\nMy enforcement.\\n\\nDUKE VINC\"\n",
            " b\"ROMEO:\\nNow, lords are my sovereign shed Saverbind.\\n\\nFirst Murderer:\\nI sufficmer, his, past fray?\\n\\nBIANCA:\\nIf us! sir, my turn? for this shall you think\\nThey shall be ne to this clothe again;\\nFor; and tell you another ig only him to Bohemia.\\nTell me, true kindness and forsuni's than she,\\nHe may but kiss, the do reason such joy\\nTill we found, and, kneel'd the hearing!\\n\\nHASTINGS:\\nMy ashametle, through the sou hast tongued\\nAnd none at all that I do beseech you; he!\\n\\nAUFIDIUS:\\nHow now! O expollent erg is at thy blood,\\nAnd nail received and from stand at him.\\n\\nThird Citizen:\\nUntendation of the first inversety full of weeds,\\nAnd part's fellow do the heir of Derbain;\\nLay hence with the freshess at it end;\\nThe gower that e'er the swalls of scorn.\\n\\nLients\\nLet us at the mark of thither God's safe.\\n\\nClown:\\nAlack, with you! Why, good Cominius:\\nThe hard and comfort is the tedious cold;\\nOr with her sixterly against her eyes.\\nBut Hereford, I call.\\n\\nJULIET:\\nWhat manactors to make a\\nClereneme the heaven finde\"\n",
            " b'ROMEO:\\nA honour, to-day tongue-ord.\\n\\nMENENIUS:\\nPray, sir, an he was, sir.\\n\\nESCALUS:\\nI know now, by a remist.\\n\\nANTONIO:\\nCommend me to the noble adversa!\\n\\nROMEO:\\nBy heaven,--\\n\\nJULIET:\\nWhat, stand thy heads for the holour of their heads of\\nyour common tell? where haste he did?\\n\\nARCHIDAMUS:\\nI did not discomin-kind, being a friar,\\nAll bush abudge of state,\\nAnd then poxspure my Cupite--Ound the end of hercely envy, sir,\\nher party is, the warrant, were is with the me;\\nLike men, and safitistament: I will time\\nThe friar of kings and fame forced A fortune cere\\nThe Volsces nothing bow a\\nvirtue in the honest.\\n\\nSATPSONAS:\\nWhat, do you through a ravent for much.\\n\\nBAPTISTA:\\nUpon one witchman: blows thou hast force again Nor any on\\nEven stinl the friend of Men, God small, if they\\nhonest were from this land?\\nOr doth the king to do so, for this obward head,\\nAnd all the earth we shall have the world.\\n\\nSEBASTIAN:\\nNor to old concerning.\\n\\nNORTHUMBERLAND:\\nWhat you must carquen kissman?\\n\\nBENVOLIO:\\nTranio, I did sti'\n",
            " b\"ROMEO:\\nFill'd withful direction!\\nAll the hows of other is: ere thy head o' I have discharded\\nWill him no less servant. All this is a\\nprestnech years a merby heart, madam; for it press\\nAt ribe our own regors, setrows,\\nHer baintafest hastings are succeeded too;\\nAh, are too much is deep-and presently\\nAnd please your life and infart, their surfeits refore.\\nWhy are now that you hids like a tafe?\\n\\nLADY ANNE:\\nAnd he shall have kill'd him; for you so reward.\\n\\nKATHARINA:\\nYou know it so appolubes with his thanks.\\n\\nGONZALO:\\nThe often did crow in Siting me so far;\\nAnd that I see thee in the brideghto raise at.\\n\\nBott:\\nBeseech you, sie. that makes down the grouck now\\nTo credit she suped by this nurse:\\nSitricial carding forth contends it,--\\n\\nCORIOLANUS:\\nBratch, we shall ficted\\nWith Bolingbroke from the young Ratclifl;\\n'Tis none, he first miss report. He'll send me, I will not be\\nus, in his scaps of behind chastisiquiver in the bod of,\\nDid mad i' the north, but he's goes,\\nI'll meet them's dark; with coward \"\n",
            " b\"ROMEO:\\nThat, bear thee up, that knot stone.\\nThis is thy cheat.\\n\\nClOVIO:\\nBe not a quarrel to your bitt:\\nBest on thy mother that shall speak all comes they have.\\nO cousin, starpation,\\nTo frow thy spark's cham i' the gross,\\nLost in the best quales with their hands.\\nThis long is behind my encounter's years,\\nAnd there with first half as eirs,\\nLend ane a shep where Gurds rips me in his part rule's heaven.\\n\\nDUKE VINCENTIO:\\nOurself, I should yet now, time\\nAgainst we will to her: Sunder: I\\nTend you thus: were return'd, he comes.\\nMake her no priest of basters, do the Duke of York:\\nAnd, for thy woods: who shall no good of the wisses of tyrance.\\nThe generlord, slave, again,--kill'd him and undeather.\\nGod we wild ushall I carry;\\nAm, lords, for I possess' depitanish'd;\\nFor those whose vering state, whom sils home.\\n\\nLUCIO:\\nThat will be dreadful better nature with a house:\\nAnd wash him head him stay.\\n\\nKATHARINA:\\nNay, but now, Shall'S. What, wilt thou mist:\\n'Sengragen, in the displess,\\nBecause I will not lea\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.2913413047790527\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6bVTZKcsQgs"
      },
      "source": [
        "Ekspor Model Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gWcg3d0TsS6O",
        "outputId": "5b44cd6d-a787-44a8-d601-09ff4f581e62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x78dfc7131660>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKVK-r7usUlz",
        "outputId": "643427fb-e2c6-427a-edd2-0880c1f95df5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "O love, part meant in parliamenes,\n",
            "Your affects of albow and to me; he be seen'.\n",
            "\n",
            "GREY:\n",
            "She speaks,\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3gu13D-ssAW"
      },
      "source": [
        "-----\n",
        "Tugas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "bM9r4DJZsvFS"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    inputs, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "o-XO2DGysxNt"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "pz-GX1zOszKz"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhqIxNvFs-4Y",
        "outputId": "0cd210ef-91a5-49e9-882b-62bc60fd7334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 16s 57ms/step - loss: 2.7309\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78dfa01fb7f0>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGwHLE94tEdQ",
        "outputId": "c298b013-f615-41ad-cdd2-8bfe21f172a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1922\n",
            "Epoch 1 Batch 50 Loss 2.0653\n",
            "Epoch 1 Batch 100 Loss 1.9274\n",
            "Epoch 1 Batch 150 Loss 1.8461\n",
            "\n",
            "Epoch 1 Loss: 1.9951\n",
            "Time taken for 1 epoch 12.38 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.7827\n",
            "Epoch 2 Batch 50 Loss 1.7092\n",
            "Epoch 2 Batch 100 Loss 1.6914\n",
            "Epoch 2 Batch 150 Loss 1.6794\n",
            "\n",
            "Epoch 2 Loss: 1.7168\n",
            "Time taken for 1 epoch 10.86 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5758\n",
            "Epoch 3 Batch 50 Loss 1.5872\n",
            "Epoch 3 Batch 100 Loss 1.5039\n",
            "Epoch 3 Batch 150 Loss 1.5213\n",
            "\n",
            "Epoch 3 Loss: 1.5561\n",
            "Time taken for 1 epoch 10.72 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4540\n",
            "Epoch 4 Batch 50 Loss 1.4406\n",
            "Epoch 4 Batch 100 Loss 1.4865\n",
            "Epoch 4 Batch 150 Loss 1.4472\n",
            "\n",
            "Epoch 4 Loss: 1.4572\n",
            "Time taken for 1 epoch 12.00 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3903\n",
            "Epoch 5 Batch 50 Loss 1.3915\n",
            "Epoch 5 Batch 100 Loss 1.3971\n",
            "Epoch 5 Batch 150 Loss 1.4031\n",
            "\n",
            "Epoch 5 Loss: 1.3887\n",
            "Time taken for 1 epoch 11.27 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3479\n",
            "Epoch 6 Batch 50 Loss 1.3206\n",
            "Epoch 6 Batch 100 Loss 1.3655\n",
            "Epoch 6 Batch 150 Loss 1.3800\n",
            "\n",
            "Epoch 6 Loss: 1.3349\n",
            "Time taken for 1 epoch 10.73 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2999\n",
            "Epoch 7 Batch 50 Loss 1.3026\n",
            "Epoch 7 Batch 100 Loss 1.2547\n",
            "Epoch 7 Batch 150 Loss 1.2556\n",
            "\n",
            "Epoch 7 Loss: 1.2898\n",
            "Time taken for 1 epoch 10.75 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2488\n",
            "Epoch 8 Batch 50 Loss 1.2895\n",
            "Epoch 8 Batch 100 Loss 1.2091\n",
            "Epoch 8 Batch 150 Loss 1.2583\n",
            "\n",
            "Epoch 8 Loss: 1.2486\n",
            "Time taken for 1 epoch 10.81 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1800\n",
            "Epoch 9 Batch 50 Loss 1.2596\n",
            "Epoch 9 Batch 100 Loss 1.2068\n",
            "Epoch 9 Batch 150 Loss 1.2733\n",
            "\n",
            "Epoch 9 Loss: 1.2087\n",
            "Time taken for 1 epoch 11.66 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1450\n",
            "Epoch 10 Batch 50 Loss 1.1826\n",
            "Epoch 10 Batch 100 Loss 1.1821\n",
            "Epoch 10 Batch 150 Loss 1.2096\n",
            "\n",
            "Epoch 10 Loss: 1.1688\n",
            "Time taken for 1 epoch 11.93 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  mean.reset_states()\n",
        "  for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "    logs = model.train_step([inp, target])\n",
        "    mean.update_state(logs['loss'])\n",
        "\n",
        "    if batch_n % 50 == 0:\n",
        "      template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "      print(template)\n",
        "\n",
        "  # saving (checkpoint) the model every 5 epochs\n",
        "  if (epoch + 1) % 5 == 0:\n",
        "    model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "  print()\n",
        "  print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "  print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjlntKy3tUJW"
      },
      "source": [
        "### **Jawaban Kesimpulan**\n",
        "\n",
        "Perbedaan antara kode tugas dengan praktikum 2 terletak pada prosedur pelatihan. Pada praktikum 2 menggunakan pendekatan pelatihan yang lebih sederhana dan umum digunakan, dengan model.fit. Sedangkan kode pada tugas menggambarkan pendekatan pelatihan yang lebih spesifik dan kompleks, yang dilakukan beberapa kustomisasi.<p>\n",
        "\n",
        "Dalam pendekatan ini, mendefinisikan metode train_step dalam model turunan yang mengatur pelatihan pada tingkat batch. Secara eksplisit dilakukan perhitungan loss, gradien, dan menerapkan pembaruan bobot model dengan apply_gradients, serta menggunakan objek tf.metrics.Mean untuk menghitung rata-rata loss selama pelatihan. Pendekatan ini memberikan lebih banyak kontrol dan fleksibilitas dalam pengaturan pelatihan model."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
