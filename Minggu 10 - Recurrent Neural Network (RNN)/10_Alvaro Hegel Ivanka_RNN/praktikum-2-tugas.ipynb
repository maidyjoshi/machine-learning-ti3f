{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yVZHX1qHAqz"
      },
      "source": [
        "**Praktikum 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7PfnbZnHAzk"
      },
      "source": [
        "**Generator Teks dengan RNN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.241953800Z",
          "start_time": "2023-11-28T07:16:44.130919800Z"
        },
        "id": "QobRhKwpG9Un"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.345753700Z",
          "start_time": "2023-11-28T07:16:50.246938500Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xm5Tut7jHKrk",
        "outputId": "80cc3be9-eb58-4cbb-9ffb-2793e0c36e5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Download Dataset Shakespeare\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.397322300Z",
          "start_time": "2023-11-28T07:16:50.346751200Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJJXKRpQHks6",
        "outputId": "695ed02a-3227-4eaa-93ef-fab544632108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Membaca teks dari file menggunakan mode 'rb' (binary mode) dan mendekode dengan encoding 'utf-8'\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# Panjang teks adalah jumlah karakter dalam teks tersebut\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.441884400Z",
          "start_time": "2023-11-28T07:16:50.399315900Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFm7pL89Hkvj",
        "outputId": "ba4d48b7-cc83-4cdf-805a-5fdcd5590ef8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mencetak 250 karakter pertama dalam teks\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.516684700Z",
          "start_time": "2023-11-28T07:16:50.410286Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMrV1oeLHky4",
        "outputId": "ca8b283d-31e0-4a99-c352-1db09c6a98d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# Mengidentifikasi karakter-karakter unik dalam teks\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "# Mencetak jumlah karakter unik\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.629196500Z",
          "start_time": "2023-11-28T07:16:50.438893100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTNjp-EJHk1V",
        "outputId": "01d8238e-493f-4587-bce2-86371f7f00d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Olah Teks: Vectorize Teks\n",
        "\n",
        "# Daftar teks contoh\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "# Memecah teks menjadi karakter-karakter Unicode\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "\n",
        "# Menampilkan hasil karakter-karakter Unicode\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.630194200Z",
          "start_time": "2023-11-28T07:16:50.548529700Z"
        },
        "id": "wbHrUlEoHk4M"
      },
      "outputs": [],
      "source": [
        "# Membuat lapisan StringLookup untuk mengonversi karakter menjadi ID numerik\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab),  # Daftar karakter-karakter yang ingin diindeks\n",
        "    mask_token=None  # Token masking (jika ada), dalam hal ini, tidak ada masking\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.631191400Z",
          "start_time": "2023-11-28T07:16:50.584334300Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCxuShDaHk7B",
        "outputId": "dfc27fca-6b3f-487a-8260-c4e351e09944"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengonversi karakter-karakter Unicode menjadi ID numerik\n",
        "ids = ids_from_chars(chars)\n",
        "\n",
        "# Menampilkan hasil ID numerik\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.632186700Z",
          "start_time": "2023-11-28T07:16:50.600229Z"
        },
        "id": "rycBOtMmHk94"
      },
      "outputs": [],
      "source": [
        "# Membuat lapisan StringLookup untuk mengonversi ID numerik ke karakter-karakter Unicode\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(),  # Menggunakan vocabulary yang telah diindeks sebelumnya\n",
        "    invert=True,  # Mengatur invert ke True untuk mengonversi kembali dari ID ke karakter\n",
        "    mask_token=None  # Token masking (jika ada), dalam hal ini, tidak ada masking\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.749439200Z",
          "start_time": "2023-11-28T07:16:50.620144Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri7e1BDMHlAu",
        "outputId": "c773da0e-1bd3-4cee-f0d4-6794e2c12bcc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:50.755417200Z",
          "start_time": "2023-11-28T07:16:50.687595900Z"
        },
        "id": "HnhK8iskHlDj"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.133906100Z",
          "start_time": "2023-11-28T07:16:50.692585900Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZCJz2sYHlGY",
        "outputId": "5e02dbff-070f-443e-ae36-6ac54ab8e763"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Prediksi\n",
        "\n",
        "#Membuat Trianing Set dan Target\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.154536800Z",
          "start_time": "2023-11-28T07:16:51.132910900Z"
        },
        "id": "-mTYcoHTHlJF"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.220250800Z",
          "start_time": "2023-11-28T07:16:51.147557600Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOmjtU3WHlMD",
        "outputId": "221a2341-47e2-4678-cfae-4436bce3b6d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.226238400Z",
          "start_time": "2023-11-28T07:16:51.220250800Z"
        },
        "id": "_gAf_1ezHlO9"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.307447700Z",
          "start_time": "2023-11-28T07:16:51.224243600Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg0D_L5EHlR9",
        "outputId": "bfbf616d-4946-49c6-c12c-84002ad01570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Metode batch  mengonversi karakter individual menjadi urutan ukuran yang diinginkan.\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.309444600Z",
          "start_time": "2023-11-28T07:16:51.249042200Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nw63DCiHlVP",
        "outputId": "cf094651-414f-40e8-97b5-786a9763b753"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "# Akan lebih mudah jika menggabungkan token kembali menjadi string\n",
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.309444600Z",
          "start_time": "2023-11-28T07:16:51.273451900Z"
        },
        "id": "p30H201HHlX2"
      },
      "outputs": [],
      "source": [
        "# Untuk pelatihan, memerlukan kumpulan data pasangan (input, label)\n",
        "\n",
        "# Fungsi yang mengambil urutan sebagai masukan\n",
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.310441400Z",
          "start_time": "2023-11-28T07:16:51.277446100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPTL58ytI327",
        "outputId": "08fb737f-348f-432d-8c38-0ca93d5afa08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.456144500Z",
          "start_time": "2023-11-28T07:16:51.283512100Z"
        },
        "id": "FJ1opHR5I3_S"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.469220300Z",
          "start_time": "2023-11-28T07:16:51.368730900Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-1wHmPkJSre",
        "outputId": "eef99498-a9de-4f2a-b808-79d4a6096104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.470320600Z",
          "start_time": "2023-11-28T07:16:51.427116500Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6kOrG5HnJSuc",
        "outputId": "28d620f0-5c9a-4776-8cd7-7f3a1661ae8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Membuat batch training\n",
        "\n",
        "# Batch size (ukuran batch) yang digunakan selama pelatihan\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size (ukuran buffer) untuk mengacak urutan dataset\n",
        "# TensorFlow data dirancang untuk bekerja dengan urutan yang mungkin tak terbatas,\n",
        "# sehingga tidak mencoba untuk mengacak seluruh urutan di dalam memori.\n",
        "# Sebaliknya, ia mempertahankan buffer di mana ia mengacak elemen.\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Mengonfigurasi dataset dengan mengacak urutan, mengatur ukuran batch,\n",
        "# dan menggunakan prefetch untuk optimalisasi\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)  # Mengacak urutan dataset\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)  # Mengatur ukuran batch dengan menghapus sisa data yang tidak cukup untuk satu batch\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)  # Menggunakan prefetch untuk optimalisasi\n",
        ")\n",
        "\n",
        "# Menampilkan dataset yang telah dikonfigurasi\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.470912200Z",
          "start_time": "2023-11-28T07:16:51.443643800Z"
        },
        "id": "5SEq-t7dJSxf"
      },
      "outputs": [],
      "source": [
        "# Buat model\n",
        "\n",
        "# Jumlah kata dalam vocabulary pada lapisan StringLookup\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# Dimensi embedding\n",
        "embedding_dim = 256\n",
        "\n",
        "# Jumlah unit RNN (Recurrent Neural Network)\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.485187300Z",
          "start_time": "2023-11-28T07:16:51.459855500Z"
        },
        "id": "zvLUNWVBJS0O"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan kelas model khusus MyModel\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "\n",
        "    # Lapisan embedding untuk mengonversi ID numerik menjadi vektor embedding\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # Lapisan GRU (Gated Recurrent Unit) dengan return_sequences dan return_state\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "\n",
        "    # Lapisan dense (sepenuhnya terhubung) dengan vocab_size output\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "\n",
        "    # Menggunakan lapisan embedding\n",
        "    x = self.embedding(x, training=training)\n",
        "\n",
        "    if states is None:\n",
        "      # Mendapatkan initial_state dari lapisan GRU jika states adalah None\n",
        "      states = self.gru.get_initial_state(x)\n",
        "\n",
        "    # Melakukan langkah propagasi pada lapisan GRU\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "\n",
        "    # Melakukan langkah propagasi pada lapisan dense\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      # Mengembalikan output dan states jika return_state adalah True\n",
        "      return x, states\n",
        "    else:\n",
        "      # Mengembalikan hanya output jika return_state adalah False\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:51.624768500Z",
          "start_time": "2023-11-28T07:16:51.467137400Z"
        },
        "id": "VqmJilkxJS3L"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,  # Jumlah kata dalam vocabulary\n",
        "    embedding_dim=embedding_dim,  # Dimensi embedding\n",
        "    rnn_units=rnn_units  # Jumlah unit dalam lapisan GRU\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.253122500Z",
          "start_time": "2023-11-28T07:16:51.500705600Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCHgzeZtJS6B",
        "outputId": "7767f251-5985-46af-8401-6a38e9f9dae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "# Uji model\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.265663800Z",
          "start_time": "2023-11-28T07:16:57.230629Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8rhUYbkJS9E",
        "outputId": "13d64b9c-6ba5-49f5-9a16-265acd29a40e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.512162200Z",
          "start_time": "2023-11-28T07:16:57.252125900Z"
        },
        "id": "8esBWa04KG_S"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices= tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.531874500Z",
          "start_time": "2023-11-28T07:16:57.269653800Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnKuPickKJjv",
        "outputId": "65f0538d-fd2b-4f11-fd05-1097df523382"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([31, 40, 24, 14, 63, 21, 27, 59, 16,  7, 52,  2, 64,  8,  3, 53, 14,\n",
              "       47, 22, 49, 27,  0, 19, 48, 38, 36, 29, 49, 38, 39, 12,  1, 43, 58,\n",
              "       33, 17, 25, 33, 43, 12, 17, 56, 45, 58, 53, 60, 18, 60, 20, 58, 45,\n",
              "       23, 51, 57, 45,  4, 56, 19, 19, 37, 60, 62, 36, 58, 24, 22, 22, 29,\n",
              "       53, 20, 25, 39, 39, 58, 31, 58, 59, 46, 38, 28, 36,  2, 10, 16, 58,\n",
              "       17,  4, 11, 26, 56,  6,  1,  9, 64, 47, 63, 29, 57, 30, 29])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.537494900Z",
          "start_time": "2023-11-28T07:16:57.281086Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiuvofpNJTAH",
        "outputId": "7c20eb78-66a1-4311-b248-0b3fba02a9e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b\"lding-anchor lost,\\nAnd half our sailors swallow'd in the flood?\\nYet lives our pilot still. Is't meet\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"RaKAxHNtC,m y-!nAhIjN[UNK]FiYWPjYZ;\\ndsTDLTd;DqfsnuEuGsfJlrf$qFFXuwWsKIIPnGLZZsRstgYOW 3CsD$:Mq'\\n.yhxPrQP\"\n"
          ]
        }
      ],
      "source": [
        "# Melihat teks yang diprediksi oleh model tidak terlatih\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.537494900Z",
          "start_time": "2023-11-28T07:16:57.294940Z"
        },
        "id": "GXXFaJX1JTDG"
      },
      "outputs": [],
      "source": [
        "# Train Model\n",
        "\n",
        "# Tambahan optimizer dan fungsi loss\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.539489400Z",
          "start_time": "2023-11-28T07:16:57.301719200Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38kRxgQSJTGM",
        "outputId": "0ce552cd-1008-4cb8-fea7-26d89039c4f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1888885, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.540485100Z",
          "start_time": "2023-11-28T07:16:57.327030100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8LndjLhJTJS",
        "outputId": "0ab46b46-da38-46b9-8489-05093e8c8539"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65.949455"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Memeriksa bahwa eksponensial dari loss rata-rata harus sama dengan ukuran kosakata\n",
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.541482500Z",
          "start_time": "2023-11-28T07:16:57.337280900Z"
        },
        "id": "F1WkiUCCJTL_"
      },
      "outputs": [],
      "source": [
        "# Konfigurasikan prosedur pelatihan\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.541482500Z",
          "start_time": "2023-11-28T07:16:57.366588800Z"
        },
        "id": "9RILfisZJTPB"
      },
      "outputs": [],
      "source": [
        "# Konfigurasi Checkpoints\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-28T07:16:57.555527200Z",
          "start_time": "2023-11-28T07:16:57.373758100Z"
        },
        "id": "mLGx0WEFLAzB"
      },
      "outputs": [],
      "source": [
        "# Lakukan Proses Training\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "ExecuteTime": {
          "start_time": "2023-11-28T07:16:57.379761500Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtFayGttLA2J",
        "is_executing": true,
        "outputId": "aa77e544-90d9-4da3-fafa-8546f4a4eaa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 13s 52ms/step - loss: 2.6914\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 12s 51ms/step - loss: 1.9719\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 1.6896\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.5338\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 12s 51ms/step - loss: 1.4372\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.3702\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.3187\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.2743\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 12s 52ms/step - loss: 1.2336\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.1930\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "OFBCtng0LA5P",
        "is_executing": true
      },
      "outputs": [],
      "source": [
        "# Generate Teks\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vezq7aEHLA8a",
        "is_executing": true
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Atk908MFLA_2",
        "is_executing": true,
        "outputId": "451f1415-e2c2-4c86-f4d5-2a37a34d9d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Not a little father, awlitted him; and come into\n",
            "me that is not his adointance, woman,\n",
            "I had it meet the time to all hibsely\n",
            "For contration. Thine eyem,\n",
            "Brothering the whole nostims?\n",
            "\n",
            "JULIET:\n",
            "He will should sow on.\n",
            "\n",
            "ROMEO:\n",
            "Nay, ruther comes hence, that skids you so she kingly you of\n",
            "this mustering. \n",
            "First Murderer:\n",
            "Condemn'd you, not my gan't world; despair\n",
            "I have in happy thrives of malice scorns,\n",
            "My father do that do I but bewn shadows,\n",
            "I'll fall for over was heart the other\n",
            "And been the beed have more from heathemiest:\n",
            "Thou husbann'd impatience, shall not\n",
            "have a shore of them veins, diemer that\n",
            "I cannot dust we becue to save\n",
            "The Lords, of gold Becknow hope: my takents of love\n",
            "Meanning my hator am he looks upon the whole.\n",
            "Here in smilones, even to draw mock thee face?\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "What, ho! I? that who,\n",
            "Stanley, I peas more particle! and moder more than woo\n",
            "My good lord, althat and thy shape was hungers to't.\n",
            "\n",
            "PETRUCHIO:\n",
            "Retumes a giand we last none bada: speak of her appronc \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.2126238346099854\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFjXg3FbLBDY",
        "is_executing": true,
        "outputId": "4630dc82-b6d7-4bf3-e2ae-8cb51e37c113"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nwhen he forgetsions you till?\\n\\nClown:\\nWe will answear the dete! more incline, kiss the other\\nRedain the thing and ride to move the times soft\\nWhich my fatter her brother Clifford, and, blunt show\\nWe shall have matter with the fride.'\\n\\nAUTOLYCUS:\\nI see there shall forget the mock he hast too,\\nWhom's point, inclanifated town, never sit\\nwith me begin the other like here almost Rovers:\\nMerely not to sweeter to in, and letters earm, I am fools,\\nAgainst our particaster! his!\\n\\nhere England's day no laster be entreated shadour tongues\\nAnd young Broken provokes above Green borne\\nI am do believe but to call me thinks,\\nSome lodgen names are committed to any horse:\\nUpon a hair! Do in the king: for whom you, know\\nMy shopon'd a loyal opacinuing:\\nThe wonders whose intent of honour, by ank you\\nSo less expeed my impose on's battle all the weeds on.\\nProvide me too late? forget my love!\\n\\nCLARENCE:\\nI'll see the light of flatesting earth to have out report\\nConsort chalitable; nuts, at home, he kindly.\\n\\nKI\"\n",
            " b\"ROMEO:\\nThat shall you need you gave upon my loss.\\n\\nPint Citizen:\\nWhat then? But you may?\\n\\nAll:\\nAlas, charge thee, my lord.\\n\\nKING RICHARD III:\\nCondemned all the conious voices. Who biddents, having discontented,\\nAnd that's good day that still, shall so;\\nFor you,\\nBy this with groomness shows along,\\nAs thou shalt answer home, how he flourished ensue\\nArt thousendly not, the sharper-store of this\\nWith all munished may prat you so much.\\n\\nVIRGILIA:\\n\\nRATLAND:\\nCouramorit the purchastes childly off, my salation\\nHath since dismasfering pale.\\n\\nKING RICHARD II:\\nMy Lord often I myself to hel;\\nAnd, girl. He, do abide her feederly.\\n\\nJULIET:\\nCall lover him shall I kiss my war.\\n\\nLUCENTIO:\\nBut say not, such a poor son, father, bless'd.\\n\\nLORD ROSS:\\nWe alle down he knows for a pwell,\\nThough all the ted of the lup-wards of thee\\nlies, that thou hast a solicity for thy son:\\nThe time hath left out which shall show out my bones\\nNe'er six. nay, your wives it quick\\nBeref to ancelt not how to make a war.\\n\\nKING RICHARD I\"\n",
            " b\"ROMEO:\\nPlay the lord hearing Romeo of her head\\nConfeit'st thou, sick; for he indeed shows as rust.\\n\\nLUCENTIO:\\nSir, your justice, look to Claren;\\nEfter of blood still, not to make heard you.\\n\\nAUTOLYCUS:\\nCondemn him my cap, she would come in? Condemn'd.\\nIt he will follwity though childing whores besome\\nThe dukes that thou quakest enemies to them\\nLike a trantle new is secretifidy\\nDo oh worthy years for protections very\\nTo come and therefore unnatural is all-end.\\n\\nFirst Citizen:\\nI may not know that hard more anmities\\nTo-morrow in disposing itself.\\nEven he of my daughterous ledge?\\n\\nKING EDWARD IV:\\nNo, not that strong to make use on hanchurcy;\\nAre you in sly, within this beast, sleeping forthward,\\nWho blost in howling at once.\\n\\nBAUTISTA:\\nI say the nobler is no beast; so sting, for one of down about,\\nNession, to come, you'll nothing.\\nYou, my lord, my marder was in oath.\\nPive it that shall be not inlex before,\\nI'll make fast, and runs it down that which ring.\\n\\nSecond Citizens:\\nHe shall not most unde\"\n",
            " b\"ROMEO:\\nDraw you, sweet Barnardine!\\nAnd that the rest and full of great hope, my lady,\\nAs loathships do grie he is gladly for a subject of such a day.\\n\\nLUCENTIO:\\nThis is their poace? look'd am.\\n\\nKING RICHARD II:\\nThis shall young men command the crown of who\\nearly. So chance to England, she empty to wait it.\\n\\nCAMILLO:\\nSleep stands from my say\\nShall shall you find mine end and draffly make is gone.\\n\\nKING RICHARD III:\\nMasters are other, and then you' so.\\n\\nCAMILLO:\\nNemed, my soul a sold harm for that:\\nspeak not thee, let me must with sin men,\\nIf this is some other easy of sight.\\n\\nFLORIZEL:\\nRomeo come.\\nShe indeed. She hath but most remain\\nTo wayed his doister. Then go blind with revenges.\\n\\nFirst Gentleman:\\nNow, Cithom, that he pass'd the sweeter fond.\\nMy lord I'll keep you to his mother! Isence\\nWe melt them both of love; he will be matter\\nAnd trats on lessions at the time of deaths not\\nThy advice here wrong'd now, shall you walk in no\\nrid, and sweet barness action on\\nAntiguants, and as he may be s\"\n",
            " b\"ROMEO:\\nBut I am nighty and here for your shants yourself\\nHave to royal tabet.\\n\\nLUCENTIO:\\nTell me, on the duke of laste; my love, that stand\\nSo till these, by sir; to shall you is undertake\\nToo young young Richmond!\\nI lare two hand of books, and leave air hand,\\nAmen to them that. Show his majesty,\\nOur sorrow pale as abuspass of my free\\nTicl't then with this before for from Lucentio's head;\\nHast thou so?' of Rovers have lester thence\\nBy all oppinctions, with such down what fish of my behald\\nAll bosom hid when he did speak nothing\\nWhere you shad resolved OF France:\\nLet this be some peason letters on\\nhan me so! But To part me, im mean toward?\\n\\nDUKE VINCENTIO:\\nKnow, that from me at none of death may never.\\n\\nISABELLA:\\nServen: thou vill't my father.\\n\\nLADY ANNE:\\n'Tis more\\nThan thus speak altrication to care,\\nDispetiberient hence, their harms from the hollow\\nWalt made at the numbiol; though I'll play him, as I am speak'st\\nThy gravingly shallow intoly lies:\\nBestraw you on your husband? Let him be maje\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.385995626449585\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHn6chtuLBGb",
        "is_executing": true,
        "outputId": "e12e19b3-af55-406c-dcfe-03760cb222d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f98a71250f0>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "# Ekspor Model Generator\n",
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPK7sY1OLBJ0",
        "is_executing": true,
        "outputId": "2c93995f-1010-4434-9a63-6f1f20e5db13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Draw, nor wars? what, little rest, ensies down from the verge\n",
            "Our hatred hath needs, or how he ofte\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "lavfFZoz63t-"
      },
      "source": [
        "**TUGAS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "I0jvdFS563t-",
        "is_executing": true
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        "    @tf.function\n",
        "    def train_step(self, inputs):\n",
        "        # Unpack inputs\n",
        "        inputs, labels = inputs\n",
        "\n",
        "        # Use GradientTape to compute gradients\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = self.loss(labels, predictions)\n",
        "\n",
        "        # Compute gradients and apply them using optimizer\n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "\n",
        "        # Return a dictionary with the loss for monitoring\n",
        "        return {'loss': loss}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5Lc5MS0m63t_"
      },
      "source": [
        "Kode di atas menerapkan metode `train_step` sesuai dengan konvensi `train_step` dalam Keras. Meskipun bersifat opsional, tetapi pendekatan ini dapat untuk menyesuaikan perilaku langkah pelatihan sambil tetap menggunakan metode `compile` dan `fit` dari model Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_BjyNdn63t_",
        "is_executing": true,
        "outputId": "5e43d43b-7937-49f9-baf7-e9b4259ad2a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 13s 54ms/step - loss: 2.7197\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f986dd097e0>"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model custom training\n",
        "model = CustomTraining(\n",
        "     vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "     embedding_dim=embedding_dim,\n",
        "     rnn_units=rnn_units)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_function = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=optimizer, loss=loss_function)\n",
        "\n",
        "# Training dataset\n",
        "epochs = 1\n",
        "model.fit(dataset, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "POEss_ne63t_"
      },
      "source": [
        "Atau jika ingin lebih mengetahui dalamnya, kita bisa membuat custom training loop sendiri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRIBVZbN63t_",
        "is_executing": true,
        "outputId": "7dfd4007-251a-4e32-95f9-3f6e2c8b880a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1636\n",
            "Epoch 1 Batch 50 Loss 2.0160\n",
            "Epoch 1 Batch 100 Loss 1.9310\n",
            "Epoch 1 Batch 150 Loss 1.8849\n",
            "\n",
            "Epoch 1 Loss: 1.9884\n",
            "Time taken for 1 epoch 11.82 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.7970\n",
            "Epoch 2 Batch 50 Loss 1.7763\n",
            "Epoch 2 Batch 100 Loss 1.6790\n",
            "Epoch 2 Batch 150 Loss 1.6709\n",
            "\n",
            "Epoch 2 Loss: 1.7106\n",
            "Time taken for 1 epoch 10.35 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.6104\n",
            "Epoch 3 Batch 50 Loss 1.5943\n",
            "Epoch 3 Batch 100 Loss 1.5675\n",
            "Epoch 3 Batch 150 Loss 1.5169\n",
            "\n",
            "Epoch 3 Loss: 1.5498\n",
            "Time taken for 1 epoch 11.27 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4895\n",
            "Epoch 4 Batch 50 Loss 1.4622\n",
            "Epoch 4 Batch 100 Loss 1.4680\n",
            "Epoch 4 Batch 150 Loss 1.4238\n",
            "\n",
            "Epoch 4 Loss: 1.4509\n",
            "Time taken for 1 epoch 11.30 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3779\n",
            "Epoch 5 Batch 50 Loss 1.4111\n",
            "Epoch 5 Batch 100 Loss 1.3758\n",
            "Epoch 5 Batch 150 Loss 1.4249\n",
            "\n",
            "Epoch 5 Loss: 1.3820\n",
            "Time taken for 1 epoch 48.05 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.2971\n",
            "Epoch 6 Batch 50 Loss 1.3222\n",
            "Epoch 6 Batch 100 Loss 1.3731\n",
            "Epoch 6 Batch 150 Loss 1.3221\n",
            "\n",
            "Epoch 6 Loss: 1.3306\n",
            "Time taken for 1 epoch 10.40 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2929\n",
            "Epoch 7 Batch 50 Loss 1.2582\n",
            "Epoch 7 Batch 100 Loss 1.3189\n",
            "Epoch 7 Batch 150 Loss 1.2648\n",
            "\n",
            "Epoch 7 Loss: 1.2853\n",
            "Time taken for 1 epoch 11.24 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2252\n",
            "Epoch 8 Batch 50 Loss 1.2266\n",
            "Epoch 8 Batch 100 Loss 1.2671\n",
            "Epoch 8 Batch 150 Loss 1.2565\n",
            "\n",
            "Epoch 8 Loss: 1.2446\n",
            "Time taken for 1 epoch 11.26 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1771\n",
            "Epoch 9 Batch 50 Loss 1.2074\n",
            "Epoch 9 Batch 100 Loss 1.1979\n",
            "Epoch 9 Batch 150 Loss 1.2289\n",
            "\n",
            "Epoch 9 Loss: 1.2042\n",
            "Time taken for 1 epoch 10.59 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1370\n",
            "Epoch 10 Batch 50 Loss 1.1527\n",
            "Epoch 10 Batch 100 Loss 1.1895\n",
            "Epoch 10 Batch 150 Loss 1.1941\n",
            "\n",
            "Epoch 10 Loss: 1.1643\n",
            "Time taken for 1 epoch 39.58 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "# Training loop over epochs\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    # Reset the mean metric for each epoch\n",
        "    mean.reset_states()\n",
        "\n",
        "    # Iterate over batches in the dataset\n",
        "    for batch_n, (inp, target) in enumerate(dataset):\n",
        "        # Perform a training step and get the loss\n",
        "        logs = model.train_step([inp, target])\n",
        "\n",
        "        # Update the mean metric with the current batch loss\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        # Print batch loss every 50 batches\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "        # Save (checkpoint) the model every 5 epochs\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    # Print epoch loss and time taken\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\" * 80)\n",
        "\n",
        "# Save the final model weights after all epochs\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Perbedaan dengan praktikum 2:**\n",
        "\n",
        "Pada Praktikum 2, digunakan pendekatan pelatihan yang lebih umum dan sederhana dengan metode model.fit yang sudah terintegrasi dengan TensorFlow. Metode ini mengelola sebagian besar aspek pelatihan, seperti perhitungan loss, perhitungan gradien, dan pembaruan bobot model secara otomatis.\n",
        "\n",
        "Sementara itu, pada kode tugas praktikum, diterapkan pendekatan pelatihan yang lebih spesifik dan kompleks. Dalam pendekatan ini, terdapat definisi metode train_step dalam model turunan yang mengatur dengan jelas perhitungan loss, perhitungan gradien, dan pembaruan bobot model. Selain itu, objek tf.metrics.Mean digunakan untuk menghitung rata-rata loss selama pelatihan. Pendekatan ini memberikan lebih banyak kemampuan untuk mengendalikan dan menyesuaikan pelatihan model, yang sangat berguna untuk tugas-tugas yang membutuhkan penyesuaian yang spesifik. Dengan demikian, perbedaan utama terletak pada tingkat kontrol yang lebih tinggi dan lebih banyak opsi kustomisasi dalam pendekatan pelatihan pada tugas praktikum."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
