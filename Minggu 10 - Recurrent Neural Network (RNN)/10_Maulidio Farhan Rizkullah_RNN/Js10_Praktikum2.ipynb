{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### Setup"
      ],
      "metadata": {
        "id": "HPX66gDbvaqG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve0qle0LvIid"
      },
      "outputs": [],
      "source": [
        "# import library\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendapatkan path file untuk dataset Shakespeare dari URL\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYRQEgogyj5w",
        "outputId": "5e74493f-c9c1-4f81-b3e0-55c8410c1ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load Data"
      ],
      "metadata": {
        "id": "4cKc0dTWynub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca isi file dan mendekodekannya sebagai teks dengan encoding utf-8\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# Mencetak panjang teks dalam karakter\n",
        "print(f'Length of text: {len(text)} characters')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2eJzaQiypr4",
        "outputId": "a1a3b713-614d-4abb-c932-1eeec3ffdacc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mencetak 250 karakter pertama dari teks\n",
        "print(text[:250])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4t2AMl-y4vF",
        "outputId": "1855b42c-18f2-4981-8d51-0d163e2ee187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat kamus dari karakter unik dalam teks dan mengurutkannya\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "# Mencetak jumlah karakter unik dalam teks\n",
        "print(f'{len(vocab)} unique characters')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noGB_wl5zDQh",
        "outputId": "765115e5-c58c-4ed0-80c2-e2a05dc7d76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Olah Teks"
      ],
      "metadata": {
        "id": "gtt19HcfzGQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vectorize Teks"
      ],
      "metadata": {
        "id": "36jhNwhRzIil"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Memecah teks contoh menjadi karakter-karakter menggunakan Unicode split\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "\n",
        "# Menampilkan hasil pemecahan karakter\n",
        "chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jT1uGmV2zL2z",
        "outputId": "3b6a7d7a-5147-4c4a-c15a-417a2cb38c75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat layer StringLookup untuk mengonversi karakter menjadi ID\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab),\n",
        "    mask_token=None\n",
        ")\n"
      ],
      "metadata": {
        "id": "Jw5A59ktzUzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan layer StringLookup untuk mengonversi karakter menjadi ID\n",
        "ids = ids_from_chars(chars)\n",
        "\n",
        "# Menampilkan hasil konversi\n",
        "ids\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0a6Lcggzd8-",
        "outputId": "92196b6e-f1f1-4032-c2c6-79cf02a856d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat layer StringLookup untuk mengonversi ID kembali menjadi karakter\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(),\n",
        "    invert=True,\n",
        "    mask_token=None\n",
        ")\n"
      ],
      "metadata": {
        "id": "dT7i7udFznxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan layer StringLookup untuk mengonversi ID kembali menjadi karakter\n",
        "chars = chars_from_ids(ids)\n",
        "\n",
        "# Menampilkan hasil konversi\n",
        "chars\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqiB1bhFzs4L",
        "outputId": "73f9b15e-8f71-4f4b-8e86-9132e4ba64d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan tf.strings.reduce_join untuk menggabungkan karakter-karakter kembali menjadi teks\n",
        "tf.strings.reduce_join(chars, axis=-1).numpy()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3e8vnYEz0Ak",
        "outputId": "d1fe5453-de2d-4530-90e4-8a7312903c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan fungsi untuk mengonversi ID kembali menjadi teks\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
      ],
      "metadata": {
        "id": "cjSZvUH2z5u3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediksi"
      ],
      "metadata": {
        "id": "JqTfnFKoz8EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan layer StringLookup untuk mengonversi semua karakter dalam teks menjadi ID\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "\n",
        "# Menampilkan hasil konversi\n",
        "all_ids\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_8uxGqbz-ok",
        "outputId": "b4be3eef-a9bd-4fec-b2e3-6567d3c443fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat dataset dari tensor ID\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)\n"
      ],
      "metadata": {
        "id": "VNsi2uIB0ad0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan karakter-karakter pertama dalam 10 tensor ID\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKpwapXu0e8N",
        "outputId": "d0ac6881-dca3-49c3-a06b-c968449ba912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan panjang urutan yang diinginkan\n",
        "seq_length = 100"
      ],
      "metadata": {
        "id": "s9WLIZZG0g-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat urutan dari dataset dengan panjang yang ditentukan\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "# Menampilkan urutan karakter pertama dalam satu batch\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbfFo6TH0jVT",
        "outputId": "c84f6213-0f9b-4c9a-d8fc-a6bd227d0813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan teks dari lima urutan pertama\n",
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3wN60OM0m0w",
        "outputId": "18dfbc33-4fde-41c1-91bd-412bb27ce378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan fungsi untuk membagi input dan target dari suatu urutan\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text\n"
      ],
      "metadata": {
        "id": "RvdoS_cx1Lcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memanggil fungsi pada contoh urutan\n",
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1tlFwhn1N48",
        "outputId": "d2496952-850a-44f1-8cc2-e784adcdd0d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Membuat dataset dari urutan dengan input dan target yang terpisah\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "01Yi1OWj1Pe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan contoh input dan target dari dataset\n",
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvLq6pAc1RVn",
        "outputId": "fcfc0387-e58c-4b07-9339-6631e8c46f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Batch Training"
      ],
      "metadata": {
        "id": "E1rjvsnc1XbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ukuran batch\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Ukuran buffer untuk mengacak dataset\n",
        "# (TF data dirancang untuk bekerja dengan urutan yang mungkin tak terbatas,\n",
        "# sehingga tidak mencoba untuk mengacak seluruh urutan dalam memori. Sebaliknya,\n",
        "# ia menjaga buffer di mana ia mengacak elemen).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Membuat dataset dengan mengacak, mengelompokkan, dan memuat dengan prefetch\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "# Menampilkan dataset\n",
        "dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7sjgYxB1ZE6",
        "outputId": "5548006d-fdd6-484d-c81d-446b58966109"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Buat Model"
      ],
      "metadata": {
        "id": "5mYZg17D1uyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Panjang kamus dalam layer StringLookup\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# Dimensi embedding\n",
        "embedding_dim = 256\n",
        "\n",
        "# Jumlah unit RNN\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "YjHOJ9tr1wui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan kelas model yang merupakan turunan dari tf.keras.Model\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    # Lapisan embedding untuk mengonversi ID menjadi vektor embedding\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    # Lapisan GRU (Gated Recurrent Unit) untuk pemrosesan urutan\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    # Lapisan Dense untuk menghasilkan output final\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    # Melakukan embedding pada input\n",
        "    x = self.embedding(x, training=training)\n",
        "    # Mendapatkan nilai awal state GRU jika tidak ada\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    # Melakukan proses GRU pada urutan input\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    # Melakukan lapisan Dense pada hasil GRU\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    # Mengembalikan hasil dan state jika diperlukan\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "-_q2r_v42UA0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat objek model menggunakan kelas yang telah didefinisikan\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "mt99HVB62W-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Uji Model"
      ],
      "metadata": {
        "id": "IEnQQogt2bxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan prediksi pada satu batch contoh input dari dataset\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0digWdu82d4H",
        "outputId": "ee9cc58c-2ccd-4484-cb42-d749896c642b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan ringkasan arsitektur model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Xm7-9u129Zm",
        "outputId": "372fe063-0896-4064-a4e1-268a96e02c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghasilkan indeks teracak dari distribusi prediksi\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "cVXvHtFl2_al"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yt4Uf-4c3F3S",
        "outputId": "6dc1e9e6-55fa-4a05-82cf-ffb533ccf162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([51, 16, 42,  2,  5,  7, 39,  9, 58, 52, 64, 50,  6, 42, 50, 51,  8,\n",
              "       15, 35,  9, 61, 33, 15, 42, 45, 36, 41, 23,  4, 30, 42, 16, 54, 30,\n",
              "       32, 26, 36, 25,  7, 32, 54, 44, 43, 52, 63, 58,  3, 50, 22, 20, 39,\n",
              "       20, 37, 42, 44,  1, 43, 16, 43, 32, 40, 22, 43, 57, 13,  9, 41, 57,\n",
              "       23, 14, 39,  7, 15, 21, 22, 11, 41,  8, 38, 65,  7, 20, 63, 56, 56,\n",
              "        8, 37,  3, 15, 16, 63, 47, 64, 44, 61, 45, 25, 48, 29, 21])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menampilkan contoh input dan prediksi karakter berikutnya\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF_oEQiX3Icp",
        "outputId": "d4cb26a1-7f56-4127-9214-d70e2a2bc784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'irror\\nWhich shows me mine changed too; for I must be\\nA party in this alteration, finding\\nMyself thus'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"lCc &,Z.smyk'ckl-BV.vTBcfWbJ$QcCoQSMWL,Soedmxs!kIGZGXce\\ndCdSaIdr?.brJAZ,BHI:b-Yz,Gxqq-X!BCxhyevfLiPH\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train Model"
      ],
      "metadata": {
        "id": "xEFS4gid3Qlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menambahkan optimizer dan fungsi loss"
      ],
      "metadata": {
        "id": "1c5nyZzW3TQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menggunakan SparseCategoricalCrossentropy sebagai fungsi loss\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "dUqkSIRn3W7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung rata-rata loss pada contoh batch\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0xt6qNl3uIW",
        "outputId": "114c7076-0cfb-48c0-9ad9-7d0aed5a8d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.190125, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menghitung eksp dari rata-rata loss\n",
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng4Z5Rsq3vrS",
        "outputId": "ffb90dc1-97b1-467f-fcac-99495afebdc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.031044"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengompilasi model dengan optimizer Adam dan fungsi loss SparseCategoricalCrossentropy\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "dmJwKZ3F3xXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasi Checkpoints"
      ],
      "metadata": {
        "id": "QWtC0B9930hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Direktori tempat checkpoint akan disimpan\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Nama file checkpoint\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "# Callback untuk menyimpan checkpoint\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n"
      ],
      "metadata": {
        "id": "_FWjTPEe3-d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melakukan Proses Training"
      ],
      "metadata": {
        "id": "Q2w3_co64UPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jumlah epoch\n",
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "e1yD44vP50Vi"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model dengan dataset dan menyimpan checkpoint\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atax3AX162yM",
        "outputId": "75ac69a6-1c9c-4799-aa9b-1ab121ccf7fc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 15s 61ms/step - loss: 2.7271\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.9869\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.7092\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 14s 62ms/step - loss: 1.5500\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 1.4527\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 1.3854\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 1.3341\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 1.2899\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 1.2486\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 15s 61ms/step - loss: 1.2099\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 14s 63ms/step - loss: 1.1697\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.1288\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 1.0858\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.0408\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.9922\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 0.9428\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 0.8903\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 0.8381\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 0.7872\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 0.7380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generate Teks"
      ],
      "metadata": {
        "id": "ZUcd_-Zw64GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan kelas untuk menghasilkan teks satu langkah pada waktu inferensi\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Membuat mask untuk mencegah \"[UNK]\" dari dihasilkan.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Menempatkan -inf pada setiap indeks yang buruk.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Sesuaikan bentuk dengan vokabulari\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Mengonversi string ke token ID.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Menjalankan model.\n",
        "    # predicted_logits.shape adalah [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Hanya menggunakan prediksi terakhir.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Menerapkan mask prediksi: mencegah \"[UNK]\" dari dihasilkan.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Mengambil sampel dari logits output untuk menghasilkan token ID.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Mengonversi dari token ID menjadi karakter\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Mengembalikan karakter dan state model.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "NjZTtwvh7Cqw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat objek model untuk inferensi satu langkah waktu\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "Hr-50SU06yVv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menjalankan inferensi pada satu contoh teks awal\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)\n"
      ],
      "metadata": {
        "id": "DcPm77DM50PS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4948f10-89f8-4cce-b70f-ec42f03a0afb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Spakes: upon pala head o' the streets,\n",
            "And every thing is here with chronators?\n",
            "But widow Dido' a ballad applars that late heart's o'ly finger?\n",
            "All must our horsion has a treacherous land Isabel,\n",
            "I am too good for thee:--GONZALO:\n",
            "I'll cry, God sleep wid is not comes.\n",
            "\n",
            "SLY:\n",
            "No, not in living adist: O, the news\n",
            "I have a torgued father, die my back.\n",
            "\n",
            "VIRGILIA:\n",
            "None else, we stand alone, see another seck\n",
            "Of the parties of certain dropsinds.\n",
            "\n",
            "ROMEO:\n",
            "We prove honest win that all abroad old steel,\n",
            "With rained harbon his plother's love, the beauty was repair,\n",
            "being but two scrupul of those hateful accest\n",
            "how upon his country: this is sick for adile;\n",
            "His adory Katharina to make a life\n",
            "And holy charges me which indeed ere I chan a three.\n",
            "\n",
            "Second Citizen:\n",
            "We have fought with unterroplested language!\n",
            "That he did ne'er revenge for, as she would say.\n",
            "3 KING HENRY VI\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Thus far as load as he was married any Juliet.\n",
            "\n",
            "RIVERS:\n",
            "O, wrapp'd and worldly thou hast emproving me?\n",
            "No, no the tr \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.7307441234588623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menjalankan inferensi pada beberapa contoh teks awal\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uXzC3TZ7PPT",
        "outputId": "e07a2a88-37d0-491b-f0bd-dc6f382a7ed2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nThese tempted men that thou hast spoke, world's rage\\nUpon the single sous wife any harm.\\n\\nLADY CAPULET:\\nThe chaplain of the Martal'st December man\\nI say, and scarr'd the delight walls;\\nAnd by and by: this is the quarrel that I did: it\\nhath best said, sir, if it be best one--I can be shere,\\nWish warmous is deward him in the tooth.\\n\\nHASTINGS:\\nI thank you, on my woman away a letter, thou\\nshalt resinus? what end what heavens! Who's there?\\n\\nThird Citizen:\\nTush, your amilias mould upon them,--\\n\\nMENENIUS:\\nAs Surran, Percy, and by tribunes.\\n\\nSICINIUS:\\nThe fighting\\nHer she to sundering on the store,\\nWho tamest on common nature, as he does.\\n\\nMARIANA:\\nGood my liege, my messenger,\\nI know not what? I think you are in last?\\n\\nKING EDWARD IV:\\nWhy stoop not 'gainst all measure us,\\nThe glorious world will rushe your cousins. This,\\nLet it not so, farewell. What, with\\nthe unlief and faint--'Side is changed to speak.\\nWear me, marry, that I am her away to love,\\nIs turns at home.\\n\\nCAMILLO:\\nO my lord, your s\"\n",
            " b\"ROMEO:\\nIs this stand and nake?\\n\\nPETRUCHIO:\\n\\nPedant:\\nSoft! what's your worship?\\n\\nLUCENTIO:\\nI rause a boy of such a cause born out of the time;\\nFor accept of him, hath you a gentleman.\\n\\nNurse:\\nThus, with fives whose usland sworn brow return,\\nAnd both rigging in this house and horse;\\nTo thee agone in blood,\\nwind pain is molelier ppockety, that most kindly,\\nThou camest, for he looks curksuit! how use this ancient courage?\\nWhere on his use, his lord, they are going.\\n\\nLUCENTIO:\\nBraces and the firation of faults of one rich in me\\nTo help him, I have thrown by the holy of his\\nfriends; that lives in these falsely of my poor appointmach,\\nProcured you much austifely fond our heads.\\n\\nDebelish estames and your office.\\nWhate'er it begins. Thou hast news in Pourtial cheek to-night:\\nBetter you come to them above, that makest her\\never so do use it in their foes,\\nAnd bad remains, with this so swift as shame.\\nWhere is the casque hasty together!\\nAnd not my father's curse in hand: nothing\\nSo against him, indeed,\"\n",
            " b\"ROMEO:\\nThis wide as you shall not come ashore I was adoke,\\nLest dead before you with their helling blood.\\n\\nROMEO:\\nWith Retur doghty from his hands hidesp'd,\\nWith politing in worldly servants, fairly marriage,\\nThat aching you our course; yet thou knowest she\\nThe devil's dam now in deadly voices together\\nThe hate whose names are forklain.\\n\\nLADY ANNE:\\nThat's too then do quittee, you bid thee not; but then\\nyou tell me of, I desire by murderous\\nHe is not ignorance to such a thought of ins\\nThe state of other ear not. Come, brothers is of all.\\n\\nHENRY BOLINGBROKE:\\nUsurpusious.\\n\\nESCALUS:\\nCome, is the world will follow.\\n\\nWARWICK:\\nAnd from my soul is much like up, 'twere not\\nsometimes than foot at secret master were\\nNor the fawn turney of unnatulack to thee.\\n\\nWARWICK:\\nRichard hath he is so, yet he was pinied in this\\nofficer; both out of his light and yoker free thousand,\\nBut 'tis nob long. What\\nsay'st thou, man? how is't with her?\\n\\nOXFORD:\\nWhy, vengeance forget you: but something\\nYour head o' the gatte\"\n",
            " b\"ROMEO:\\nBloody will prove honour thine-faced\\nWhose paties and confessor, Warwick prayed by thee,\\nBy being as harfly to thee again.\\n\\nGREEN:\\nIs wicked me: the other through these wounds\\nApollow'd the goose.\\n\\nHORTENSIO:\\nVery well; and thy fond father had but a petty good\\nGod depart and lay on; my dearests-hard ripeous sent\\nOf that he was honest of it. I warrant their love!\\nOr silk I being not a certain drops:\\nTherefore your purse as you, with hasty tender of my mig-needlors,\\nBut Romeo has with me into tradeless, and\\nfor thy days with thee: a man as stranger,\\nthough ne'er shalt kill thy thoughts affecting?\\nDie I aches and mock'd their vester will be our\\nof; one that as hostility: but we two\\nwho is sweetery. When you should have\\nMad so near a worldran of extempt, that knock not\\nThat all his lasting love far brawling overboard.\\n\\nPETRUCHIO:\\nWhy, farewell; I am thus I think there's nothing finger.\\nBut look'd-poor house such gentle scaps allestime.\\n\\nCLARENCE:\\nAre you my mast redemption of himself Your\"\n",
            " b\"ROMEO:\\nIf that can beet humour'd by the bust day does in the middle\\nof her an hour; and yours. They much of our dear Rutland's tortures,\\nAnd to these bloody would not look for thee.\\n\\nCLARENCE:\\nMy Lord of Warwick, Warwick, hath all the vows\\nWe have caused the spirits of Rome and hither\\nAnd these whom thou so marr'd them now.\\n\\nBUCKINGHAM:\\nWell, let's about deposed; being rison,--\\nAs you and you shall harden strong a man.\\n\\nFRIAR LAURENCE:\\nFair scarce can contract, and paper all, devise\\nThe reasons where against our husbands wept,\\nTo report it, widow nor no other escape,\\nThe commonwealty be asleep; the words again.\\n\\nEDWARD:\\nNow in good sir; for thyself have made a woman\\nMastards day do what we patient, then they seek you;\\nCome quite, from fast; 'tis three no mourner, all ignorance,\\nAnd troops of that aboand misfortune lives\\nIn earnest in a holy knaviop'er in our counce:\\nMy queen, you bow? the crown is talk'd?\\n\\nVALERIA:\\nBut for where is the queen?\\n\\nHENRY PERCY:\\nMy lord, with holy royalty, thou se\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.322404146194458\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ekspor Model Generator"
      ],
      "metadata": {
        "id": "yi0cJNTg77rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menyimpan model satu langkah waktu sebagai SavedModel\n",
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "\n",
        "# Memuat model kembali\n",
        "one_step_reloaded = tf.saved_model.load('one_step')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY0yrwDH7-El",
        "outputId": "2365804d-34a8-4a35-c65e-156244ca6a0d"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x787d804c0520>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menjalankan inferensi pada model yang dimuat kembali\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "# Mencetak teks hasil inferensi\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I82jZJN47_4T",
        "outputId": "5ea971c1-b03d-42c1-d1fd-afdaf195cc11"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Clarater Slain no less; but with this new grass how\n",
            "He could gurst they bally doth beg the servants\n"
          ]
        }
      ]
    }
  ]
}