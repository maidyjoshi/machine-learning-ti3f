{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9ChVZMWFfIJi"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7Ufw4eogTKz",
        "outputId": "24bf79ac-447e-4134-fb9a-d208a2eee29a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Mendapatkan path file untuk dataset Shakespeare dari URL\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe56lNK4gaRy",
        "outputId": "07cc55dd-7e17-4a68-d0d0-cb6f4a9b4562"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# membaca, lalu mendekode konten tersebut dari binary menjadi string menggunakan encoding ‘utf-8’\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# mencetak jumlah karakter dalam teks tersebut\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ld_RB2XBgcxB",
        "outputId": "19450d21-ba2b-472a-8eaf-cdf54df04d41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mencetak 250 text pertama\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZbUPCSHge1J",
        "outputId": "93fdb5f9-cf10-4404-8414-36f86b1491b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# mencari jumlah karakter unik dalam teks\n",
        "vocab = sorted(set(text)) # mengubah teks menjadi set untuk menghilangkan duplikat\n",
        "print(f'{len(vocab)} unique characters') # mencetak jumlah karakter unik dalam teks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cabsr4hoggsr",
        "outputId": "25f8738c-4582-4a26-ec61-ca576e22b61f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz'] # mendefinisikan list string yang akan diproses\n",
        "chars = tf.strings.unicode_split (example_texts, input_encoding='UTF-8') # membagi setiap string dalam example_texts menjadi list karakter\n",
        "chars # mencetak hasil dari operasi split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_whzGVvSgsOq",
        "outputId": "0a702b46-ceec-42b5-f0c8-c1a9747fba09"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# membuat instance dari layer StringLookup dengan vocabulari yang ditentukan oleh vocab\n",
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None) \n",
        "\n",
        "ids = ids_from_chars(chars) # mengubah chars menjadi indeks integer menggunakan ids_from_chars\n",
        "ids # mencetak array indeks integer yang mewakili chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Nt6_5_8g40d",
        "outputId": "07ae3822-b9e8-4bf7-a436-9768e281a10f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# membuat instance dari layer StringLookup dengan vocabulari yang ditentukan oleh ids_from_chars.get_vocabulary()\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "chars = chars_from_ids(ids) # mengubah ids kembali menjadi karakter menggunakan chars_from_ids\n",
        "chars # mencetak array karakter yang mewakili ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUya3pY_hEyk",
        "outputId": "bd866d37-25ef-4af6-eeff-012c4b3cfe68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy() # menggabungkan elemen-elemen dalam array chars menjadi string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ok1mT2uahJlM",
        "outputId": "1d118564-5d31-46a3-c47f-1e345d4b232c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Membuat fungsi mengubah list indeks integer kembali menjadi string\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n",
        "\n",
        "# membagi teks menjadi list karakter dan hasilnya disimpan di variabel all_ids\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNNwjNF7hYwo",
        "outputId": "effd4029-f68f-4a51-b58a-56f6f3ec3fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids) # membuat tf.data.Dataset dari all_ids\n",
        "\n",
        "# Menampilkan karakter-karakter pertama dalam 10 tensor ID\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbgiZAWXhklY",
        "outputId": "c9420281-3d02-45a5-c43c-5505f6aec120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Menentukan panjang urutan yang diinginkan\n",
        "seq_length = 100\n",
        "\n",
        "# Membuat urutan dari dataset dengan panjang yang ditentukan\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "# Menampilkan urutan karakter pertama dalam satu batch\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9eqk5swhsF4",
        "outputId": "f19c0821-6f6a-4cd9-9041-995eca1dba12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan teks dari lima urutan pertama\n",
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsjQf05XhwPZ",
        "outputId": "d8457d24-934c-4a19-daa3-2af5f746a1e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "# Mendefinisikan fungsi untuk membagi input dan target dari suatu urutan\n",
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "split_input_target(list(\"Tensorflow\")) # Memanggil fungsi pada contoh urutan\n",
        "\n",
        "dataset = sequences.map(split_input_target) # Membuat dataset dari urutan dengan input dan target yang terpisah\n",
        "\n",
        "# Menampilkan contoh input dan target dari dataset\n",
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu63AoPMiNmp",
        "outputId": "db8106c5-77e8-4278-dbe5-a8d0c94930fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ukuran batch\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Ukuran buffer untuk mengacak dataset\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Membuat dataset dengan mengacak, mengelompokkan, dan memuat dengan prefetch\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset # Menampilkan dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lozXl8JNi5OI"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024\n",
        "\n",
        "# Mendefinisikan kelas model yang merupakan turunan dari tf.keras.Model\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x\n",
        "\n",
        "# Membuat objek model menggunakan kelas yang telah didefinisikan\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Df2-7qLgi9Bn",
        "outputId": "1939f9fc-8c43-4555-f2fa-1df56b295d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n",
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Melakukan prediksi pada satu batch contoh input dari dataset\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n",
        "\n",
        "model.summary() # Menampilkan ringkasan arsitektur model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS-QVUnIjUFv",
        "outputId": "3cac00c7-d240-4524-f54c-61a911edc84e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'ding\\nThat changeth thus his manners.\\n\\nCAMILLO:\\nI dare not know, my lord.\\n\\nPOLIXENES:\\nHow! dare not! '\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"wIDUIH'sOJvM\\nr.RVeeJiLUl'3\\ns[UNK]AqvZZ:EsJpTNZWS:HdtnlIABv'bwhhcaYKUornRGZ;NgsxnaR[UNK]-d[UNK]PdXO; pamFY--\\nGPuY\"\n"
          ]
        }
      ],
      "source": [
        "# Menghasilkan indeks teracak dari distribusi prediksi\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
        "\n",
        "sampled_indices\n",
        "\n",
        "# Menampilkan contoh input dan prediksi karakter berikutnya\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK9Rp3XHjg5Y",
        "outputId": "b93e7087-4dd2-49a6-e917-b01b50b6a323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1894326, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Menggunakan SparseCategoricalCrossentropy sebagai fungsi loss\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Menghitung rata-rata loss pada contoh batch\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgwJaVd5juls",
        "outputId": "541b87dd-6ab9-4954-c34b-51431a4be0a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65.985344"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menghitung eksp dari rata-rata loss\n",
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UhlLnrFYjx-E"
      },
      "outputs": [],
      "source": [
        "# mengkompilasi model dengan menentukan optimizer dan fungsi loss\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRTtVSP4j73_",
        "outputId": "02af3a03-ddc1-490c-9101-3e86213f9bbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 15s 55ms/step - loss: 1.5197\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 13s 56ms/step - loss: 1.4316\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.3686\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.3186\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.2748\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.2345\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 1.1951\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 1.1547\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.1134\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.0697\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.0235\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.9742\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.9218\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.8699\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.8163\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 0.7649\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.7182\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.6733\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.6340\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.6013\n"
          ]
        }
      ],
      "source": [
        "# mendefinisikan direktori di mana checkpoint akan disimpan\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "# mendefinisikan prefix untuk nama file checkpoint\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "# membuat callback ModelCheckpoint yang akan menyimpan bobot model ke file checkpoint setelah setiap epoch\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)\n",
        "\n",
        "EPOCHS = 20 # mendefinisikan jumlah epoch\n",
        "\n",
        "# melatih model dengan dataset yang ditentukan selama jumlah epoch yang ditentukan, dan menyimpan bobot model setelah setiap epoch\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "M7P565nSnMAr"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states\n",
        "\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnwfdWUJnYvs",
        "outputId": "c5b07d02-1fc9-4e79-9dd0-e6f115797ec4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "The utterance of the luminable and cheques\n",
            "Rome to me than one coats and beat two more stones\n",
            "In unewering name myself exactly,\n",
            "It shall be freely pompetual wit\n",
            "demanded; what with our ready sorrow?\n",
            "\n",
            "ANGELO:\n",
            "You say your days o' the conquerors.\n",
            "\n",
            "MENENIUS:\n",
            "The worthy leggards, this endured men sir: you may attend our guests,\n",
            "Lozed takes, the city begins to die.\n",
            "\n",
            "KING RICHARD II:\n",
            "An if what horse is our confess restruity.\n",
            "First would you have broken from him, dear sin's presence\n",
            "Through't with that word 'banishe'l'd in one light,--\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Go, fool! why, An if she be opentry,' then,\n",
            "By deep in cellowing were true. Take my meaning\n",
            "The country's friend. You shall my words\n",
            "With words that cannot be corression with\n",
            "with the heavens to the last.\n",
            "\n",
            "ESCALUS:\n",
            "ETward with me: beseech you, tell: be calm\n",
            "His glad to vessel those bastards.\n",
            "\n",
            "GLOUCESTER:\n",
            "This island goes had been many-gentle Lad Anny\n",
            "The childress when the boar will pray their fortune soundly.\n",
            "\n",
            "Volsce:\n",
            "I am a quarrel sore in  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.3832337856292725\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Z9mmpkwncgz",
        "outputId": "25b444a7-012f-40ab-bbe7-4421404d487a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nThe own particular shame with slain:\\nAnd yet I warrant her; Duly obedience,\\nHaving no more of thif; and it had so dear,\\nAnd I forefore we speak no more. I'll be miled.\\n\\nYORK:\\nWhat is the news whom thou wert sworn too well?\\nI mean, in Vienna, sir.\\n\\nSEBASTIAN:\\nAy, what a miserable hure these roared\\nThey are both broken soft! how loves no reason\\nAs Pehelo's to crave, and for your days,\\nTo prive the taste in famous moes,\\nThere shall not proceed to wail invectives,\\nAnd never will it tetchy high her naturally permit?\\nUnch-vouch, of you have one\\nAn aught roubling their hearts attended,\\nTo make his foundant in steel,\\nAnd these decless from his son are old men,\\nAnd give I believe me, this prevails, we must strange,\\nI cannot lour' to knowly. If\\nMarch'd with this delivery? let's still a rark;\\nBut, soft! what a little thing I saw her,\\nAgainst the holour unto my foes,\\nAnd take the sclittle grave of our morance, which\\nThey are bound in guared beating more.\\n\\nMIRCASTIAN:\\nGod keep your instrument.\\n\\nVI\"\n",
            " b\"ROMEO:\\nThe prenzie there, first, are gentleman.\\nO Gidger there, they studed, which is\\nhe marry will hear him come before.\\n\\nMENENIUS:\\nHas it bed,\\nWhich revenges you were the book of heaven,\\nFor I am therefore known that thou art: but\\nI'll plant strike to the doy; this ship, will comet\\nUpon the sidely timer more.\\nTowards London tille thee for my loving maso;\\nWho has she likely?\\n\\nJULIET:\\nBut now do them good friend Edward hath one word.\\n\\nHENRY BOLINGBROKE:\\nThanks, brave Montague's coverty lie:\\nI longing her; the wind-say I ever saw\\nTo prive my strength content with beauty-sweetless,\\nIf I be deceived: he did not weighing soldiers,\\nWith Angelo though contented with\\nthe crown, being o'er myself, for his pardons:\\nThinking he made eye return to you;\\nYoung Romeo is it for the corour-speak.\\nHath been blush'd, to knock his things and mind\\nTo besiege me in the holeming of thy breath?\\n\\nBENVOLIO:\\nGo forward it. This news; which if thou wilt, sir, have you a queen,\\nNot with the Romans, therefore, Master Fr\"\n",
            " b\"ROMEO:\\nHow she is mistory.\\nLift prebate farther of fire, spotless\\nFirst, his better deterage an honest,\\nReturn him here again.\\n\\nFirst Gentleman:\\nA master, like an injury confess:\\nI may not at this having breath their words:\\nThis man that thoughts and play to this deed was fond,\\nTo prove him to her laid to the south to the\\nsoil high, that this being so, if they\\ncannot be convented too: and see where begin him.\\n\\nDUKE OF AUMERLE:\\nEven out of Capulet,--lad as thou darest.\\n\\nTRANIO:\\nKing one a vantage of thy head love tell;\\nBegun mightier here, read like a dear friar, and\\nMy love is mind, to fear ere now, if\\nnot, no more of mine, Citizens:\\nThe game of England and thy faught report is death:\\nAnd if we pardon him.\\n\\nDUCHESS OF YORK:\\nI do not hunt, so that with God's fault\\nI'll send him reason so sad herebility:\\nThe unswif and famous to fear the name of Hicester\\nHath risent a stutch of stuff. Leave me a\\ncause remembereath their opening feast. Licio, this\\nFlourish thee with that smulling; whom I intend\"\n",
            " b\"ROMEO:\\nWhat says I have here the custome from sun?\\nHave you do confess to you in heaven?\\nSoftly, what they must be I think, calls down.\\nMy words will sig so sleep in peace, the preasts we say,\\nWe must end o, in What company,\\nI mean, in all beholding, I cheer your hands;\\nNow we intend to the purpose. Bid no more\\nStaff with him. You speak all athernal\\nTakes here lost a bluminess.\\n\\nCLAUDIO:\\nVillains, my lords,\\nGod have we here bestriving makes them.\\n\\nHERMIONE:\\nFair cousin, fair maid; wherefore it redembles,\\nhaving no more sits one to know more offening memory\\nWith baleful weeld. would he knew me, not unparallel'd\\nOf gracious. What are you in me?\\nI am a Roman safety.\\n\\nPETER:\\nPrantact, being embraces, that tempestates\\nShall be my wife is so other town.\\n\\nPETRUCHIO:\\nThen, sir;\\nHold, there, at once undoobled,\\nAs is his hounds they would believe us.\\nThou takest thy foul those chance 'What he is entent\\nTill he be anhipented with thy effect.\\n\\nGLOUCESTER:\\nHere's Romeo bids.\\n\\nShepherd:\\nThey call me word \"\n",
            " b\"ROMEO:\\nI tell thee, meanime.\\n\\nClown:\\nBlack, Edward hath been brother'd with Treacherous,\\nWhy we will make their fair desiring eyes\\nHave been beholding there, that thought i' the king.\\nO God! which then 'tis mine,--\\nFor, being mad Apace, I come, this within\\nYour changeling; I say, I come\\nI come to greet at unkindness and death.\\nThe rare keep winter, yet this gentleman to lose\\nThe pedent's of his ede, now came into some a\\nMortal more beholding tempest;\\nAnd in this rebellious steping what we dead,\\nThat thou contempt me excellents from me,\\nIn what laid makes that feel'd voices:\\nThou hast advanced tile the esped him of strong\\nAnd might shall blind uncoarts me to shine a block,\\nAnd yet more shocks, that our way instant,--if they do lay here,\\nWhere Christian last would give me letters--\\n\\nFirst Citizen:\\nI think thou burnt here? Tush on the market-place,\\nComes it moes to conqueror.\\nAt whom I will for great Baptista ta'en,\\nThe corrupt wind ship sign'd with stronger\\nThan he to their abundal ere no marv\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.7276225090026855\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBOoLWfangm8",
        "outputId": "85b33350-32e0-4fdf-9e62-e9b6ab5735d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7f38b4f27100>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "The chaplish'd spenation of my faith, come on the cause\n",
            "Of thricting with the highwimation that you\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')\n",
        "\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
