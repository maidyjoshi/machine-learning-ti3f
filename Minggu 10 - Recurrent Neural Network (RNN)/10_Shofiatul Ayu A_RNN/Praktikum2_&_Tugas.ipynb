{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp6ALftlQ5Fl"
      },
      "source": [
        "# PRAKTIKUM 2\n",
        "### Generator Teks dengan RNN\n",
        "\n",
        "Praktikum ini mendemonstrasikan cara melakukan genearsi text menggunakan RNN. Dataset yang digunkan adalah dataset Shakespeare's writing from Andrej Karpathy's The Unreasonable Effectiveness of Recurrent Neural Networks. Jika diberikan urutan karakter dari data ini (\"Shakespear\"), latih model untuk memprediksi karakter berikutnya dalam urutan (\"e\"). Urutan teks yang lebih panjang dapat dihasilkan dengan memanggil model berulang kali.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpQ45vHiRC9x"
      },
      "source": [
        "Tutorial ini menggunakan tf.keras dan eager execution. Berikut adalah contoh output ketika model dalam tutorial ini dilatih selama 30 epoch, dan dimulai dengan prompt \"Q\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj-sZO8oRHXb"
      },
      "source": [
        "### Setup\n",
        "#### Import Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "LYLwUJVURM8D"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzXyOKqcRQTv"
      },
      "source": [
        "#### Download Dataset Shakespeare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1wQH7AFRUJa",
        "outputId": "fb671aca-876b-4178-eed3-74da00c435e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAnJvvUsRb8K"
      },
      "source": [
        "#### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Euej3WhRaTq",
        "outputId": "f0cdd41d-4960-44c9-daae-a0ed354c1f1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text : 1115394characters\n"
          ]
        }
      ],
      "source": [
        "# Read, the people decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding = 'utf-8')\n",
        "\n",
        "# length of text is the number characters in it\n",
        "print(f'Length of text : {len(text)}characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfJRUVLxRkJA",
        "outputId": "f0a659f5-706c-4933-a872-dc1987faf3ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpBd57OfRnzo",
        "outputId": "daaf12bd-fdf5-4102-e819-417f2178c4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3MCvZOkRqyI"
      },
      "source": [
        "### Olah Teks\n",
        "#### Vectorize Teks\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOX_gTPaRyMZ",
        "outputId": "0e894b78-0e74-40cb-c0d4-5a725bef77ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Membagi teks menjadi karakter-karakter Unicode\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Lm-4mzR45m"
      },
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "yiuP3Ix2SFrY"
      },
      "outputs": [],
      "source": [
        "# Membuat layer StringLookup untuk mengonversi karakter menjadi ID\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab), mask_token=None\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DbM8hNWSKLS"
      },
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqjz3_dQSMnw",
        "outputId": "59de2762-05e1-4c7e-ede3-1bfed4ebba3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAuNDoFXSQHa"
      },
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode tf.keras.layers.StringLookup(..., invert=True).\n",
        "Catatan: pada kode ini, daripada meneruskan kosakata asli yang dihasilkan dengan diurutkan(set(teks)) gunakan metode get_vocabulary() dari tf.keras.layers.StringLookup sehingga token [UNK] disetel dengan cara yang sama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "q5nF1uLmSav-"
      },
      "outputs": [],
      "source": [
        "# Membuat layer StringLookup untuk mengonversi ID menjadi karakter\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(),\n",
        "    invert=True, mask_token=None\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSvJAjzISZHe"
      },
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYwuzVDPSbLh",
        "outputId": "cfe6ac0b-ff77-4882-b3a6-0274a6acb565"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengonversi ID kembali menjadi karakter\n",
        "chars = chars_from_ids(ids)\n",
        "chars\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eVuKojySvvk"
      },
      "source": [
        "Anda dapat menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDihKd0zSwot",
        "outputId": "ee802c5f-4b0c-49f4-f43a-f9d3325f939d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menggabungkan karakter menjadi string\n",
        "tf.strings.reduce_join(chars, axis=-1).numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "g3PZymOISxMw"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk mendapatkan teks dari ID\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYgfHWIxS7i9"
      },
      "source": [
        "### Prediksi\n",
        "#### Membuat Trianing Set dan Target\n",
        "\n",
        "Selanjutnya bagilah teks menjadi contoh sequence. Setiap masukan sequence akan berisi karakter seq_length dari teks. Untuk setiap masukan sequence, target prediksi berisi teks dengan panjang yang sama, hanya digeser satu karakter ke kanan. Jadi, bagi teks menjadi beberapa bagian seq_length+1. Misalnya, seq_length adalah 4 dan teks kita adalah \"Hello\". Urutan masukannya adalah \"Hell\", dan urutan targetnya adalah \"ello\". Untuk melakukan ini, pertama-tama gunakan fungsi tf.data.Dataset.from_tensor_slices untuk mengonversi vektor teks menjadi aliran indeks karakter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVzm7INMTJMp",
        "outputId": "3b7cf5f3-20fd-44e4-8b35-cd571963990d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jnFFMAXCTNP3"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7onth2DPTPlp",
        "outputId": "2676b5ee-ce35-4a8e-8631-3c58eadb0b13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan teks dari 10 batch pertama dalam dataset ID\n",
        "for ids in ids_dataset.take(10):\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Fmpw4pMRTR08"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33_Tc9KyTr__"
      },
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWUWyEItTUuV",
        "outputId": "22938832-daae-4c0a-d8c2-9e8c0b6249ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Membuat urutan karakter dari dataset ID dengan panjang sekuens ditambah 1\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "# Menampilkan urutan karakter dari 1 batch pertama\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqORV5fuTuNT"
      },
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkTuWQaZT8rL",
        "outputId": "5daba6a7-4ff3-444d-9f13-ff9cc324829a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Lo7fO7GBUL-B"
      },
      "outputs": [],
      "source": [
        "# Fungsi untuk memisahkan input dan target dari sebuah urutan karakter\n",
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sycOW-9ZUW_1",
        "outputId": "375dd66c-607b-4135-b875-faf2e2f139bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Contoh penggunaan fungsi split_input_target pada urutan karakter \"Tensorflow\"\n",
        "split_input_target(list(\"Tensorflow\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Serz_4YCUevB"
      },
      "outputs": [],
      "source": [
        "# Membuat dataset baru dengan memetakan fungsi split_input_target pada setiap elemen urutan karakter\n",
        "dataset = sequences.map(split_input_target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llSxBOUZUieC",
        "outputId": "15d6c7b3-90a2-4e66-8b7a-abdd9eae08f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "# Mengambil satu contoh dari dataset hasil pemisahan input dan target\n",
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGp6y0hyUlrR"
      },
      "source": [
        "#### Membuat Batch Training\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpssshJ7Uqvw",
        "outputId": "96c2064b-a9c9-48fe-c5f7-d9e6438b537a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EFIXetqUrSa"
      },
      "source": [
        "### Buat Model\n",
        "Bagian ini mendefinisikan model sebagai subkelas keras.Model (untuk lebih detilnya, lihat Making new Layers and Models via subclassing).\n",
        "Model yang kita bangun memiliki 3 lapisan neural network :\n",
        "- tf.keras.layers.Embedding: Lapisan masukan. Tabel pencarian yang dapat dilatih yang akan memetakan setiap karakter-ID ke vektor dengan dimensi embedding_dim;\n",
        "- tf.keras.layers.GRU: lapisan RNN dengan ukuran unit=rnn_units (Anda juga dapat menggunakan lapisan LSTM di sini.)\n",
        "- tf.keras.layers.Dense: Lapisan keluaran, dengan keluaran vocab_size. Ini menghasilkan satu logit untuk setiap karakter dalam kosakata. Ini adalah log kemungkinan setiap karakter menurut model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "71cFLSjDU2ij"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "vWOj4saXVxp7"
      },
      "outputs": [],
      "source": [
        "# Definisi kelas model kustom MyModel\n",
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super().__init__(self)\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = inputs\n",
        "        x = self.embedding(x, training=training)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(x)\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.dense(x, training=training)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "-YvRnYZeVyr2"
      },
      "outputs": [],
      "source": [
        "# Membuat instance model kustom MyModel\n",
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXTJgKDOV0c4"
      },
      "source": [
        "### Uji Model\n",
        "pertama, cek bentuk dari output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZrolEXQWJNI",
        "outputId": "a03602eb-a4ae-4f4e-a2e2-f2a2600d1e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "# Melakukan inferensi untuk satu batch contoh dari dataset\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL151RaOWJo-"
      },
      "source": [
        "Dalam contoh di atas, panjang urutan masukan adalah 100 tetapi model dapat dijalankan pada masukan dengan panjang berapa pun:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbNtNCweWLQV",
        "outputId": "03784209-3c58-4708-e5fc-53a266e412aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense_4 (Dense)             multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "a2YU-MMhWjkm"
      },
      "outputs": [],
      "source": [
        "# Menggunakan distribusi kategorikal untuk menghasilkan indeks yang diambil secara acak\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "# Menyusun kembali bentuk tensor dan mengonversinya ke dalam array NumPy\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgcWC8EYWsF_",
        "outputId": "b1cd4029-898c-4507-e1b6-e5b93dbadc1f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([61, 12,  9, 13, 27, 48, 58, 62,  9, 22,  8, 49, 10, 52, 28, 22, 16,\n",
              "       12, 39, 26, 25, 27, 50, 41, 55, 54, 49, 33, 30,  1, 46, 33, 39, 27,\n",
              "       30, 54, 14, 49, 59, 30, 48, 20, 20, 21, 42, 63, 62,  7, 42, 29,  1,\n",
              "        0, 32, 29, 16, 16,  9, 39, 64,  8, 41, 32, 27,  1, 13, 28, 46, 30,\n",
              "        2, 44, 59, 58,  6, 22, 13, 34, 22, 34, 43,  4, 65,  6, 31, 34, 20,\n",
              "       23, 15, 42, 59, 46, 52,  3, 42, 52,  3, 57,  7, 26, 47, 34])"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHhsiSedWsp7"
      },
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-IHSlEGXGHn",
        "outputId": "00074449-8beb-4210-f87d-413c62215c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'd to wear a crown,\\nHis hand to wield a sceptre, and himself\\nLikely in time to bless a regal throne.\\n'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"v;.?Nisw.I-j3mOIC;ZMLNkbpojTQ\\ngTZNQoAjtQiGGHcxw,cP\\n[UNK]SPCC.Zy-bSN\\n?OgQ ets'I?UIUd$z'RUGJBctgm!cm!r,MhU\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvLD6avgXGip"
      },
      "source": [
        "### Train Model\n",
        "#### Tambahan optimizer dan fungsi loss\n",
        "loss function tf.keras.losses.sparse_categorical_crossentropy standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag from_logits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "AaXC32I8XQbO"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItcEY83HXymW",
        "outputId": "f15a6ce0-7677-4100-e84a-ecc63d0a4fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.190126, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31aGrKAyX0y3",
        "outputId": "95e61ca6-e6a8-43b0-e89b-92c994479628"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66.031105"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "3hQ3EeKfX2LZ"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVp_4BvTX3GM"
      },
      "source": [
        "#### Konfigurasi Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "RZKbBu_3X-n6"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pr3-gDRX_gw"
      },
      "source": [
        "#### Lakukan Proses Training\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "JKUv0AVwYDNE"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgGHaIEVYE9y",
        "outputId": "5b346a3a-06f7-4d0f-f03e-f042ed98878a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 13s 56ms/step - loss: 2.7280\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.9937\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 1.7175\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 1.5556\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 1.4561\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.3866\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.3333\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.2869\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 13s 57ms/step - loss: 1.2457\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 13s 58ms/step - loss: 1.2057\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.1666\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.1256\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 13s 61ms/step - loss: 1.0828\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.0374\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 0.9893\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.9388\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.8873\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 0.8344\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 0.7838\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.7328\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW8ihelqYIif"
      },
      "source": [
        "### Generate Teks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "frvLBY32YKgp"
      },
      "outputs": [],
      "source": [
        "\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "JmquIt06YTLJ"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqClintjYVQ_",
        "outputId": "88e36b7f-8987-4733-e082-fce9dc45c1af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "How brook it not?\n",
            "\n",
            "BRUTUS:\n",
            "Consild his presence, my lord.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "What's the soul of thy mother, nay, nor if he?\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "Say not, sir, general; come, sir, ask'd am: if he swore,\n",
            "Your purish in this. But that you love your house,\n",
            "A graver increase that he is held\n",
            "But one a fool thy bride royal times,\n",
            "Drawn say the seas on them; I had thought\n",
            "so criminal to his curse intends;\n",
            "And you were not prepared for an hour fortune.\n",
            "\n",
            "KING RICHARD III:\n",
            "Blessed bewith my sworn, lords, good Kate,\n",
            "And take durst no longer stake a vice: only things not smake\n",
            "To know not at your very librer prison.\n",
            "\n",
            "RICHARD:\n",
            "Thou art poor in, and much in whood\n",
            "To answer it.\n",
            "\n",
            "AUFIDIUS:\n",
            "I know it.\n",
            "\n",
            "GRUMIO:\n",
            "King Edward, voice and these good request,\n",
            "For did ner two waits upon her, for the extremest of thine ears;\n",
            "Believe it, and our friends substiture's in your extremest.\n",
            "\n",
            "JULIET:\n",
            "You are too honest to do instance.\n",
            "\n",
            "DUKE VINCENTIO:\n",
            "I thank your grace.\n",
            "\n",
            "GLOUCESTER:\n",
            "Here's Pomp your death.\n",
            "\n",
            "First Senator:\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.3455183506011963\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2wJptnWYYfD",
        "outputId": "a578f199-62b0-457b-87a1-68852e31eada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nWhat say you, sir?\\n\\nROMEO:\\nWhy, have you faintly conquered your honour never.\\nBut feact from me, let that move me no excuse?\\n\\nAUTOLYCUS:\\nI am Green in heaven; but I'll think thou hadst, though I not do't.\\n\\nCORIOLANUS:\\nVincet it but a pit o' the mirth,\\nThan pity not what like you one would forget.\\n\\nNORTHUMBERLAND:\\nNay, I think he is before to know his promises,\\nWho hath pass'd and straight of lamentation.\\nGo, ready throw at this I came.\\n\\nTRANIO:\\nI know will then?\\n\\nNurse:\\nFie, young aprous will to frame mine oath.\\n\\nThird Citizen:\\nThere is a traitor, can you lay they live,\\nThat shall be hated that husband me,\\nThat he did business send upon thy yate;\\nBut that hath crim'd the torch to wail their wrath;\\nNor that which lives like a good world\\nBuy, while my father now it do:\\nHis prayers and undertaking Tybalt demandry\\nAre well contradiction:\\nTo earn to Lord Angelo is cross, now but\\nLetin's weakness with maintesher, to stande,\\nAnd therefore, being the advantage of him;\\nhe'll have my death!'\\n\\nS\"\n",
            " b\"ROMEO:\\nThe surney shame!\\n\\nTRANIO:\\nAnd fit, the lords of Claudio dead amors;\\nAnd rull here thou shalt hear themselves, when\\nAlas, thy slander's bloody forces drink.\\n\\nHENRY BOLINGBROKE:\\nBerny and sweet: I'll know, what sayest thou shalt not live.\\n\\nQUEEN ELIZABETH:\\nPite as the maid of Hortunes.\\n\\nSecand Senator:\\nCan go defore? Traitors not, nor frog is\\nAt ancient news so would be kept,\\nAnd I in praise them, I were well murdered:\\nNor one me, in thy soul, I can her,\\nAnd in their servants drops before our marriage\\nAs blame chased in a hoaring of hip!\\n\\nProvost:\\nThis, more to be the better is the midwife's name, sir;\\nHold rid the air, I have that lost you say\\nyour grace comes notico servicea:\\nOr I am thus, I think he swears' heart,\\nAnd ax the right and the forward wretch'd with us.\\n\\nROMEO:\\nHad I! no more to curse the king\\nIs a little. What seeks you are.\\n\\nKING RICHARD III:\\nI pray thee, gentle nurse!\\nPut thy anointed arimment of your wit stay,\\nWhich will I drown your Verona almost,\\nHelp seen in edilat\"\n",
            " b\"ROMEO:\\nHow should the tears were of thy looks and\\nTybalt.\\n\\nCAMILLO:\\nMy lest is\\nvirtued than you tarry, sir.\\n\\nESCALUS:\\nEither the better\\nThat I ensequest:'\\n\\nFirst Gentleman:\\nWhy, I am taught to have you that will\\ncontinuely.\\n\\nPAULINA:\\nI shall forb-ked to me.\\n\\nBIONDELLO:\\nHo!\\n\\nFRIAR LAURENCE:\\nFaithfully; like a little bend, Vincentio;\\nBut heaven she is not whereon thyself and thy love,\\nIn monument shall asprive Authority,\\nPusin'd givings. And after rolance\\nWill thine aboutly, has but troublet in!\\n\\nDUKE OF YORK:\\nSeed. What is that; both violence once\\nOn the deer sound.' Mowbray, she's dead!\\n\\nJULIET:\\nCome, leading seeks the duct married that hath\\ndrademined.\\n\\nShepherd:\\nYou cambiat friends, so wouldst as mother.\\n\\nGRUMIO:\\nNay, an't; think you that stabb'd their bodies was?\\n\\nWARWICK:\\nThe worthiness of our gross lost,\\nTo fear the second brother are no more. Go, counsel to the time!\\nAnd, like a bloody deed prayer's worthy fear!\\nFelt heaven, whenetear thee not away?\\n\\nROMEO:\\nI talk of that.\\n\\nANGELO:\\nAnd\"\n",
            " b\"ROMEO:\\nThis is the way; our knees he'll spake alace.\\nWho knows not for the lord of Coriolanus:\\nBut, mournering welcome, good morrow,--\\n\\nKING RICHARD III:\\nO Ratharianf are your kindred's voices, would you have\\nthem not that scorn him surplus eleven years\\nShall labour mocks again through any\\nnight: if you should durst prove a waiting,\\nNorthumberlands one daughter of a holy, and young\\nMasters; the beggary in this innocent should\\nbe.\\nYet, as you went any triumphant frait;\\nAnd not our more to entertain them stought\\nAt Courtesy, his flebsives in are as arms.\\nThey have done school-mistress than\\nBy throws not young more kind to counterpeace their souls,\\nMakes you to him for faults, if I be a\\nmay receive to give thee at thy fatal;\\nThough first bewareing tyrannious friends,\\nIn pain, devise him my mouth, her noble mother\\nOf mine absolute possession and aly,\\nTo revel in the faults of fiery cain,\\nTowards me with that offencef with praises,\\nYour lecture stempt and mistress fairly sect.\\n\\nSecond Citizen:\\nWh\"\n",
            " b\"ROMEO:\\nYou shall have none;\\nBeseech your necks, a dog and a dead man into\\nAbout his bitings: though I had prove him\\nTo make a scallet vault, even for a life.\\nWhy dost thou wakes on me?\\nIf thou wilt live, or what you are,\\nWith that honour hath he will be married to put what thou shalt reign,\\nTill cite some speech with your in them.\\n\\nThird Ressen:\\nI remember you, sir; for I had rather be you well,\\nwedle things not to stand for sorrow with his virtuous;\\nHer even ask in loss, they say the time\\nOn the issue.\\n\\nFirst Gentleman:\\nWhat, are you sure, there?\\n\\nBAPTISTA:\\nFaith, Here's am clear experienced, cannot have received\\nYour trust to myself: as she had lived\\nTo breakfoings more faithful friend! or what I am:\\nI hope it but to send the rotten of my sorrow's wronge,\\nI will remain already. Centite but thought!\\nI prithee, giving him Drumous plaguten with\\nhis bodies. Therefore prepare yourself; for it hath dewards\\nAs prisoner to his countryment.\\n\\nSICINIUS:\\nFie, fear, eatier, as I am not unreasonable hou\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.3174517154693604\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxEX1azpYbPb"
      },
      "source": [
        "### Ekspor Model Generator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXA0noyIYcmV",
        "outputId": "6f5441bf-4d4c-45c9-dee1-8d20d2a58722"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7e643e370c40>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfADZHf4Ygt2",
        "outputId": "2a75b6b8-6781-40a2-edff-b6ef56fc8da4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "I should have knowledge for that King Lewis\n",
            "Because to be my pent to supply the roor;\n",
            "For had I lau\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "aWSdC84jrvsE"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        " @tf.function\n",
        " def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "        predictions = self(inputs, training=True)\n",
        "        loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "JCrc0U_bsAlc"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "XWxGn5nXsCop"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mmW7Z1tsEsI",
        "outputId": "690cec6e-8629-4c5b-a041-d784ab67e0e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 15s 61ms/step - loss: 2.7255\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e6445321120>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMDOksdHsGrc",
        "outputId": "a2232a92-f4ee-443c-99ff-3c7e1bd04459"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1640\n",
            "Epoch 1 Batch 50 Loss 2.0604\n",
            "Epoch 1 Batch 100 Loss 1.9571\n",
            "Epoch 1 Batch 150 Loss 1.8771\n",
            "\n",
            "Epoch 1 Loss: 1.9983\n",
            "Time taken for 1 epoch 12.80 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8489\n",
            "Epoch 2 Batch 50 Loss 1.7650\n",
            "Epoch 2 Batch 100 Loss 1.7357\n",
            "Epoch 2 Batch 150 Loss 1.6363\n",
            "\n",
            "Epoch 2 Loss: 1.7132\n",
            "Time taken for 1 epoch 11.81 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5900\n",
            "Epoch 3 Batch 50 Loss 1.5626\n",
            "Epoch 3 Batch 100 Loss 1.5091\n",
            "Epoch 3 Batch 150 Loss 1.5381\n",
            "\n",
            "Epoch 3 Loss: 1.5503\n",
            "Time taken for 1 epoch 12.59 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4876\n",
            "Epoch 4 Batch 50 Loss 1.4260\n",
            "Epoch 4 Batch 100 Loss 1.4630\n",
            "Epoch 4 Batch 150 Loss 1.4686\n",
            "\n",
            "Epoch 4 Loss: 1.4504\n",
            "Time taken for 1 epoch 12.91 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3383\n",
            "Epoch 5 Batch 50 Loss 1.3625\n",
            "Epoch 5 Batch 100 Loss 1.4237\n",
            "Epoch 5 Batch 150 Loss 1.3733\n",
            "\n",
            "Epoch 5 Loss: 1.3818\n",
            "Time taken for 1 epoch 43.79 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3497\n",
            "Epoch 6 Batch 50 Loss 1.3578\n",
            "Epoch 6 Batch 100 Loss 1.3498\n",
            "Epoch 6 Batch 150 Loss 1.3327\n",
            "\n",
            "Epoch 6 Loss: 1.3274\n",
            "Time taken for 1 epoch 12.04 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.3049\n",
            "Epoch 7 Batch 50 Loss 1.2644\n",
            "Epoch 7 Batch 100 Loss 1.2590\n",
            "Epoch 7 Batch 150 Loss 1.3170\n",
            "\n",
            "Epoch 7 Loss: 1.2832\n",
            "Time taken for 1 epoch 12.57 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2321\n",
            "Epoch 8 Batch 50 Loss 1.2200\n",
            "Epoch 8 Batch 100 Loss 1.2325\n",
            "Epoch 8 Batch 150 Loss 1.2246\n",
            "\n",
            "Epoch 8 Loss: 1.2417\n",
            "Time taken for 1 epoch 12.98 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1981\n",
            "Epoch 9 Batch 50 Loss 1.2048\n",
            "Epoch 9 Batch 100 Loss 1.2410\n",
            "Epoch 9 Batch 150 Loss 1.2034\n",
            "\n",
            "Epoch 9 Loss: 1.2009\n",
            "Time taken for 1 epoch 12.59 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1370\n",
            "Epoch 10 Batch 50 Loss 1.1351\n",
            "Epoch 10 Batch 100 Loss 1.1812\n",
            "Epoch 10 Batch 150 Loss 1.1707\n",
            "\n",
            "Epoch 10 Loss: 1.1624\n",
            "Time taken for 1 epoch 38.86 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "      logs = model.train_step([inp, target])\n",
        "      mean.update_state(logs['loss'])\n",
        "\n",
        "      if batch_n % 50 == 0:\n",
        "         template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "         print(template)\n",
        "\n",
        " # saving (checkpoint) the model every 5 epochs\n",
        "      if (epoch + 1) % 5 == 0:\n",
        "         model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
