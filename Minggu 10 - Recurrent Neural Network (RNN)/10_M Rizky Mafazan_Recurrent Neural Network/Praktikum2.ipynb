{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PgV9mCdkz8L"
      },
      "source": [
        "## Praktikum 2\n",
        "### M. Rizky Mafazan (16)\n",
        "### 2141720140"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnW9FA8rkz8N"
      },
      "source": [
        "**Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i2WNzdujIwLj"
      },
      "outputs": [],
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj7ywO3AI6CI",
        "outputId": "f0be5233-160f-4066-eb18-deb2096cef45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Download Dataset Shakespeare\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2U-itL2JQCu",
        "outputId": "5aeead70-16c9-4468-dfd1-aa8a12a5a75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Load Data\n",
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0jbxX7dJXJA",
        "outputId": "f418f386-7601-42a5-833d-85bd8f788a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntG3SO0AJZbl",
        "outputId": "dbe00dce-ce3d-47ab-ca1a-080f49b55f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGhY3O3xkz8P"
      },
      "source": [
        "**Olah Teks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VoQKs-kpJa_m",
        "outputId": "8f080a99-539c-4cf6-92c9-d65354b4fb96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Vectorize Teks\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r0f1kQA8JnDS"
      },
      "outputs": [],
      "source": [
        "# sekarang buat tf.keras.layers.StringLookup layer:\n",
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeubiVzZJwAe",
        "outputId": "016692f3-6e24-402c-80c5-d6305b470888"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# perintah diatas mengconvert token menjadi id\n",
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wTqPQsYZJ2fa"
      },
      "outputs": [],
      "source": [
        "# kosakata asli yang dihasilkan dengan diurutkan(set(teks)) gunakan metode get_vocabulary()\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqhSjEADJ-Np",
        "outputId": "fec7e5f7-beed-4803-8ac9-e5ba16098c5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM-nVHEMKEzp",
        "outputId": "2f3d7cec-c54e-4bc5-e6b9-a32ba8eab070"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Anda dapat menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string.\n",
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I0e5SeVVKRfo"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqTtRvgsKX0u",
        "outputId": "9bc51416-0cba-493a-fd2f-6ca7bf341fa1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Prediksi\n",
        "# mengonversi vektor teks menjadi aliran indeks karakter.\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UE46kR_3Kn1I"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JiqA6JtKric",
        "outputId": "df45656d-8bb4-40e9-d7d3-ca25ed2f4df2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))\n",
        "\n",
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC1xJlO4KzDo",
        "outputId": "67118e33-00ea-43ac-8028-d862c6a8e6e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan.\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFv7uYcSK3_C",
        "outputId": "fe5e3224-fc20-403a-8916-685baec8a539"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "# akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:\n",
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Ndbwkp0iK8vg"
      },
      "outputs": [],
      "source": [
        "# fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu\n",
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text\n",
        "\n",
        "split_input_target(list(\"Tensorflow\"))\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKM4eWg6LOrg",
        "outputId": "845582af-8f2f-4609-d55d-2e6897520d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OugjkBk7LWaB",
        "outputId": "6ff8064c-412c-461f-ac0c-77e1c0450a76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Membuat Batch Training\n",
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzNl6uZqkz8S"
      },
      "source": [
        "**Buat Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qyp0gNLjLb1f"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "b6stBk5gLhJj"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XFpbnBNKLjXp"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cHbyaDakz8S"
      },
      "source": [
        "**Uji Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FgszJmWLlgz",
        "outputId": "35d0f79d-e726-45ac-e3d7-379d65965af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiBZywFFLpbI",
        "outputId": "3d9b9160-5e23-4e91-b424-48b336759a0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "10WQVuj8LsLK"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coJkQkWFLunh",
        "outputId": "68e07f5b-4603-4ae1-b387-2b27c19ef10f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17, 39, 33, 12, 38,  9, 45, 30,  3, 40, 35, 54, 29, 16, 62, 11, 45,\n",
              "       49, 43, 65, 12, 46, 40,  2, 17, 29,  5, 42, 49,  6, 46, 63, 53, 63,\n",
              "       10, 53,  7, 34, 65,  2, 64, 40, 34, 41, 49, 32, 47,  9, 19, 43, 34,\n",
              "       49,  6,  2, 31, 12,  6, 38, 60, 31, 19,  2, 36, 59, 17, 50, 14,  6,\n",
              "       59, 35, 39, 56, 38, 26, 11, 20, 38, 27, 59, 31,  1, 37, 55, 63, 17,\n",
              "       25, 15, 53,  6, 56,  2, 41,  2, 65, 47, 20,  1, 41, 14, 25])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdCKRaj1L0g-",
        "outputId": "772b8484-075d-4c79-cecf-5f6cf70475bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'here,\\nTo seek out sorrow that dwells every where.\\nDesolate, desolate, will I hence and die:\\nThe last'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"DZT;Y.fQ!aVoPCw:fjdz;ga DP&cj'gxnx3n,Uz yaUbjSh.FdUj' R;'YuRF WtDkA'tVZqYM:GYNtR\\nXpxDLBn'q b zhG\\nbAL\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmZSkN2Okz8T"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "7l-7R8rYL4rE"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgzZBzMjL8Vw",
        "outputId": "5101c394-2635-4e2c-db2a-e7a905edade3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1902475, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKlnNaMOL_C1",
        "outputId": "0427158c-063b-49da-f0ab-284398b984d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.03914"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UivwcqLTMCHg"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "RXUu7UoSME81"
      },
      "outputs": [],
      "source": [
        "# Konfigurasi Checkpoints\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "377zZLuMMJwr",
        "outputId": "e82041b6-499b-4a9a-8be3-3465933c8ff4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 19s 56ms/step - loss: 2.6745\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.9567\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 1.6795\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 1.5258\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.4317\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.3653\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.3140\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 1.2695\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.2278\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.1864\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.1448\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.1024\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.0570\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.0092\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 0.9598\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.9070\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.8548\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.8026\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 0.7529\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.7056\n"
          ]
        }
      ],
      "source": [
        "# Lakukan Proses Training\n",
        "EPOCHS = 20\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hROd7VQOkz8V"
      },
      "source": [
        "**Generate Teks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "cWCP7LzJMSkE"
      },
      "outputs": [],
      "source": [
        "# Berikut ini membuat prediksi satu langkah\n",
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mPgcmQwFMbT-"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YX4AtExMehc",
        "outputId": "8dfd747d-d9e8-4a8c-f30e-4a062361db8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Sir, in devilive thousand men, and have I slide\n",
            "from carrious for his part wherein we see the wants\n",
            "Dise occupation of the moon.\n",
            "\n",
            "LUCENTIO:\n",
            "See not on the med, and by thy noble Peera!\n",
            "Be't to have him,\n",
            "For hap thy clop walk again and your deliver?\n",
            "\n",
            "WARWICK:\n",
            "And leave your five and Kate. God give him, makings and\n",
            "'Ay. Stir, nor your name: Warwick, I dare draw.\n",
            "Son you call me a foe.\n",
            "\n",
            "LUCIO:\n",
            "O think, towards Cove?\n",
            "\n",
            "BIANCA:\n",
            "The gid you now, thin the utternician staff,\n",
            "With loxters and a slave, as yours\n",
            "like sooth, to-morrow, and yet yet he had done with him,\n",
            "And cannot please you, we can conquer out\n",
            "Aform I singline or so taken:\n",
            "Such envious things as wealth! our camelting lie\n",
            "Plast all death upon thine eyes, their blood\n",
            "Is victory and Licentles' lie:\n",
            "And therefore can you fame again, and say you\n",
            "have, 'tis come to know like secret thou after:\n",
            "The good in this time and a vassal, than forgot\n",
            "We not a shamefully; but it is so, it\n",
            "shall be the point.\n",
            "\n",
            "Provost:\n",
            "Thus was Bolingbroke's father, \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.3052284717559814\n"
          ]
        }
      ],
      "source": [
        "# Karena sedikitnya jumlah epoch pelatihan, model belum belajar membentuk kalimat runtut.\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAPi6svLMwbJ",
        "outputId": "b0fe5386-ca5a-402b-e424-a626709c518a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'ROMEO:\\nSpeakest not thy nostiness, brings not the sea,\\nWhich commends from out a man,\\nRemembery, Hastings, and I know not what:\\nBut to your forward, thinking so revive,\\nHer mett me with your heart, a thousand pound.\\n\\nNORTHUMBERLAND:\\nThe clock send more strice contents.\\n\\nBIANCA:\\nIn son branscases, eat and Juliet,\\nMy tongue doth give love, to humbly wrong I think.\\nFor what we never wrinkled that within the earth\\nCourins of her.\\n\\nNurse:\\nHast thou made me justice of my trod of trage?\\nProvides one pardon to the pady.\\n\\nBRUTUS:\\nRichard! are you! unworthy thief,\\nTo tire your leisure did not love.\\n\\nBRAKENBURY:\\nStir with my fortune divension of this blood,\\nWhose fodfit you yourself, for the good great deal doe\\nThy body in the to Rome, must he be diend;\\nAnd, fetch doth night tiguous gentleman,\\nTo buy seeming Angelo.\\n\\nISABELLA:\\nHow now? chiefler, curse, be full of\\nhimself, expecting with France?\\n\\nMARCIUS:\\nThy subjects sworn threefold our came off,\\nWhen mine own part,--hights himself?\\n\\nMENENIUS:\\nNow, the'\n",
            " b\"ROMEO:\\nO, thou didst kill my bone eye, hear me\\nYour fellow harder, my brothers lord;\\nIs it not white us to enter.\\n\\nFirst Lord:\\nPeace, Caice, Master Froth, I think, my lord;\\nAnd here lie compet it to the earth to me\\nAnd with the big of that e'er Access of ready.\\n\\nBRUTUS:\\nWe say he has the familer, this unjust,\\nI know thy music and will find live a witness\\nAnd those that breathe offended how that by\\nRichast particular. He says he made\\nA sicker caintral faint-upea flay'd?\\n\\nQUEEN ELIZABETH:\\nTranio is any in this desperate gallan;\\nThey shall be barred against my child.\\n\\nADRNIA:\\nYou are learn, and supeal things lung for him;\\nAnd as his perjure of the king's,\\nTo red your gain and you our kingdom, dreams\\nMake bad attendan town of seven eut;\\nBut O, thy child is young, or shall we come with him?\\nYou'll hear you woo'd; in fire from hence,\\nTo fight on me; I said a gentleman. Let us\\nshall to him than it is that hollow pagentary.\\n\\nBAPTISTA:\\nI know this villain! we have pity'd out suspect\\nAfter a wasted on\"\n",
            " b\"ROMEO:\\nPompey.\\n\\nSEBASTIAN:\\nForetake yout bring in my breast of this; and ten this\\nnietune and my soul is ready.\\n\\nISABELLA:\\nThe cause?\\n\\nBRUTUS:\\nHake he me\\nTo sleep and scope our senseless in hour-fire?\\nThat for the rivers of honourable takes,\\nAnd take away twelve foul birth,\\nThan force have stuff'd for his eyes.\\n\\nFirst Senator:\\nSo, let him be broken: you whoreson press\\nTo take our brother Richard make you Duke of York.\\n\\nEXTON:\\nWe staw's it, but to do with Question, is 'twixt him, these\\nsometimes and place you holy sin, for her,\\nShall think upon you gentlemen;\\nTo vine abuses; like stiff still shame,\\nAs that do growing fair wife so?\\n\\nCAMILLO:\\nThen know you not.\\n\\nANGELO:\\nFaint, thou hast breath in my brother.\\n\\nGLOUCESTER:\\nThe devil assmine on her dukedom\\nCan learn to live an unshunner. You't be satisfied!\\n\\nJULIET:\\nWho, ere my daughter? speak, Bohemia?\\n\\nGLOUCESTER:\\nTouch'd Angelo to speak, nor a quiet bears!\\nTendering the ground, this deed where he comes not.\\n\\nLORD ROSS:\\nThyself things from thee \"\n",
            " b\"ROMEO:\\nLet's to be thus;\\nHis curse is done, They'r language he hath\\nOraily in good haste: the beggary part\\nLuke's with our corseiviest har encourse with\\nhim.\\n\\nANGELO:\\nShe will be naked with silver.\\n\\nPAULINA:\\nOn pierce of Aprilions, all in one\\nI take, give used with fair word,\\nThat Rome is grown to burn broil'd\\nWith patience, both our horses;\\nAnd strawing Bolingbroke's untrueths, out\\nOf the dear blood to some requiret as they show\\ndoom call thine inteller. A damnal's patrician, and forsooth,\\nTo see Rome give use to hindlion of\\nher pains: I do learn him offer'd love.\\nShun I hear from me! and will I stand up;\\nNeither be till I bare blows.\\nMy uncle Rivers, Vaughan, Grey,\\nAnd leave thy knaves. I hear Cominius;\\nMake haste, proud man,' and I will withdous suppatation:\\nOr he be done, and give the man, whose reason\\nMust have you inago, to Berke eyes concluded,\\nThan, by the boy's office of thine.\\n\\nGLOUCESTER:\\nSirrah, go here pence our neither\\nA miserable in thy tree: and\\nthough aught enough.\\n\\nCAMILLO:\"\n",
            " b\"ROMEO:\\nPrepare thy conscieen! I might\\nBe calm in boding, and these to other can will\\nIntentious strength-nought burns, but bows, our eyes.\\n\\nGirse:\\nMarry, and that's by the people.\\n\\nCAPULET:\\nMadam, why, hark you never middness\\nWas drown'd in blood, kings, and all things of\\nwoe. But my fair Kate!\\nATaintim be converse as they had curse\\nAs I before a business. Take mine:\\nI cannot speak, unlucking on an art\\nThat he is to't. You are gentlemen.\\n\\nClown:\\nIf I dare not to see.\\n\\nGONZALO:\\nThis is the body: or resolved 'tond me So,\\nBe sworn, traitor, rest Warwick; send her not\\nWhich we have told the hearts to tell him here,\\nA makes one sat to entreat his behind charmshost.\\n\\nLUCIO:\\nBy any my person, kind Henry live we bear you not,\\nBid thee here to find his eyes: one who shall not bid me\\nThe polerous beggar for it: but I dare not so:\\nO, this your company, Remicened,\\nHath over-enter'd traitors for the mind\\nof that wisely, dommons, and begin hither.\\n\\nWARWICK:\\nTo London, and your mother! what a measure me\\nTo\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.138026714324951\n"
          ]
        }
      ],
      "source": [
        "# model menghasilkan 5 keluaran dalam waktu yang hampir sama dengan waktu yang dibutuhkan untuk menghasilkan 1 keluaran di atas.\n",
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsgeFJ50kz8W"
      },
      "source": [
        "**Ekspor Model Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNefko9tMzel",
        "outputId": "20fe23fb-f4ef-44ad-a37e-f45376c12a36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7832008dc3a0>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "When we'll be thought at first,\n",
            "We'll thought like a trod of breath:\n",
            "Keep he imager, but not fall. \n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')\n",
        "\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}