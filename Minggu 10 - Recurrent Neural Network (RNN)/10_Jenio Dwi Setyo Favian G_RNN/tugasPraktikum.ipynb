{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tugas Praktikum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gunakan tf.GradientTape untuk men track nilai gradient. Anda dapat mempelajari lebih lanjut tentang pendekatan ini dengan membaca eager execution guide.\n",
        "Prosedurnya adalah :\n",
        "1. Jalankan Model dan hitung loss dengan tf.GradientTape.\n",
        "2. Hitung update dan terapkan pada model dengan optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### praktikum 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tf_kPPBTBV9G"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf \n",
        "import numpy as np \n",
        "import os \n",
        "import time "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BknBnF7BV9K",
        "outputId": "c4e953e0-efec-489e-95d1-650d25601706"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m_LXJJhBV9L",
        "outputId": "a9cf4535-8bb2-4535-a63b-5e018d55bb18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8') \n",
        "\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylnuFzMIBkxa",
        "outputId": "4c651a53-1198-45f9-b35d-9ddee35b72f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBzajNJWBnlS",
        "outputId": "2bdeb386-0ace-4e1d-a5eb-e17bc6019168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "vocab = sorted(set(text)) \n",
        "print(f'{len(vocab)} unique characters') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SECZw_WkBpqj",
        "outputId": "dda4095b-e7a6-44ae-a80f-a8d515e78d62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QfoaNZScBruk"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mry4zpxBurI",
        "outputId": "7b460890-c08c-4ff1-d310-862f9d0b68d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UIQ-_zviB51p"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVegNn4CB108",
        "outputId": "e664b083-0f27-4279-a97f-306eb13696b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ2ZvwTiB7kR",
        "outputId": "21e26c07-6216-4165-e1dc-dd396d1d480c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "g_vh8UaGB9f2"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na7T-5ioCA5U",
        "outputId": "f96538dc-28bd-45ad-a17f-8117fe65a6db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v9RIBjf6CEgV"
      },
      "outputs": [],
      "source": [
        "\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HtIL1iRCHZr",
        "outputId": "c1524887-e131-49f8-ef1f-5cdc82f87910"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10): \n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8')) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zs_d9kg9CJeZ"
      },
      "outputs": [],
      "source": [
        "seq_length = 100 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPtEuDizCLLd",
        "outputId": "4e7f541a-29fb-425c-ffd5-5d78086fd54d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True) \n",
        "\n",
        "for seq in sequences.take(1): \n",
        "  print(chars_from_ids(seq)) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qymRlRcBCNDT",
        "outputId": "95ea9eb2-7255-448e-d43f-ed2bc6874a3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5): \n",
        "    print(text_from_ids(seq).numpy()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hPrQKHGqCQEO"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1] \n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77G75zKnCRq8",
        "outputId": "fdda4fe1-0a51-4495-86ef-fde0c2d21d74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\")) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0WNgsixPCSgv"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v529INprCUxa",
        "outputId": "e48d574d-02f7-4bed-f222-f318ee6b0820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1): \n",
        "    print(\"Input :\", text_from_ids(input_example).numpy()) \n",
        "    print(\"Target:\", text_from_ids(target_example).numpy()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFzs38ulCXGF",
        "outputId": "0c371f44-93bf-4818-c1b3-e20ef5f4151d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000 \n",
        "\n",
        "dataset = (\n",
        "    dataset \n",
        "    .shuffle(BUFFER_SIZE) \n",
        "    .batch(BATCH_SIZE, drop_remainder=True) \n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)) \n",
        "\n",
        "dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "BeuGjLXHCbVd"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary()) \n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256 \n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "SzC5FKI-CcNz"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) \n",
        "    self.gru = tf.keras.layers.GRU(rnn_units, \n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True) \n",
        "    self.dense = tf.keras.layers.Dense(vocab_size) \n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs \n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training) \n",
        "\n",
        "    if return_state:\n",
        "      return x, states \n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jmsLoOhHCeMo"
      },
      "outputs": [],
      "source": [
        "model = MyModel( \n",
        "    vocab_size=vocab_size, \n",
        "    embedding_dim=embedding_dim, \n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdYegFFhCg3V",
        "outputId": "52f3737f-c4a6-43b7-ff30-766f23466ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch) \n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5476y7kECjhn",
        "outputId": "9987ce11-e001-475f-8e00-8c9d8531ce41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sPLAMMblClDm"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) \n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbyX-xbTCm0r",
        "outputId": "0e9cc101-6cc7-4c59-bdcc-04f115d7f0f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([16, 50, 52,  9, 48, 18, 60, 36, 24, 40, 50, 17, 58, 65, 49, 53, 40,\n",
              "        3,  5,  1, 45, 57, 35, 10, 30, 19, 37, 28, 33,  6,  7, 15,  8, 63,\n",
              "       21, 45,  0, 18, 30, 25, 38, 29,  5, 50, 18,  0,  9, 62, 39, 31, 24,\n",
              "       49,  3,  1, 46, 61,  5, 31, 39, 62, 51, 14, 56, 35,  0, 47,  1,  3,\n",
              "       15, 34, 51, 33, 12,  0, 43, 16, 48,  2, 17, 39, 28,  9, 37, 25, 40,\n",
              "       45, 53, 58, 25, 47, 61, 29, 47, 53, 22, 17, 15, 16, 26, 16])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices # menampilkan array variabel sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxdDXeYYCoeJ",
        "outputId": "09e15b04-1d85-4aee-b32b-9e4cfa3e2337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'furnish me of reason. They are come.\\nYour mother was most true to wedlock, prince;\\nFor she did print'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"Ckm.iEuWKakDszjna!&\\nfrV3QFXOT',B-xHf[UNK]EQLYP&kE[UNK].wZRKj!\\ngv&RZwlAqV[UNK]h\\n!BUlT;[UNK]dCi DZO.XLafnsLhvPhnIDBCMC\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy()) \n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy()) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "0uD0PY4QCqHE"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwsQznroCr0V",
        "outputId": "a7e669aa-2700-4361-b509-74f819806749"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1890483, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6Fbs0-wCtOh",
        "outputId": "13454f76-6324-4137-874e-54d08e1ae333"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65.959984"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JBE4h6ymCvDN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "d_PyPAxdCy49"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints' \n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSj_esbnCzkT",
        "outputId": "cffe563d-9004-4b90-ac32-d06bb52c5586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 21s 63ms/step - loss: 2.7299\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 2.0006\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 12s 52ms/step - loss: 1.7170\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.5513\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 11s 55ms/step - loss: 1.4506\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.3823\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.3294\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.2830\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.2422\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.2015\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.1619\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.1190\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 1.0759\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.0286\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 0.9796\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.9286\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.8770\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.8231\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.7717\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 0.7247\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback]) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3aAPJEqDZU3"
      },
      "source": [
        "\n",
        "### Praktikum Tugas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PVRnDxN9BIk4"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function # mengonversi fungsi Python menjadi graph TensorFlow\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs # Menyimpan value inputs dengan membaginya ke inputs dan labels\n",
        "      with tf.GradientTape() as tape: # Membuat GradientTape untuk menghitung gradien dari operasi TensorFlow yang direkam\n",
        "          predictions = self(inputs, training=True) # memanggil model untuk menghasilkan prediksi dengan mengaktifkan mode training\n",
        "          loss = self.loss(labels, predictions) # menghitung kerugian model dengan membandingkan labels dengan predictions\n",
        "\n",
        "      grads = tape.gradient(loss, model.trainable_variables) # menghitung gradien dari kerugian model terhadap variabel-variabel yang dapat dilatih\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables)) # memperbarui parameter model menggunakan optimizer\n",
        "\n",
        "      return {'loss': loss} # Mengembalikan dictionary dengan key 'loss' dan value variabel loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "U7JXWIZpBIk-"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining( # Membuat Model CustomTraining\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()), # dengan kosakata yang digunakna sebanyak vocabulary yang dibuat sebelumnya\n",
        "    embedding_dim=embedding_dim, # argument embedding_dim dari variabel embedding_dim\n",
        "    rnn_units=rnn_units) # dan banyak unit rnn dengan variabel rnn_units"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "2T1QPmXUBIlA"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)) # Compile model dengan optimizer ADAM yang menhasilkan output berupa logits dengan menggunakan function loss berupa SparseCategoricalCrossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn-LzmqMBIlC",
        "outputId": "e9786608-166b-4374-a72b-f1f34e1e4f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 15s 63ms/step - loss: 2.7328\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b9b08f7d330>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1) # Melatih model dengan dataset dan 1 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjLY0PbqBIlD"
      },
      "source": [
        "Atau jika ingin lebih mengetahui dalamnya, kita bisa membuat custom training loop sendiri:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_NpBgKIBIlG",
        "outputId": "260679d5-2257-41d3-e529-51f3dae4ebd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1850\n",
            "Epoch 1 Batch 50 Loss 2.0719\n",
            "Epoch 1 Batch 100 Loss 1.9632\n",
            "Epoch 1 Batch 150 Loss 1.8372\n",
            "\n",
            "Epoch 1 Loss: 1.9996\n",
            "Time taken for 1 epoch 13.58 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.7799\n",
            "Epoch 2 Batch 50 Loss 1.7642\n",
            "Epoch 2 Batch 100 Loss 1.6440\n",
            "Epoch 2 Batch 150 Loss 1.6568\n",
            "\n",
            "Epoch 2 Loss: 1.7203\n",
            "Time taken for 1 epoch 11.90 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.6131\n",
            "Epoch 3 Batch 50 Loss 1.5627\n",
            "Epoch 3 Batch 100 Loss 1.5742\n",
            "Epoch 3 Batch 150 Loss 1.5305\n",
            "\n",
            "Epoch 3 Loss: 1.5578\n",
            "Time taken for 1 epoch 11.72 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4767\n",
            "Epoch 4 Batch 50 Loss 1.4475\n",
            "Epoch 4 Batch 100 Loss 1.4692\n",
            "Epoch 4 Batch 150 Loss 1.4812\n",
            "\n",
            "Epoch 4 Loss: 1.4576\n",
            "Time taken for 1 epoch 11.65 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.4228\n",
            "Epoch 5 Batch 50 Loss 1.4168\n",
            "Epoch 5 Batch 100 Loss 1.3737\n",
            "Epoch 5 Batch 150 Loss 1.4100\n",
            "\n",
            "Epoch 5 Loss: 1.3888\n",
            "Time taken for 1 epoch 20.59 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3110\n",
            "Epoch 6 Batch 50 Loss 1.3286\n",
            "Epoch 6 Batch 100 Loss 1.3280\n",
            "Epoch 6 Batch 150 Loss 1.3488\n",
            "\n",
            "Epoch 6 Loss: 1.3351\n",
            "Time taken for 1 epoch 11.60 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2672\n",
            "Epoch 7 Batch 50 Loss 1.2955\n",
            "Epoch 7 Batch 100 Loss 1.2953\n",
            "Epoch 7 Batch 150 Loss 1.3208\n",
            "\n",
            "Epoch 7 Loss: 1.2904\n",
            "Time taken for 1 epoch 11.89 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2236\n",
            "Epoch 8 Batch 50 Loss 1.2952\n",
            "Epoch 8 Batch 100 Loss 1.2284\n",
            "Epoch 8 Batch 150 Loss 1.2715\n",
            "\n",
            "Epoch 8 Loss: 1.2502\n",
            "Time taken for 1 epoch 12.00 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1949\n",
            "Epoch 9 Batch 50 Loss 1.2304\n",
            "Epoch 9 Batch 100 Loss 1.2336\n",
            "Epoch 9 Batch 150 Loss 1.1997\n",
            "\n",
            "Epoch 9 Loss: 1.2100\n",
            "Time taken for 1 epoch 12.09 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1374\n",
            "Epoch 10 Batch 50 Loss 1.1530\n",
            "Epoch 10 Batch 100 Loss 1.1992\n",
            "Epoch 10 Batch 150 Loss 1.1632\n",
            "\n",
            "Epoch 10 Loss: 1.1717\n",
            "Time taken for 1 epoch 20.58 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 11 Batch 0 Loss 1.0730\n",
            "Epoch 11 Batch 50 Loss 1.1214\n",
            "Epoch 11 Batch 100 Loss 1.1426\n",
            "Epoch 11 Batch 150 Loss 1.1594\n",
            "\n",
            "Epoch 11 Loss: 1.1321\n",
            "Time taken for 1 epoch 11.44 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 12 Batch 0 Loss 1.0723\n",
            "Epoch 12 Batch 50 Loss 1.1037\n",
            "Epoch 12 Batch 100 Loss 1.0861\n",
            "Epoch 12 Batch 150 Loss 1.1084\n",
            "\n",
            "Epoch 12 Loss: 1.0900\n",
            "Time taken for 1 epoch 11.71 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 13 Batch 0 Loss 0.9986\n",
            "Epoch 13 Batch 50 Loss 1.0244\n",
            "Epoch 13 Batch 100 Loss 1.0426\n",
            "Epoch 13 Batch 150 Loss 1.0657\n",
            "\n",
            "Epoch 13 Loss: 1.0449\n",
            "Time taken for 1 epoch 11.98 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 14 Batch 0 Loss 0.9860\n",
            "Epoch 14 Batch 50 Loss 0.9524\n",
            "Epoch 14 Batch 100 Loss 1.0170\n",
            "Epoch 14 Batch 150 Loss 1.0003\n",
            "\n",
            "Epoch 14 Loss: 0.9974\n",
            "Time taken for 1 epoch 11.98 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 15 Batch 0 Loss 0.8983\n",
            "Epoch 15 Batch 50 Loss 0.9438\n",
            "Epoch 15 Batch 100 Loss 0.9468\n",
            "Epoch 15 Batch 150 Loss 0.9833\n",
            "\n",
            "Epoch 15 Loss: 0.9467\n",
            "Time taken for 1 epoch 11.87 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 16 Batch 0 Loss 0.8575\n",
            "Epoch 16 Batch 50 Loss 0.8799\n",
            "Epoch 16 Batch 100 Loss 0.9227\n",
            "Epoch 16 Batch 150 Loss 0.9083\n",
            "\n",
            "Epoch 16 Loss: 0.8955\n",
            "Time taken for 1 epoch 20.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 17 Batch 0 Loss 0.7896\n",
            "Epoch 17 Batch 50 Loss 0.8052\n",
            "Epoch 17 Batch 100 Loss 0.8537\n",
            "Epoch 17 Batch 150 Loss 0.8811\n",
            "\n",
            "Epoch 17 Loss: 0.8413\n",
            "Time taken for 1 epoch 11.50 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 18 Batch 0 Loss 0.7704\n",
            "Epoch 18 Batch 50 Loss 0.7565\n",
            "Epoch 18 Batch 100 Loss 0.8043\n",
            "Epoch 18 Batch 150 Loss 0.8277\n",
            "\n",
            "Epoch 18 Loss: 0.7891\n",
            "Time taken for 1 epoch 11.85 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 19 Batch 0 Loss 0.6970\n",
            "Epoch 19 Batch 50 Loss 0.7184\n",
            "Epoch 19 Batch 100 Loss 0.7349\n",
            "Epoch 19 Batch 150 Loss 0.7858\n",
            "\n",
            "Epoch 19 Loss: 0.7390\n",
            "Time taken for 1 epoch 12.00 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 20 Batch 0 Loss 0.6465\n",
            "Epoch 20 Batch 50 Loss 0.6720\n",
            "Epoch 20 Batch 100 Loss 0.7129\n",
            "Epoch 20 Batch 150 Loss 0.7121\n",
            "\n",
            "Epoch 20 Loss: 0.6919\n",
            "Time taken for 1 epoch 12.17 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 20 # Inisisalisasi variabel EPOCH\n",
        "\n",
        "mean = tf.metrics.Mean() # membuat metrik rata-rata\n",
        "\n",
        "for epoch in range(EPOCHS): # Perulangan sebanyak EPCOHS\n",
        "    start = time.time() # Mencatat waktu mulai proses pada perulangan saat ini\n",
        "\n",
        "    mean.reset_states() # mereset metrik rata-rata\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset): # melakukan iterasi pada dataset dan mendapatkan batch data yang terdiri dari input dan target dengan menambahkan indeks disetiap elemennya\n",
        "        logs = model.train_step([inp, target]) # melatih modelg dengan menggunakan batch data yang diberikan\n",
        "        mean.update_state(logs['loss']) # memperbarui metrik rata-rata dengan loss training\n",
        "\n",
        "        if batch_n % 50 == 0: # Jika batch_n modulus 50 sama dengan 0\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\" # Menampilkan Epoch saat ini, value batch dan loss\n",
        "            print(template) # Menampilkan template\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0: # Jika epoch + 1 modulus 5 sama dengan 0\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch)) # menyimpan bobot model ke file dengan memanfaatkan checkpoint_prefix sebelumnya\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}') # Menampilkan epoch saat ini dan hasil dari mean\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec') # Menampilkan estimasi waktu dari selisih waktu saat ini dengan start\n",
        "    print(\"_\"*80) # Menampilkan 80 garis bawah\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch)) # menyimpan bobot model machine learning ke file dengan memanfaatkan checkpoint_prefix sebelumnya"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE1EaVu-Iutl"
      },
      "source": [
        "Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?\n",
        "> Perbedaan kode diatas dengan praktikum 2 yaitu pada praktikum 2 tidak memberi kita banyak kendali atas pelatihan. praktikum 2 menggunakan \"teacher-forcing\" yang mencegah prediksi buruk diumpankan kembali ke model, sehingga model tidak pernah belajar untuk pulih dari kesalahan."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
