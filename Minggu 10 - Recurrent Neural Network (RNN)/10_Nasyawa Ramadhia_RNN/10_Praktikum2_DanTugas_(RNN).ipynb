{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Praktikum 2**"
      ],
      "metadata": {
        "id": "xb2eMtuP1ZiJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Nasyawa Ramadhia // 2141720011 // 22**"
      ],
      "metadata": {
        "id": "4b07g8Clpr5j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset yang digunkan adalah dataset Shakespeare's writing from Andrej Karpathy's The Unreasonable Effectiveness of Recurrent Neural Networks."
      ],
      "metadata": {
        "id": "IXKI8mV4p1JB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup**\n",
        "Import TensorFlow"
      ],
      "metadata": {
        "id": "iFevmGncqgyM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dZRTLhz3ppaa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**penjelasan**:\n",
        "- TensorFlow, library yang sering digunakan dalam pengembangan machine learning dan deep learning\n",
        "- NumPy, library fundamental untuk komputasi numerik dalam Python, menyediakan struktur data (seperti array dan matriks)\n",
        "- Modul os menyediakan fungsionalitas untuk berinteraksi dengan sistem operasi.\n",
        "- Modul time menyediakan fungsi-fungsi terkait waktu dan pengukuran waktu dalam Python.\n"
      ],
      "metadata": {
        "id": "UvVBM2-jI-7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yo49egATqmql",
        "outputId": "51f297e4-ba59-497c-b8d8-79f12426e8ee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "penggunaan fungsi get_file dari modul tf.keras.utils dalam TensorFlow.\n",
        "Fungsi ini digunakan untuk mengunduh file dari URL yang diberikan dan menyimpannya di dalam direktori yang ditentukan secara otomatis atau sesuai dengan kebutuhan."
      ],
      "metadata": {
        "id": "SduSrg3PJg03"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Data**"
      ],
      "metadata": {
        "id": "vzlyeFvPqxuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgJDQyE6qv1c",
        "outputId": "b7a9ba34-9a68-4c02-8e2c-c68d24ba9592"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**penjelasan:**\n",
        "- open(path_to_file, 'rb').read(),  fungsi open() untuk membuka file yang telah diunduh dalam mode 'rb' (mode baca untuk file dalam format biner). Kemudian menggunakan .read() untuk membaca seluruh isi file dalam bentuk biner.\n",
        "\n",
        "- print(f'Length of text: {len(text)} characters') digunakan untuk mencetak panjang teks yang telah dibaca dari file"
      ],
      "metadata": {
        "id": "sG4PXeuULCL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cnt1oN0q05j",
        "outputId": "84ec36ce-b41b-43c1-858a-e5081bcc52d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_quWB52rQXB",
        "outputId": "0a25f2a3-8a44-4073-8631-3c02701457bf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Olah Teks**\n",
        "\n",
        "tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu.\n"
      ],
      "metadata": {
        "id": "BCVuzCTdrVB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtW4-1VwrgUJ",
        "outputId": "4b773aea-bc70-4b56-930a-b6529c95cbfb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "membuat tf.keras,layers.StringLookup\n",
        "\n",
        "mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "ek6vekyDr3zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "WUP40IqqrrlZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**penjelasan**\n",
        "- ids_from_chars adalah variabel yang menampung lapisan StringLookup.\n",
        "- tf.keras.layers.StringLookup digunakan untuk membuat lapisan ini.\n",
        "- parameter vocabulary yang harus berisi daftar karakter yang akan diindeks. vocab\n",
        "- mask_token=None menunjukkan bahwa tidak ada token khusus yang ditetapkan sebagai mask"
      ],
      "metadata": {
        "id": "DTMhMvDOOhd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc4JdepDr05O",
        "outputId": "610c4014-701f-46a7-82c5-e9645e62673b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "32b_844TsH6S"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**penjelasan**\n",
        "- chars_from_ids adalah variabel yang menampung lapisan StringLookup.\n",
        "- invert=True menandakan bahwa konversi sekarang akan dilakukan dari ID kembali ke karakter aslinya.\n",
        "\n",
        "Lapisan chars_from_ids ini berguna untuk mengonversi kembali ID yang dihasilkan sebelumnya ke karakter aslinya."
      ],
      "metadata": {
        "id": "0eLPEIiPO0qE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD1vcl2GsMqJ",
        "outputId": "931de99f-c976-4005-da15-9b073af1627b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6osONlvsVod",
        "outputId": "dfcd479c-4d4c-45f5-a189-b963f0627b90"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "9lFv89fAsl27"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**penjelasan**:\n",
        "Fungsi ini mengambil urutan ID (mungkin hasil dari suatu proses pada model atau proses pemrosesan sebelumnya) dan kemudian menggunakan chars_from_ids untuk mengonversi ID tersebut kembali menjadi karakter. Fungsi tf.strings.reduce_join digunakan untuk menggabungkan karakter-karakter ini menjadi sebuah string dalam bentuk teks."
      ],
      "metadata": {
        "id": "QxBezm_4PR5u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membuat Trianing Set dan Target**"
      ],
      "metadata": {
        "id": "AzWCikW9tg40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U2-MG-Htdwl",
        "outputId": "0e0b2367-6fb9-4741-82cc-ab3cb31694a6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "ynTyaLSJttc5"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ipne1gHtwER",
        "outputId": "4c2282c4-fc51-45c4-81d1-5ecd9a88ca01"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "JZ5zmS3Zt6A4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan"
      ],
      "metadata": {
        "id": "XAh5jxbbuQrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn4NGI6juJM4",
        "outputId": "5860f810-0209-4e14-a773-9f8ec769db49"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTBES1nKuXj9",
        "outputId": "f33fdb22-989e-46ba-e556-ccfc7e511580"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "6OhuOoDOug6L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv6TYk6Hutn4",
        "outputId": "b4ed6257-1e5e-4ed6-a411-f6c04b46b2dc"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "52XlngKIuv1E"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfpzU1yBu0ki",
        "outputId": "a2057442-1b0e-4bc1-d4aa-93768eb072af"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Membuat Batch Training**\n"
      ],
      "metadata": {
        "id": "TH0s5kJru97s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Fi-4fPXvbeo",
        "outputId": "cd05ad26-a086-4cf1-adbd-7d60a2c19f3a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Buat Model**"
      ],
      "metadata": {
        "id": "JfmVRXIGvfWG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "zOlDBbdkve1O"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- tf.keras.layers.Embedding: Lapisan masukan. Tabel pencarian yang dapat dilatih yang akan memetakan setiap karakter-ID ke vektor dengan dimensi embedding_dim;\n",
        "- tf.keras.layers.GRU: lapisan RNN dengan ukuran unit=rnn_units (Anda juga dapat menggunakan lapisan LSTM di sini.)\n",
        "- tf.keras.layers.Dense: Lapisan keluaran, dengan keluaran vocab_size. Ini menghasilkan satu logit untuk setiap karakter dalam kosakata. Ini adalah log kemungkinan setiap karakter menurut model."
      ],
      "metadata": {
        "id": "VZO6U5UevoIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "kWdY49vHvelY"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "IUSl9Bw4wALU"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "4q50RQftwJ17"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Uji Model**"
      ],
      "metadata": {
        "id": "EpbkWNmPwPZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBPdvLYhwRz9",
        "outputId": "fe4362e1-cfca-4598-802c-a8890c619b0c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C77UjquTwTqU",
        "outputId": "9942b326-b827-4350-9b59-8dd4d0b2eefd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "TAbHj9cTxLEL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVWaIvzixTEL",
        "outputId": "e132c978-aa57-449c-a7e9-fcc2d15b2897"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([41,  9, 35, 14, 39, 51, 33,  9, 51, 26, 19, 34, 53, 54, 42, 10, 13,\n",
              "       61, 51, 34, 41, 21, 34, 38,  0, 23, 36, 49, 11, 25, 12, 14,  3, 24,\n",
              "       15, 19, 43, 32, 32, 13, 62, 12, 41, 24, 42,  2, 20,  7, 51, 10, 20,\n",
              "       48, 46, 35, 61, 41, 24, 54, 22, 22, 63,  5, 38, 61,  6, 18, 31, 47,\n",
              "        0, 33, 64, 54, 45, 39,  8, 12,  5, 37, 11,  4, 17,  4,  5, 40, 45,\n",
              "       49, 59,  4,  5, 24,  6, 15, 33, 65, 20, 56, 27, 41, 15, 40])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y40B6SpuxUvK",
        "outputId": "c128a227-a0e0-4a1a-effe-7f362aea4bf0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'oy; I am past moe children, but thy sons and\\ndaughters will be all gentlemen born.\\n\\nClown:\\nYou are w'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"b.VAZlT.lMFUnoc3?vlUbHUY[UNK]JWj:L;A!KBFdSS?w;bKc G,l3GigVvbKoIIx&Yv'ERh[UNK]TyofZ-;&X:$D$&afjt$&K'BTzGqNbBa\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Model**"
      ],
      "metadata": {
        "id": "ibIsdD0NxaQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "toCbCzdVxdZc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-plgGatnxg_o",
        "outputId": "afdc93bc-1727-46ad-f692-d054aa108057"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.189494, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XNw4PHrxkqV",
        "outputId": "26106946-5f9d-4f35-a56f-7ff6f296fc69"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.9894"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "d-jQE6AWxmjp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "YJge5y9Xxo9N"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Proses Training**"
      ],
      "metadata": {
        "id": "FIKEPpgvyxuR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=20"
      ],
      "metadata": {
        "id": "biGISxYVy1-X"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRwQNpuwy5Rc",
        "outputId": "0830f19f-49bc-4d0a-f936-5544149b0d6d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 14s 56ms/step - loss: 2.7117\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 54ms/step - loss: 1.9816\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.7024\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.5441\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.4486\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.3812\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 12s 55ms/step - loss: 1.3289\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.2835\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.2431\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.2031\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 1.1628\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.1202\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.0773\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 12s 57ms/step - loss: 1.0319\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 0.9818\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.9319\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 12s 56ms/step - loss: 0.8789\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.8258\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 0.7750\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 11s 56ms/step - loss: 0.7265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Teks**"
      ],
      "metadata": {
        "id": "FWYV7OtG0I3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "IZh2mq680ac6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**penjelasan:**\n",
        "Inisialisasi Kelas:\n",
        "- Kelas OneStep menerima beberapa parameter seperti model, chars_from_ids, ids_from_chars, dan temperature\n",
        "- model, yang akan digunakan untuk melakukan prediksi langkah demi langkah.\n",
        "- temperature: Parameter opsional untuk mengatur \"kreativitas\" atau \"uncertainty\" dalam proses pengambilan sampel\n",
        "\n",
        "Metode generate_one_step:\n",
        "- Metode ini mengambil input sebagai teks (dalam bentuk string)\n",
        "- teks input diubah menjadi token ID menggunakan ids_from_chars\n",
        "- model dijalankan untuk mendapatkan predicted_logits, yang berisi kemungkinan probabilitas dari karakter-karakter selanjutnya.\n",
        "- Dilakukan normalisasi menggunakan self.temperature untuk mengontrol variabilitas teks yang dihasilkan.\n",
        "- Karakter selanjutnya diprediksi berdasarkan distribusi probabilitas menggunakan tf.random.categorical."
      ],
      "metadata": {
        "id": "l858V9nbScY1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "zvf4L5wC0eV-"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fIiFIp70r81",
        "outputId": "0c9cc025-57bd-4315-c4f5-0d88240521ca"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "The collerts of the dishonoun after:\n",
            "Is not the frowns of his aither persua, peace\n",
            "With all when she deliver'd but thy nurse years device,\n",
            "And once no less than Henry's heat? I hold it no harm.\n",
            "\n",
            "FRIAR LAURENCE:\n",
            "Bootless and two maid was not warrant;\n",
            "But let my told it counsels muttle on.\n",
            "\n",
            "ISABELLA:\n",
            "To sin, for I have lively.\n",
            "\n",
            "GREMIO:\n",
            "I married, sir, no granted surpe, with ourself,\n",
            "Whose honouration at your joys,\n",
            "with words at good one.\n",
            "Is not my father was the character, Here I stay,\n",
            "For thinking thou did call him of his eyesigh stand:\n",
            "Never was such filled for your pleasure is.\n",
            "How long a sin which canst unthought doth embrace them\n",
            "Maintain what you preat near all, as if a thousand fear\n",
            "Thy love, black part: serve it; and I would discover him\n",
            "To reap As all that I should be ingeg.\n",
            "\n",
            "ADY GREY:\n",
            "I shall, dischars; and tell them when I would do too,\n",
            "Than with usurping breathing: here are like my father\n",
            "Which of your hearts and heart-sorrow lightly.\n",
            "The virgious confusion what the cause\n",
            "As \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.261446952819824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBC-nDC20-15",
        "outputId": "7c741f7f-4be8-4a78-86b7-cbc809ad6897"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nAy, if no more than the town of France:\\nHis loving trial o' the love have done,\\nEven as has youth with hard but most have more cause\\nTo more short unhappy words pretty into his life,\\nOr death hath made them us, the ears illow;\\nHer charity most good and so finely when too late!\\n\\nVOLUMNIA:\\nBastain was that, my lord. I pity us,\\nThe news that Rome gafe so? Come here; that's to read?\\n\\nPETRUCHIO:\\nI shall.\\n\\nDUKE VINCENTIO:\\nYou will not, then?\\n\\nPage:\\nMy lord, here comes a neather of them: with trumpets' sun.\\nEven such, the fruits of love I mean to see\\nme from the sister of the king and no other right.\\n\\nROMEO:\\nI take upon you; and, as it were ready!\\nFor what often? have well indeed? how to Chrift again,\\nBeing but off with the first dear father and\\nHim and Saints between and nimble in life,\\nA man of safframest morn beloved\\nit to marry 'pardon'' is another one too, or not a suspect law,\\nFrom when this time let fed this young blood speak again\\nTo make no staught from them, that hath thy state I c\"\n",
            " b\"ROMEO:\\nI will not run away.\\n\\nLARTIUS:\\nOn pain of witness call\\nThat I may palm in this mystirm again.\\nI come to verd content already.\\n\\nISABELLA:\\nMay nothing miss! she was beauted for to tell?\\n\\nBAPTISTA:\\nTaggest thou forgot do un; that, if it to the king,\\nI'll leave your country's father, or shown.\\n\\nKATHARINA:\\nI prithee, peace: there is my daughter gone?\\nAnd you will have it from my heart lies before thy day.\\n\\nTRANIO:\\nI could hear for her less replenish from offence, that with thee?\\n\\nPETRUCHIO:\\nI know who geath.\\n\\nWERMION:\\nO know, it was infirmity of blood;\\nThat, being suitforth to else, I said a bastard;\\nThy wits the happy gallant, being over-proud in\\nput them; and the pretty dignes of his lacks.\\nThou blood is not the Duke of Glove for sweet,\\nBut she'll not rare them accurs?\\n\\nCLAUDIO:\\nThe prettie-tabination combined, but follows sit\\nOf it at your conduit.\\n\\nAUTOLYCUS:\\nI am for my accomn; and all their heads before him,\\nThough it begins an evil distraction town,\\nTo let me see the boying diting p\"\n",
            " b\"ROMEO:\\nHark ye; your goodness open it so;\\nA man and learnON ELIZABETH:\\nFor grave is as the devild throne, but niversy;\\nHere cousins anow 't:\\nI would forget thee, for I have no cause to speak\\nAgainst the hights great and despair! Have you forget,\\nWith pail their better estate as perforce,\\nAnd could not mellow thee this fellow?\\n\\nSecond Murderer:\\nI will, make talked of your fortune; here's my father\\nTo know himself igson hardly.\\n\\nDUKE OF YORK:\\nBrother, I would this woll?\\nIn him?\\n\\nLUCIO:\\nTo her, if too England a neave where:\\nThese all, deposed and frowly object\\nWherein your father ruledy sons.\\n\\nVOLUMNIA:\\nBe calm both than I am; read o' the tackles,\\nAnd drilt from banifelts here progets how\\nTo see out pitiff in our coast of all.\\nI stand, I'll make a puppet o' them; and\\nthere's not which thrust any innocent and a strange realm;\\nI may go on: there is no worse here;\\nPut do not move yourself, and see how they press;\\nSo doth the hope that bear thy sea,\\nThan shame same gentlewoman in thy sheep,\\nAnd vir\"\n",
            " b\"ROMEO:\\n\\nBISHOPTO:\\nI know not what a deal of his life-bear.\\nHark you no good for your Coriolanus.\\n\\nDUKE VINCENTIO:\\nMore of this regire? after, I will gaited the two flatterers\\nLend from us it; let it be processor:\\nAnd that too music at that title shall to go you of\\nThe days join'd to the sour conspiration.\\n\\nBUCKINGHAM:\\nWhat, will my weapon, will you twell? we say the lords of men.\\nBut in your minds cannot lose thee with thy witnes\\nThe dishonour brings on the provost.\\n\\nKING RICHARD III:\\nDraw near, yet dead my innocent and give him so\\nfear'd; she would afford the grave\\nAddine unto their hearts were stifleding;\\nThe leisure and the life of teniousness,\\nHis guilty does, is warp'd to me: us, call hardly\\nHe here deliver'd with our true king:\\nAnd he shall spend mine noble feverous him;\\nNor choose our zeal't to be with peace, nor hate to\\nThe apts travelled with orrow and thesely\\nSholes of them accuse.\\n\\nSecont Senator:\\nSo, true.\\nI will not deny to love, and bid thee from thy father?\\nThy neighbown moon \"\n",
            " b\"ROMEO:\\nPoor soul, thy force torch in carrions in thine ear,\\nTill we could hear me so unluckily'd.\\n\\nLUCENTIO:\\nWhy is the matter? O woful boy!\\nAh, good morrow, Signior Gremio. What's the prince\\nOur voices cried by him and true love's use!\\nO, I will wash them bait all fortune good us\\nSuch again; back with money and formsort; Capitle,\\nTo have more acting, and if you speak,\\nOr to the utter of my blood. Nay, I shall.\\n\\nGentleman:\\nUrmer up aud feet, when I shall not, he had can ill\\nInto pieece or sovereignty.\\n\\nSEBARTIIAN:\\nPray now, fond Derbunion.\\n\\nDUKE OF YORK:\\nPeace, the king come unknown: belike he is a crutle,\\nYet in possible linger.\\n\\nLEONTES:\\nI ne'er heard he halk,\\nAnd come at the petition. Is it near\\nmy oaks begins to won, I'll strike again and tread,\\nBoth him as dear to me; a dogion--\\nDid not to cherish root and puilty of the histy.\\nAnd sheard the trumpet sounds his title to the queen\\nHath boot in beats that it be dish'd; and how she looks\\nUpon them after stand and great disgrasset,\\nAs is her\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.322892665863037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ekspor Model Generator**"
      ],
      "metadata": {
        "id": "u1XoT3aK1C7i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wli-LUS61GwR",
        "outputId": "7b27c64a-1f25-4e6b-989f-fe47808ff8fb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7a34e4bcbdf0>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**penjelasan :**\n",
        "- tf.saved_model.save(one_step_model, 'one_step'): Baris kode ini menyimpan model yang disebut one_step_model ke dalam file dengan nama 'one_step'\n",
        "- one_step_reloaded = tf.saved_model.load('one_step'): Baris kode ini memuat (load) model yang sebelumnya telah disimpan dengan nama 'one_step'. Model yang dimuat kemudian diberikan label one_step_reloaded\n"
      ],
      "metadata": {
        "id": "QFFwsUM2R1Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AffJekn11ISk",
        "outputId": "f5d5bcbe-1f00-4757-ccfd-727291752058"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Speak comest to London any of you have done.\n",
            "\n",
            "Shepherd:\n",
            "Lord, madam, go to, no, it doth so;\n",
            "And I d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**penjelasan**\n",
        "\n",
        "- Variabel states awalnya diatur ke None\n",
        "- next_char diinisialisasi dengan teks awal \"ROMEO:\"\n",
        "- Melalui loop for, dilakukan iterasi sebanyak 100 kali\n",
        "- Setelah proses iterasi selesai, dilakukan penggabungan semua karakter dalam result menggunakan tf.strings.join() untuk membentuk teks berikutnya."
      ],
      "metadata": {
        "id": "7R2kVgR0Ps3m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Tugas**\n",
        "\n",
        "Prosedur pelatihan pada praktikum 2 merupakan prosedur sederhana, yang tidak memberi Anda banyak kendali. Model ini menggunakan \"teacher-forcing\" yang mencegah prediksi buruk diumpankan kembali ke model, sehingga model tidak pernah belajar untuk pulih dari kesalahan. Jadi, setelah Anda melihat cara menjalankan model secara manual, selanjutnya Anda akan mengimplementasikan custom loop pelatihan. Hal ini memberikan titik awal jika, misalnya, Anda ingin menerapkan pembelajaran kurikulum untuk membantu menstabilkan keluaran open-loop model. Bagian terpenting dari loop pelatihan khusus adalah fungsi langkah pelatihan.\n",
        "\n",
        "Gunakan tf.GradientTape untuk men track nilai gradient. Anda dapat mempelajari lebih lanjut tentang pendekatan ini dengan membaca eager execution guide.\n",
        "\n",
        "Prosedurnya adalah:\n",
        "1. Jalankan Model dan hitung loss dengan tf.GradientTape.\n",
        "2. Hitung update dan terapkan pada model dengan optimizer"
      ],
      "metadata": {
        "id": "q8b7SAWCZx-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "    inputs, labels = inputs\n",
        "    with tf.GradientTape() as tape:\n",
        "      predictions = self(inputs, training=True)\n",
        "      loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "txXaEKAqZ1G9"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode diatas menerapkan train_step method sesuai dengan  Keras' train_step conventions. Ini opsional, tetapi memungkinkan Anda mengubah perilaku langkah pelatihan dan tetap menggunakan keras Model.compile and Model.fit methods."
      ],
      "metadata": {
        "id": "9gCiC-22Z_Pm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "AsvdfgamaBqB"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "id": "9-ZEm6uNaDs2"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rQ3OZuJaFrF",
        "outputId": "c42fc154-5497-4cc5-b1f4-4097d7db35fe"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 14s 57ms/step - loss: 2.7316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a35bba27040>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Atau jika ingin lebih mengetahui dalamnya, kita bisa membuat custom training loop sendiri:"
      ],
      "metadata": {
        "id": "f17NynX4aKJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "# saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "print()\n",
        "print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HN6YjYtkaKrV",
        "outputId": "c8d614eb-b4b5-43a0-8b62-234ad33dc080"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1973\n",
            "Epoch 1 Batch 50 Loss 2.0948\n",
            "Epoch 1 Batch 100 Loss 1.9349\n",
            "Epoch 1 Batch 150 Loss 1.8574\n",
            "Epoch 2 Batch 0 Loss 1.8245\n",
            "Epoch 2 Batch 50 Loss 1.7728\n",
            "Epoch 2 Batch 100 Loss 1.6935\n",
            "Epoch 2 Batch 150 Loss 1.6981\n",
            "Epoch 3 Batch 0 Loss 1.6297\n",
            "Epoch 3 Batch 50 Loss 1.5459\n",
            "Epoch 3 Batch 100 Loss 1.5686\n",
            "Epoch 3 Batch 150 Loss 1.5253\n",
            "Epoch 4 Batch 0 Loss 1.5276\n",
            "Epoch 4 Batch 50 Loss 1.4719\n",
            "Epoch 4 Batch 100 Loss 1.4908\n",
            "Epoch 4 Batch 150 Loss 1.4224\n",
            "Epoch 5 Batch 0 Loss 1.3849\n",
            "Epoch 5 Batch 50 Loss 1.4119\n",
            "Epoch 5 Batch 100 Loss 1.3711\n",
            "Epoch 5 Batch 150 Loss 1.3855\n",
            "Epoch 6 Batch 0 Loss 1.4148\n",
            "Epoch 6 Batch 50 Loss 1.3013\n",
            "Epoch 6 Batch 100 Loss 1.3171\n",
            "Epoch 6 Batch 150 Loss 1.2855\n",
            "Epoch 7 Batch 0 Loss 1.2576\n",
            "Epoch 7 Batch 50 Loss 1.2844\n",
            "Epoch 7 Batch 100 Loss 1.3062\n",
            "Epoch 7 Batch 150 Loss 1.2736\n",
            "Epoch 8 Batch 0 Loss 1.2212\n",
            "Epoch 8 Batch 50 Loss 1.2445\n",
            "Epoch 8 Batch 100 Loss 1.2574\n",
            "Epoch 8 Batch 150 Loss 1.2446\n",
            "Epoch 9 Batch 0 Loss 1.2130\n",
            "Epoch 9 Batch 50 Loss 1.1671\n",
            "Epoch 9 Batch 100 Loss 1.2062\n",
            "Epoch 9 Batch 150 Loss 1.2139\n",
            "Epoch 10 Batch 0 Loss 1.1136\n",
            "Epoch 10 Batch 50 Loss 1.1551\n",
            "Epoch 10 Batch 100 Loss 1.1850\n",
            "Epoch 10 Batch 150 Loss 1.2002\n",
            "\n",
            "Epoch 10 Loss: 1.1686\n",
            "Time taken for 1 epoch 20.60 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PERBEDAAN ANTARA PRAKTIKUM 2 DAN TUGAS**\n",
        "\n",
        "1. Perbedaan pertama adalah **waktu** karena pada praktikum 2 menggunakan\n",
        " **ephocs yang lebih banyak** sehingga waktu **runtime lebih lama** dibanding tugas\n",
        "\n",
        "2. Pada praktikum **menggunakan function** yang telah disediakan oleh library tensorflow, sedangkan pada tugas **menggunakan perulangan dan tf**.GradientTape yang memungkinkan kita untuk lebih fleksibel pada penggunaan"
      ],
      "metadata": {
        "id": "mZN3rgfyaOP2"
      }
    }
  ]
}