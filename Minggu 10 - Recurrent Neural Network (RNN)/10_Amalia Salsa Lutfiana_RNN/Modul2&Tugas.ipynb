{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfG5w6Ojmyk0"
      },
      "outputs": [],
      "source": [
        "# Mendeklarasikan penggnaan TensorFlow\n",
        "import tensorflow as tf\n",
        "# Mendeklarsaikan penggunaan NumPy\n",
        "import numpy as np\n",
        "# Mendeklarasikan modul os\n",
        "import os\n",
        "# Mendeklarasikan modul 'time'\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7UY67S5nDlw",
        "outputId": "52c7d8e3-6e8e-4b75-ab7a-7fa915a5d733"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Mengunduh file\n",
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecw3SGXEeJge"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDe61bxCnlyD",
        "outputId": "b8322896-4cec-47a4-c8cb-0d43445c1633"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Membaca file dalam bentuk biner\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# Menghitung karakter teks\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPwNldixnpFx",
        "outputId": "4ea713fb-e2e4-4148-f5b6-181c9d492d04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Memberikan gambaran awal dari teks yang telah dibaca\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "je4EvfDPnyrH",
        "outputId": "c0100a6a-3a7a-45d0-8bdd-52d4fb698dd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# Mengidentifikasi karakter unik dalam teks\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THmWt0Own46O"
      },
      "source": [
        "**Olah Teks**\n",
        "\n",
        "Vectorize Teks\n",
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBhTeeI5oBsK",
        "outputId": "b963b014-867c-4852-8807-89f2c39dc404"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menghasilkan struktur data TensorFlow yang cocok\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALVr_zo_oNwp"
      },
      "outputs": [],
      "source": [
        "# Mengonversi string menjadi numerik\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "619wKqW2oRJD",
        "outputId": "6c8c5369-0241-45ba-83d8-73d0f8e15427"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mempresentasikan ID dari karakter 'chars'\n",
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zb_DtFcKo96F"
      },
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode tf.keras.layers.StringLookup(..., invert=True).\n",
        "Catatan: pada kode ini, daripada meneruskan kosakata asli yang dihasilkan dengan diurutkan(set(teks)) gunakan metode get_vocabulary() dari tf.keras.layers.StringLookup sehingga token [UNK] disetel dengan cara yang sama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRxtDJdNpBsr"
      },
      "outputs": [],
      "source": [
        "# Mengonversi kembali ID numerik menjadi karakter unik\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDf3wh1ypSKA"
      },
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter tf.RaggedTensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg9tXWUMpTAd",
        "outputId": "b3e594fa-40e9-4a6d-84c9-877790ef15c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengembalikan ID numerik yang sesuai dengan mapping yang ditentukan\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Xox9Q9paVJ"
      },
      "source": [
        "Anda dapat menggunakan tf.strings.reduce_join untuk menggabungkan kembali karakter menjadi string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZgXcqc2pbDP",
        "outputId": "3c28b695-1bbc-4bdf-f719-54fdb2f4cfad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menggabungkan karakter dari tiap tensor\n",
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICG7yn5yplir"
      },
      "outputs": [],
      "source": [
        "# Mengonversi kumpulan ID numerik dan mengonversi kembali menjadi teks\n",
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q0Gebdepx2h"
      },
      "source": [
        "**Prediksi**\n",
        "\n",
        "Diberikan sebuah karakter, atau serangkaian karakter, karakter apa yang paling mungkin berikutnya? Ini adalah tugas yang harus Anda latih agar model dapat melakukannya. Masukan ke model akan berupa urutan karakter, dan Anda melatih model untuk memprediksi keluaran berupa karakter berikut pada setiap langkah waktu. Karena RNN mempertahankan keadaan internal yang bergantung pada elemen yang terlihat sebelumnya, mengingat semua karakter dihitung hingga saat ini, karakter apa selanjutnya?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbG1SY6Cp0sD",
        "outputId": "965028c9-c328-4fe5-b8bc-cb88e1e6e9b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengonversi teks menjadi ID numerik\n",
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cI1wiC3hqXg7"
      },
      "outputs": [],
      "source": [
        "# Melatih model untuk pemrosesan data lanjutan\n",
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSGf98nFqbLE",
        "outputId": "188098d2-581a-41e9-de61-05ebe07b41fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "# Menggabungkan karakter unik pada setiap elemen dataset\n",
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Q41uSysqiuM"
      },
      "outputs": [],
      "source": [
        "# Menyimpan panjang urutan\n",
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StRjIpCjqt3R",
        "outputId": "bdbfc4d5-133e-47ad-f39b-7301934689eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "# Menunjukkan jika panjang urutan tidak dapat dibagi habis, maka elemen yang tersisa akan dihapus\n",
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "# Melakukan iterasi\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUqoyPpWqyHL",
        "outputId": "2b628302-7f27-4110-9fe1-7dd27bb8801a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "# Mengonversi hasil setiap ID numerik menjadi array NumPy\n",
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3Xg2vskq4rS"
      },
      "outputs": [],
      "source": [
        "# Memprediksi elemen\n",
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-O_VmZcPq_Kt",
        "outputId": "ced41f8c-5c56-45be-9b72-e64ee7044238"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Memisahkan list menjadi 2 bagian\n",
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v7E0K75rCBA"
      },
      "outputs": [],
      "source": [
        "# Memisahkan setiap urutan ID numerik menjadi pasangan input\n",
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qni0aFMurE32",
        "outputId": "33c43169-fd8b-41a7-8aba-c0adc26b3808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "# Mencetak pasangan input dan target untuk melihat urutan ID yang konkret\n",
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1Vv39uRrML9"
      },
      "source": [
        "**Membuat Batch Training**\n",
        "\n",
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvS5OXNYrP7u",
        "outputId": "bc6e8fab-c663-4326-f445-c7944eafbcc4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menentukan ukuran batch yang akan digunakan\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Menentukan ukuran buffer yang digunakan saat melakukan pengacakan dataset\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "#\n",
        "dataset = (\n",
        "    dataset\n",
        "    # Melakukan pengacakan elemen dalam dataset menggunakan buffer seukuran BUFFER_SIZE\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    # Membagi dataset menjadi batch dengan ukuran BATCH_SIZE\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    # Menerapkan prefetching pada dataset\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT0_JTxvrZgw"
      },
      "source": [
        "**Buat Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b71iEVM7rcTb"
      },
      "outputs": [],
      "source": [
        "# Menghitung panjang atau jumlah elemen dalam vocabulary\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# Menentukan dimensi embedding\n",
        "embedding_dim = 256\n",
        "\n",
        "# Menentukan jumlah unit untuk memproses urutan data\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPsSAW9VrfUa"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    # Mengonversi ID numerik menjadi representasi vektor kontinu\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    # Memproses urutan data dengan menentukan jumlah unit GRU\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    # Menentukan jumlah unit output\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  # Mendefinisikan bagaimana model melakukan forward pass\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    # Menginisialisasi variabel x\n",
        "    x = inputs\n",
        "    # Memproses input melalui layer embedding\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    # Memproses input melalui layer GRU\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    # Memproses hasil dari GRU melalui layer Dense untuk mendapatkan output model\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    # mengembalikan output (x)\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    # Jika tidak, model hanya akan mengembalikan output (x).\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVr7flWVeh7a"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    # Menentukan ukuran vocabulary\n",
        "    vocab_size=vocab_size,\n",
        "    # Menentukan dimensi embedding\n",
        "    embedding_dim=embedding_dim,\n",
        "    # Menentukan jumlah unit dalam layer GRU\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BlbCHTAeoal"
      },
      "source": [
        "**Uji Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma2L_7OverD7",
        "outputId": "09f63336-437e-4fa9-a22d-ce5d6c9ba4ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "# Melakukan iterasi melalui satu batch pertama dari dataset\n",
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    # Membuat prediksi pada input batch\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    # Mencetak bentuk dari hasil prediksi\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKOWgSgbevEA",
        "outputId": "4a6a1e14-44c2-42e9-ed30-f548fbf992b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Mencetak summary\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7y2IrXrdeyrv"
      },
      "outputs": [],
      "source": [
        "# Menghasilkan sampel indeks\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssIT2jAoe0__",
        "outputId": "ab4ec289-aec9-433a-f4bf-ec115a196815"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([12, 53, 13,  9, 18, 34, 34,  7, 46, 18, 21, 63, 20, 29, 30, 36, 59,\n",
              "       40, 32, 50, 57, 62, 33, 26,  2,  4, 47, 65, 50, 63, 25, 47, 23, 22,\n",
              "        5, 46, 34, 12, 25, 10, 54, 16, 57, 52, 60, 28,  5, 14, 62, 26, 50,\n",
              "       55, 47, 54, 51, 30, 18, 36, 59, 51, 29, 49, 27, 44,  2, 64,  3, 24,\n",
              "       10, 39, 14, 53, 51,  7, 61, 50, 44,  2, 25, 14, 56, 11, 10, 43, 16,\n",
              "       53, 26, 17, 39, 57, 39, 46, 14,  1, 25, 43, 51, 42, 42, 63])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengekstrak dan menampilkan nilai indeks\n",
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa3BeU_te3ji",
        "outputId": "80adb92e-8781-4a54-ce3d-c1190ed49ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'Third Servingman:\\nO slaves, I can tell you news,-- news, you rascals!\\n\\nFirst Servingman:\\nWhat, what,'\n",
            "\n",
            "Next Char Predictions:\n",
            " b';n?.EUU,gEHxGPQWtaSkrwTM $hzkxLhJI&gU;L3oCrmuO&AwMkpholQEWtlPjNe y!K3ZAnl,vke LAq:3dCnMDZrZgA\\nLdlccx'\n"
          ]
        }
      ],
      "source": [
        "# Mencetak teks dari input ke konsol dengan label \"Input\"\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "# Mencetak teks dari sampel indeks ke konsol dengan label \"Next Char Predictions\"\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbI8lF6Ce7FM"
      },
      "source": [
        "**Train Model**\n",
        "\n",
        "Pada titik ini permasalahan dapat dianggap sebagai permasalahan klasifikasi standar. Permasalahan dapat disimpulkan dengan : Berdasarkan status RNN sebelumnya, dan masukan langkah kali ini, prediksi kelas karakter berikutnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CW2554fke-Js"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan objek fungsi kerugian untuk menghitung kerugian antara prediksi model dan label yang sebenarnya\n",
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NIEPsdHfB0z",
        "outputId": "24c540b2-ed57-45fd-a49c-dd1bd849fd27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1889763, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# Menghasilkan nilai rata-rata kerugian untuk satu batch\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "# Mencetak bentuk dari prediksi model\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "# Mencetak nilai rata-rata kerugian untuk satu batch\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRpxKxUpfEGq",
        "outputId": "eaf7298d-ad70-4bae-d501-f39d795634c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "65.95524"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Menghitung nilai eksponensial dari setiap elemen dalam tensor\n",
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6qK-P4JfGNw"
      },
      "outputs": [],
      "source": [
        "# Menentukan optimizer yang akan digunakan selama pelatihan\n",
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZTlfshOfJs9"
      },
      "source": [
        "**Konfigurasi Checkpoints**\n",
        "\n",
        "Gunakan tf.keras.callbacks.ModelCheckpoint untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWcVNg3IfMKQ"
      },
      "outputs": [],
      "source": [
        "# Menentukan direktori tempat checkpoint akan disimpan\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Menentukan awalan nama file untuk checkpoint\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    # Menentukan jalur dan awalan nama file untuk checkpoint\n",
        "    filepath=checkpoint_prefix,\n",
        "    # Menentukan bahwa hanya bobot model yang akan disimpan sebagai checkpoint\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zbHTlWVfQfZ"
      },
      "source": [
        "**Lakukan Proses Training**\n",
        "\n",
        "Agar waktu pelatihan tidak terlalu lama, gunakan 10 epoch untuk melatih model. Di Colab, setel runtime ke GPU untuk pelatihan yang lebih cepat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMDpzRV7fSwG"
      },
      "outputs": [],
      "source": [
        "# Menentukan jumlah epoch\n",
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGYdXPThfktY",
        "outputId": "8b0b8579-358f-457e-fde4-1fb898b3f8f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 1045s 6s/step - loss: 2.6982\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 1043s 6s/step - loss: 1.9715\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 1031s 6s/step - loss: 1.6931\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 1021s 6s/step - loss: 1.5357\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 1022s 6s/step - loss: 1.4389\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 1026s 6s/step - loss: 1.3710\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 1010s 6s/step - loss: 1.3200\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 1030s 6s/step - loss: 1.2742\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 1007s 6s/step - loss: 1.2327\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 1009s 6s/step - loss: 1.1926\n"
          ]
        }
      ],
      "source": [
        "# Melatih dengan dataset yang diberikan\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajob9c41frLx"
      },
      "source": [
        "**Generate Teks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHCRebGAfs1u"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  # Mengontrol sejauh mana variasi output yang dihasilkan oleh model\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    # Menyimpan model sebagai atribut kelas\n",
        "    self.model = model\n",
        "    # Menyimpan fungsi konversi karakter\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    # Menyimpan fungsi konversi token\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Membuat tensor yang berisi token ID dari karakter [UNK]\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    # Membangun tensor yang banyak nilainya nol\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  #  Mendeklarasikan metode generate_one_step sebagai fungsi TensorFlow yang dapat dijalankan secara grafis\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Mengonversi input ke token IDs\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    # Mengonversi karakter input ke token IDs dan mengonversi hasilnya ke dalam bentuk tensor\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Menjalankan model untuk mendapatkan logits dan state model\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Mengambil prediksi terakhir\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Menerapkan mask pada logits untuk mencegah karakter [UNK]\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Mengambil sampel dari distribusi kategorikal untuk mendapatkan token IDs\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    #Menghilangkan dimensi ke-2 dari tensor hasil sampel\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Mengonversi token IDs hasil sampel ke karakter\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Mengembalikan karakter\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8nlKPaNfzC5"
      },
      "outputs": [],
      "source": [
        "# Mengonversi karakter ke token IDs untuk mengonversi input karakter menjadi token IDs\n",
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c3KH_DBf066",
        "outputId": "0779c565-5ad3-4b14-fc73-da0fe1f8bdbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "And I will own to-morrow.\n",
            "\n",
            "Clown:\n",
            "Ah, ay, you are heard.\n",
            "\n",
            "GREGORY:\n",
            "They say the corn, that's created. Conceives my blood\n",
            "In steps hur discockers I chaple ye; sir,\n",
            "what he you new crept of holds. By him affect.\n",
            "\n",
            "Second Citizen:\n",
            "The shadow paunt of women are you quarrel, for youe\n",
            "that thou sursed state and wanders him;\n",
            "And with Carthag's breathed in this sland\n",
            "To see the flouring penarts to be all\n",
            "gred forth confused with the execution\n",
            "Should bring it could see the affice of my request.\n",
            "Now in the warlike seems like enficious he\n",
            "make me no were to them drop to me.\n",
            "\n",
            "MARCIUS:\n",
            "Thou love's meet accept.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "And will not he to cloof, he fall not join;\n",
            "For neither death in warwhed to your own course,\n",
            "Blow thrush my head is dukedom and in that dif.\n",
            "A kingly dear spitchet and cracked in;\n",
            "Which would be resosted with the state: where thou satest\n",
            "to still unjasting by the comfort and ceres\n",
            "And feat protectors by me, and more thou, man in steel\n",
            "One throwed out of necessable.\n",
            "About it! \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.557306528091431\n"
          ]
        }
      ],
      "source": [
        "# Merekam waktu awal sebelum proses generasi teks dimulai\n",
        "start = time.time()\n",
        "states = None\n",
        "# Menentukan karakter awal yang akan menjadi input pertama untuk model generatif\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "# Melakukan Loop sebanyak 1000 langkah untuk menghasilkan teks berisi 1000 karakter\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  # Menambahkan karakter yang dihasilkan ke dalam list result\n",
        "  result.append(next_char)\n",
        "\n",
        "# Menggabungkan semua karakter yang dihasilkan dalam 1 string\n",
        "result = tf.strings.join(result)\n",
        "# Merekam waktu akhir setelah proses generasi teks selesai\n",
        "end = time.time()\n",
        "# Mencetak teks\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jetTImQ9f1sC",
        "outputId": "5e3dea1f-0635-49fe-bbb6-08b03fb7288e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nThey must partain Coponior's comfort-back burns in\\nRecents of holds me. Shall, I reason to thee:\\nThy noble majesty doth my reckence?\\nNow, sir, little good-horse grass and but what tyrant\\nTo hear himself leading us I see\\n, ender im not to be her manner.\\n\\nNORFOLK:\\nAlas, thou face the issue?\\n\\nSTCAMILLO:\\nSir, be right;\\nLet him well so, if defore I of your redempts\\nWhen you most unturnible sought deceived.\\nBut what often and there to armed and good?\\n\\nRICHARD:\\nO, you may do what care?\\n\\nPOMPEY:\\nWell said, you, farewell; let'? all heart\\nMy brother, didst peace and wept the drop.\\n\\nGLOUCESTER:\\nThey say, a very sixternoon to my renowned than in,\\nTo--fortune, to execute of friar, toop for this\\nTo put it offrighty-ornated, answerlious frowns;\\nAnd be you seement, young and all the lew\\nThat, my diffect of the noble direction\\nIf ever mine own fatterngary where thou\\nDauet'st, scalls with another waitings. But what, a boundy\\nTo emils, my house: marry, your heart pray you, but,\\nGone no servant canst tha\"\n",
            " b\"ROMEO:\\nI would not back where I had dined.\\n\\nPRINCE:\\nWhen hang denived for, as thou, sleys ox, word,\\nOnly for the dept with what they repent?\\n\\nNord,\\nHis dear lords to be repair was yet deadly entreat the mark.\\nMy lord, his head, if you cannot cried be obediment.\\n\\nPETRUCHIO:\\nNay, she's ele, he would not yet fall of this his voice:\\nThe overtrains goesword, a subject of her accusation.\\n\\nKING EDWARD IV:\\nYea, uneafe, I underdone with the honour of my\\nsense, my lord, the sought for used, but long.\\n\\nLEONTES:\\nWe will go to;\\nI'll love your brows in great and alone\\nAnd rotty to report him, winding the guilty\\nThe appear in despines thereof, sweet safe aid,\\nHer terrers are all unkindness selamical\\nOf your own powers, and coy'll not persua.\\nWhat manners I live hath no more then risposing of a flese;\\nOf that our law encompass'd compair to proceete\\nOf their victores Duke of Barch, did's etter die,\\nThat you shall be untoward:\\nWhat murityer-hath the mighty deeds\\nTo lift us still charity of smell,\\nAll my prett\"\n",
            " b\"ROMEO:\\nThe worsed is so fartued to us.\\n\\nNurse:\\nA back of his tender brother comes;\\nOr what so roces as unstancely pats:\\nThey do you melt you, shall we because my trunk,\\nBefore the feast was justice.\\n\\nThird Citizen:\\nAnd sighting set the chrife,\\nWith, they not that have no joy promise,\\nYour father's look'd and ourselves to thee, no love,\\nAnd now had been some sworn commonly now?\\nThe note's regs and free look to our own poy\\nAnd was a man flotest wondrously, Buckingham birth\\nTo rich it a merry monarchy.\\n\\nGLOUCESTER:\\nI do repent you now.\\n\\nDUKE VINCENTIO:\\nI am in? think you in heaven with men are lance.\\nWhat's the matter? O that we scandal,\\nFall plent of Bolingbank: 'lone't! I'll swear for the young Rome.\\n\\nSEBASTIAN:\\nBe satisfied! What thou seest not any his lean and good?\\nIf you confines you shall be your displeasure,\\nOr, if thou geterbius's law we masch well intent\\nWith tongue hard-frazed the mortal eyes,\\nOffending but the infection flanter,\\nThy fresh patiens appear which you drack mine,\\nAs quic\"\n",
            " b\"ROMEO:\\nBeseech, leads you: and I should look me.\\n\\nQUEEN:\\nMy lord, be nothing butcher! Just of Gloucester talk?\\n\\nJOHN OF GAUNT:\\nO was my boot! the king married yourselves\\nWill see her wench: bore much geitestury and\\nyeck'd these forneyars women;\\nOr, if you not, soon, God, like as anry reading,\\nInto the deceit of France, the poor intence\\nAnd hented upon thy seasor, lords to eat.\\n\\nBRUTUS:\\nThey have good untold.\\n\\nMARIANABULI:\\nBy my too behold? Why, thene were upright,\\nWeigh one look'd for more strike here in varifier\\nIn't not we make so sight of courage,\\nBe forbary in a suntention to gut\\na trumpet, to prison of those preying in firet,\\nWorse than my face, she is falling off.\\nIf thou here? O hall, what deal hang\\nWhen, you will. For faith, sir, sir,\\nof a gone you with this bloody blood!\\nUpter it, and teach of men and hangs\\nMay be the body trumpets; for then\\nwe have achers to come. we two make Edward's head:\\nNow tapsistire he'll indeer her greatts, surely:\\nI'll landed thin here in the frait-fulling-\"\n",
            " b\"ROMEO:\\nGod-sent there. But noble lords!\\n\\nWARWICK:\\nThough doved and talk of our fetch proceeds\\nThat whom I have newded\\nIn this, one rote and greeting eye,\\nDescend up his natural place, sleep.\\n\\nSecond Lendlerrar:\\n'Tis a skill.\\n\\nKATHARINA:\\nPray, sir, your brother's way to deterance; but my hell\\nOf her custom Frozen, sil, upon thy foot,\\nNor your wholesome meaning wretchiers for\\nthe uncertain our kindred lords himself comes rather\\nLooking out of friends.\\n\\nWARWICK:\\nThen who lattle waves which impodity?\\n\\nAll:\\nTelly here in this lady.\\n\\nDUKE VINCENTIO:\\nYour sights heaven would make refort. Ty crafts, whenservise\\nBut my choesy sellows to be your asking.\\n\\nRICHMOND:\\nGet you to your viswars, what thou mean'st thoughts,\\nAnd leading you a pherishing clouds allet;\\nNow please my feth and budgle, hereafter.\\n\\nPROSPERO:\\nBut seem'd time.\\n\\nBRUTUS:\\nLest I be brief;\\nObey's the real of hence. Come, let's with him.\\n\\nTYRREL:\\nFarewell, I trush you: what speaks of pacions,\\nThat too moonards, instructions and too yet--mo\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 6.784124851226807\n"
          ]
        }
      ],
      "source": [
        "# Merekam waktu awal sebelum proses generasi teks dimulai\n",
        "start = time.time()\n",
        "states = None\n",
        "# Menentukan beberapa string awal sebagai input\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "# Melakukan Loop sebanyak 1000 langkah untuk menghasilkan teks berisi 1000 karakter\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "# Menggabungkan semua string yang dihasilkan menjadi satu string\n",
        "result = tf.strings.join(result)\n",
        "# Merekam waktu akhir setelah proses generasi teks selesai\n",
        "end = time.time()\n",
        "# Mencetak teks\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzLwvOmTgBJE"
      },
      "source": [
        "**Ekspor Model Generator**\n",
        "\n",
        "Model satu langkah ini dapat dengan mudah disimpan dan digunakan kembali, memungkinkan Anda menggunakannya di mana pun tf.saved_model diterima."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cR7aSYxYgC1L",
        "outputId": "5ba729c9-c643-4c01-d7c4-ad5996a9bd9a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7bec5fef1ff0>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "# Menyimpan model ke direktori dengan nama 'one_step'\n",
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "# Memuat kembali model dari direktori yang sama, 'one_step'\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ldd-upKgE5Q",
        "outputId": "72a19d60-96fa-4d61-d004-a1d7422ab79f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "What, you have offly soul!\n",
            "\n",
            "First Senator:\n",
            "Hath can be you deeds, ready by consent\n",
            "Ah, goien: sit t\n"
          ]
        }
      ],
      "source": [
        "#  Inisialisasi state model\n",
        "states = None\n",
        "# Menentukan karakter awal\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "# Melakukan nisialisasi list result\n",
        "result = [next_char]\n",
        "\n",
        "# Loop sebanyak 100 langkah untuk menghasilkan teks berisi 100 karakter\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "# Menggabungkan semua karakter yang dihasilkan menjadi satu string dan mencetaknya\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LCaeWtXrYJx"
      },
      "source": [
        "# Tugas\n",
        "\n",
        "*   Jalankan Model dan hitung loss dengan tf.GradientTape.\n",
        "*   Hitung update dan terapkan pada model dengan optimizer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q9TtuU2LV5iB"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        "     @tf.function\n",
        "     def train_step(self, inputs):\n",
        "        inputs, labels = inputs\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = self.loss(labels, predictions)\n",
        "            grads = tape.gradient(loss, model.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "            return {'loss': loss}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdzEsyD6V87r"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKsSENF6WArO"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMiAZULdWGAf",
        "outputId": "1bf5c540-875d-4442-f3f9-4c1ceaee059f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 949s 5s/step - loss: 2.7218\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bec5f98b160>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0IiHTEUWKXW",
        "outputId": "dec06a36-d46e-4521-e40f-f314d5dd51bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1924\n",
            "Epoch 1 Batch 50 Loss 2.0588\n",
            "Epoch 1 Batch 100 Loss 1.9927\n",
            "Epoch 1 Batch 150 Loss 1.8179\n",
            "\n",
            "Epoch 1 Loss: 1.9860\n",
            "Time taken for 1 epoch 921.91 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.7544\n",
            "Epoch 2 Batch 50 Loss 1.7466\n",
            "Epoch 2 Batch 100 Loss 1.6997\n",
            "Epoch 2 Batch 150 Loss 1.6337\n",
            "\n",
            "Epoch 2 Loss: 1.7116\n",
            "Time taken for 1 epoch 921.92 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5910\n",
            "Epoch 3 Batch 50 Loss 1.6010\n",
            "Epoch 3 Batch 100 Loss 1.5403\n",
            "Epoch 3 Batch 150 Loss 1.5356\n",
            "\n",
            "Epoch 3 Loss: 1.5518\n",
            "Time taken for 1 epoch 921.91 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4751\n",
            "Epoch 4 Batch 50 Loss 1.4134\n",
            "Epoch 4 Batch 100 Loss 1.4284\n",
            "Epoch 4 Batch 150 Loss 1.4634\n",
            "\n",
            "Epoch 4 Loss: 1.4519\n",
            "Time taken for 1 epoch 921.92 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3726\n",
            "Epoch 5 Batch 50 Loss 1.3833\n",
            "Epoch 5 Batch 100 Loss 1.3692\n",
            "Epoch 5 Batch 150 Loss 1.3369\n",
            "\n",
            "Epoch 5 Loss: 1.3833\n",
            "Time taken for 1 epoch 922.06 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3331\n",
            "Epoch 6 Batch 50 Loss 1.3217\n",
            "Epoch 6 Batch 100 Loss 1.3288\n",
            "Epoch 6 Batch 150 Loss 1.3303\n",
            "\n",
            "Epoch 6 Loss: 1.3311\n",
            "Time taken for 1 epoch 921.93 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2668\n",
            "Epoch 7 Batch 50 Loss 1.2621\n",
            "Epoch 7 Batch 100 Loss 1.2610\n",
            "Epoch 7 Batch 150 Loss 1.2568\n",
            "\n",
            "Epoch 7 Loss: 1.2852\n",
            "Time taken for 1 epoch 921.91 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2468\n",
            "Epoch 8 Batch 50 Loss 1.2259\n",
            "Epoch 8 Batch 100 Loss 1.2529\n",
            "Epoch 8 Batch 150 Loss 1.2771\n",
            "\n",
            "Epoch 8 Loss: 1.2440\n",
            "Time taken for 1 epoch 921.91 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1575\n",
            "Epoch 9 Batch 50 Loss 1.2136\n",
            "Epoch 9 Batch 100 Loss 1.2324\n",
            "Epoch 9 Batch 150 Loss 1.2207\n",
            "\n",
            "Epoch 9 Loss: 1.2030\n",
            "Time taken for 1 epoch 893.97 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1366\n",
            "Epoch 10 Batch 50 Loss 1.1647\n",
            "Epoch 10 Batch 100 Loss 1.1831\n",
            "Epoch 10 Batch 150 Loss 1.1788\n",
            "\n",
            "Epoch 10 Loss: 1.1637\n",
            "Time taken for 1 epoch 922.04 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "      model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krEQUpRVWRZS"
      },
      "source": [
        "*   Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?\n",
        "\n",
        "\n",
        "Tugas diatas menggunakan tf.GradientTape yang mana pada gradien dari nilai kesalahan tersebut dapat dilatih dalam model dilacak, kemudian diterapkan untuk memperbarui variabel tersebut. Prediksi model ini didasari oleh hasil prediksi sebelumnya pada langkah sebelumnya. Sehingga, apabila terdapat kesalahan dalam prediksi, akan berdampak pada langkah berikutnya. Jadi, setiap kesalahan pada setiap langkah akan memengaruhi hasil prediksi model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}